var documenterSearchIndex = {"docs":
[{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#A-Deep-Dive-into-Distributed.jl","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-12-06</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-12-06</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-20</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-08-20</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='154' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='154' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='135' height='20' fill='#0F80C1'/><rect width='154' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='855' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='1250'>Distributed Computing</text><text x='855' y='140' transform='scale(.1)' textLength='1250'>Distributed Computing</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='54' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='54' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='35' height='20' fill='#0F80C1'/><rect width='54' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='355' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='250'>Julia</text><text x='355' y='140' transform='scale(.1)' textLength='250'>Julia</text></g></svg></div>","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"<iframe src=\"slide/index.html\" style=\"width: 100%;height: 50vh\"></iframe>","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"slide","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Distributed.jl is a standard library in Julia to do multi-processing and distributed computing. The distributed-computing section in the official julia docs already provides a nice introduction on how to use it. I assume most of you have skimmed through it. So here I'll mainly focus on how this package is designed and implemented, hoping that you'll have a better understanding after this talk.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"My talk will be organized in the Q&A style. So feel free to raise more questions in the end of this talk if anything is still unclear to you.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#1.-How-to-initialize-Distributed.jl?","page":"A Deep Dive into Distributed.jl","title":"1. How to initialize Distributed.jl?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"The easiest way is to start the julia with an extra parameter -p auto. Then based on the number of logical cores on your machine, the same number of julia processors will be created and connected on your machine. Or you can specify the number explicitly.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n                         ┌─────────────┐\n                    ┌────► myid() == 2 │\n                    │    └─────────────┘\n ┌─────────────┐    │\n │ julia -p 3  │    │    ┌─────────────┐\n │             ├────┼────► myid() == 3 │\n │ myid() == 1 │    │    └─────────────┘\n └─────────────┘    │\n                    │    ┌─────────────┐\n                    └────► myid() == 4 │\n                         └─────────────┘\n","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"To create multiple processors, we can provide a file like this:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"println(run(`cat $(joinpath(@__DIR__, \"local_machines\"))`))","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"And set it to the --machine-file argument. In the above file, we use the localhost 127.0.0.1 for simplicity.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n\n                                             ┌─────────────┐\n                                          ┌──► myid() == 2 │\n                              ┌────────┐  │  └─────────────┘\n                           ┌──► Node 1 ├──┤\n                           │  └────────┘  │  ┌─────────────┐\n                           │              └──► myid() == 3 │\n                           │                 └─────────────┘\n ┌──────────────────────┐  │\n │ julia --machine-file │  │\n │                      ├──┤\n │     myid() == 1      │  │                 ┌─────────────┐\n └──────────────────────┘  │              ┌──► myid() == 4 │\n                           │  ┌────────┐  │  └─────────────┘\n                           └──► Node 2 ├──┤\n                              └────────┘  │  ┌─────────────┐\n                                          └──► myid() == 5 │\n                                             └─────────────┘","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Of course, you can also set them dynamically with addprocs.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#1.1-Why-is-there-an-extra-processor-created?","page":"A Deep Dive into Distributed.jl","title":"1.1 Why is there an extra processor created?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"It's mentioned in the distributed-computing section from the official doc that:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Communication in Julia is generally \"one-sided\", meaning that the programmer needs to explicitly manage only one process in a two-process operation.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"This means that, by design the processor we created to launch workers will serve as the header. Its main goal is to dispatch jobs to workers instead of doing computing on its own. So in most cases, we just execute code on the header and tell workers what they need to do. That is what \"one-sided\" means above.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"So the header processor is just the extra one we created.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#2.-How-are-the-workers-created?","page":"A Deep Dive into Distributed.jl","title":"2. How are the workers created?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"This can be narrowed down to several more specific questions. But before answering them, let's see what's happening when we load the package with using Distributed first.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Let's ignore the first line for now. We'll discuss start_gc_msgs_task later. Two important global variables are initialized here, the first one is LPROC (Local Processor for short), which serves like an identifier of the current processor. The second one is PGRP, (Processor Group for short). It records the workers we'll create later. It will be initialized with the only one element LPROC here. And that's why you'll see only one worker with id 1 is returned from workers().","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"using Distributed\nworkers()","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"The function to create workers is provided by addprocs. By default, it will be dispatched to addprocs_locked(manager::ClusterManager; kw...) (Here ClusterManager is an abstract type, we'll introduce two typical implementations in Distributed.jl soon). Since two main public APIs are involved in its implementation, let's examine the code in detail here:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"First, it tries to call the launch method implemented by specific ClusterManager asynchronously. Then the main task will periodically check whether the launch task has been finshed or not every second. If not, it'll try to setup the the connection with workers which has already been added into launched by the ClusterManager. Note that the outer @sync will guarantee all the setup_launched_worker calls are finished (all connections between header and worker are initialized).","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"So what should launch do? As the doc says:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"launch(manager::ClusterManager, params::Dict, launched::Array, launch_ntfy::Condition)Implemented by cluster managers. For every Julia worker launched by this function, it should append a WorkerConfig entry to launched and notify launch_ntfy. The function MUST exit once all workers, requested by manager have been launched. params is a dictionary of all keyword arguments addprocs was called with.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"But what is WorkerConfig? Its definition in Distributed.jl is specifically tight with two ClusterManager and we'll discuss soon. Basically it describes where and how the header should send messages to (Like a IO stream, or a http connection). Once the ClusterManager has finished initializing the worker processor, we need to register this worker in the header:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Figure out where to read messages from (r_s) and write messages to (w_s) worker.\nBind the finalizer of the worker to tell its cluster manager when it's finalized.\nCreate an async task to handle messages from the worker.\nSend the header's information to worker so that the worker knows where the header is and how to send messages.\nWait until the worker confirms and joins the cluster. Otherwise, remove it if time is out.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#2.1-How-are-workers-created-on-my-local-machine?","page":"A Deep Dive into Distributed.jl","title":"2.1 How are workers created on my local machine?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Pretty straightforward, right? A new julia processor is created and then a worker config is properly set. But how does this new processor handle new messages sent from sender or other workers? Note that there's an extra option --worker in the cmd.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"With this option, the newly created julia processor will do some extra work for us to have everything properly set. Basically, it will create a new socked connection and handle messages coming in. You can use netstat -tunlp | grep julia to see which ports the workers are using.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#2.2-How-are-workers-created-across-different-machines?","page":"A Deep Dive into Distributed.jl","title":"2.2 How are workers created across different machines?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"To create workers across machines, Distributed.jl provides a SSH based cluster manager. Although the code in the SSHManager looks very complex, the core idea behind is similar to the LocalManager. We run the command to create a julia worker processor through SSH and record the process id. Then we can use this id to kill the worker if required.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#2.3-A-practical-example","page":"A Deep Dive into Distributed.jl","title":"2.3 A practical example","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"In ClusterManagers.jl, several common cluster managers are provided. You should definitely check it first if the default LocalManager and SSHManager don't apply in your environment. Now let's take a close look at an interesting one: ElasticManager.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"                                 ┌────────┐\n                               ┌─┤ worker │\n                               │ └────────┘\n      ┌─────────────┐ connect  │   ......\n      │ socket      │          │ ┌────────┐\n      │             │◄─────────┼─┤ worker │\n      │   - address │          │ └────────┘\n      │   - port    │          │ ......\n      └────▲───┬────┘          │ ┌────────┐\n           │   │               └─┤ worker │\n           │   │                 └────────┘\n           │   │\n           │   │ received new connection\n    watch  │   │\n  new conn │   │ check cookie\n           │   │\n           │   │ push into\n           │   │\n        ┌──┴───▼──┐\n        │ pending │\n        └────┬────┘\n             │\n             │\n             │\n        ┌────▼─────┐\n        │ addprocs │\n        └──────────┘","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"After initialization, the ElasticManageer created two background tasks: the first one is to watch on new connections, and the second one is to add new processors by reusing the addprocs function in Distributed.jl. In the launch step, it simply take take the pending socket and add it into launched. And in the manage step, it simply maintains a dict of active workers.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#3.-How-do-workers-communicate?","page":"A Deep Dive into Distributed.jl","title":"3. How do workers communicate?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"In the above section, we've mentioned that a worker processor will run start_worker first after initialization, and then wait for messages. But how are messages encoded and interpreted?","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n                  ┌─────────────────────┐\n                  │     .........       │\n                  │ ┌─────────────────┐ │\n                  │ │     BOUNDARY    │ │\n                  │ └─────────────────┘ │\n                  │                     │\n                  │ ┌─────────────────┐ │\n                  │ │ header          │ │\n                  │ │                 │ │\n               ┌──┼─►  * response_oid │ │\n               │  │ │  * notify_oid   │ │\n               │  │ └─────────────────┘ │\n               │  │                     │\n               │  │ ┌─────────────────┐ │\n ┌──────────┐  │  │ │                 │ │    ┌────────────┐\n │ send_msg ├──┼──┼─► builtin message ├─┼────► handle_msg │\n └──────────┘  │  │ │                 │ │    └────────────┘\n               │  │ └─────────────────┘ │\n               │  │                     │\n               │  │ ┌─────────────────┐ │\n               └──┼─►     BOUNDARY    │ │\n                  │ └─────────────────┘ │\n                  │     .........       │\n                  └─────────────────────┘\n","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Messages are serialized into a reader steam seperated by a collection of constant bytes (MSG_BOUNDARY). Each message has two parts, a header and a message body. In Distributed.jl, several predefined types of messages are provided. Each message then be deserialized and dispatched to a specific handle_msg implementation. Each header has exactly two fields, the response_oid and notify_oid. Now we are going to study two key concepts in Distributed.jl: remote call and remote reference.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#3.1-Remote-reference","page":"A Deep Dive into Distributed.jl","title":"3.1 Remote reference","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"In Distributed.jl, each worker has a unique id (myid()). To locate objects created by Distributed.jl, each of them will also have a unique id in that processor.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"As you can see, by default the id is auto-increment. And the whence is set to the current worker. Remember that each AbstractRemoteRef instance must at least contain these two basic id to locate it.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Future","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"A Future is an abstract container of a remote object (it can also reside in the current processor). Beyond the whence and id, it has two extra fields. The where indicates where the underlying value v is stored. Understanding the difference between where and whence is crucial. Let's say we're on worker 1 and would like to do a simple calculation of 1+1 on worker 2. Without the where field, we have to first send the remote calculation message to worker 2. Then the worker create a unique RRID and return it to worker 1. And when we want to fetch the calculation result v, we have to send the fetch command to worker 2 again and wait until the calculation is done and passed the result back to worker 1.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n                                timeline\n\n                                    │\n ┌───────────────────────────────┐  │  ┌────────────────────────────────┐\n │ worker 1                      │  │  │                        worker 2│\n │                               │  │  │                                │\n │          remotecall F: 1 + 1 ─┼──┼──┤►                               │\n │                               │  │  │  create a unique remote ref: R │\n │                waiting......  │  │  │                                │\n │                              ◄├──┼──┼─ pass back R                   │\n │        remote_ref R received  │  │  │                                │\n │                               │  │  │  do the calculation of F       │\n │    do some other calculation  │  │  │                                │\n │                               │  │  │  ......                        │\n │                       ......  │  │  │                                │\n │                               │  │  │                                │\n │ fetch result from remote_ref ─┼──┼──┤► wait F finish                 │\n │                               │  │  │                                │\n │                               │  │  │  ......                        │\n │                waiting......  │  │  │                                │\n │                              ◄├──┼──┼─ send back result              │\n │          remote value cached  │  │  │                                │\n │                               │  │  │                                │\n └───────────────────────────────┘  │  └────────────────────────────────┘\n                                    ▼","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"But if we have a where field to record where the calculation happens, then the first round could be reduced.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"                              timeline\n\n                                  │\n ┌─────────────────────────────┐  │  ┌───────────────────┐\n │  worker 1                   │  │  │          worker 2 │\n │                             │  │  │                   │\n │       create remote call F ─┼──┼──┤► received F & R   │\n │           and remote ref R  │  │  │                   │\n │                             │  │  │  do calculation   │\n │  do some other calculation  │  │  │                   │\n │                             │  │  │  ......           │\n │                     ......  │  │  │                   │\n │                             │  │  │                   │\n │  fetch reult from where(R) ─┼──┼──┤► wait F finish    │\n │                             │  │  │                   │\n │                             │  │  │  ......           │\n │              waiting......  │  │  │                   │\n │                            ◄├──┼──┼─ send back result │\n │        remote value cached  │  │  │                   │\n └─────────────────────────────┘  │  └───────────────────┘\n                                  ▼","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"RemoteChannel is similar, except that the underlying value can not be copied back and forth. We can only check whether it is ready and take! elements from it.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#3.2-Remote-call","page":"A Deep Dive into Distributed.jl","title":"3.2 Remote call","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Now let's examine what's happening in the following simple code:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"using Distributed\n\naddprocs(2)\n\nx = @spawnat 2 begin\n    sleep(3)\n    rand(3)\nend\n\nprint(x[])","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"First, we create a worker with addprocs(2). Then we try to create a remote call which simply returns a random vector. The @spawnat macro will wrap the following expression into a parameterless function (usually known as a thunk) and turn it into a remotecall. In remotecall, a Future is first created to store the result in the future. Then the whence and id info of the future is extracted to form the message header (a RRID). The thunk is wrapped in a specific CallMsg and forms the message body. The whole message is serialized and written to the worker's r_stream. Note that the remotecall is async, so you can work on some other stuff and fetch the result later. On the worker side, once received a new message, it is deserialized and dispatched to the corresponding handle_msg call. For CallMsg, it will create a temp Channel(1) to store the result and associate it with the RRID in its global client_refs. Now when we try to fetch the result with x[], it will send another message of remotecall_fetch with a dedicated function fetch_ref and wait for the response. Once it receives the result. It will be cached in its :v field, so that future fetch calls will not do the remote call again.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"The following up question is, what about the original data on worker 2? Since now we have fetched and cached the value, we won't need it anymore.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Actually we can't remove it from worker 2 directly. Let's say we send the future x to another worker 3 before it fetches the result. If the result is removed from worker 2 immediately in respond to the fetch operation on worker 1. Then the worker 3 will never get the chance to fetch the result. But we still need to remove it sometime, right? Otherwise the memory usage will keep growing. In fact, the worker where the data of the Future resides will keep track of the connected workers of this Future. Everytime the GC hapens with a Future, we'll try to delete itself from the connected clients. And when no connected clients left, we're safe to remove it from client_refs.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Note that some expresions can't be executed through @spawnat (for example using SomePackage). That's why we have several different message types and handle_msg implementations. But the whole pipeline is almost the same.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#3.3-WorkerPool-and-pmap","page":"A Deep Dive into Distributed.jl","title":"3.3 WorkerPool and pmap","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"With the knowledge above, now we know how the Distributed.jl works. But still it is not very easy to use since we have to deal with the worker id directly. That's why WorkerPool and pmap are provided. pmap tries to divide the workload first and the worker pool can help to leverage computing resource more efficiently. This part is relatively easy to read and understand.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/#Is-Distributed.jl-perfect?","page":"A Deep Dive into Distributed.jl","title":"Is Distributed.jl perfect?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Well, the standard answer is, there's no perfect design, only traceoffs. In my opinion, Distributed.jl is designed for HPC environments, where all the workers are quite stable. All the functionalities it provides are very fundamental and do not feature usability that much. On top of it, there's a Dagger.jl which is more usable for dynamic graph computing. And I'm also considering implementing a more flexible one. Stay tuned!","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.en/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"keywords: Algorithm CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/The_EM_Algorithm/#EM算法","page":"EM算法","title":"EM算法","text":"","category":"section"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"偶然看到一篇文章讲EM算法，感觉讲得很清晰。文中用到了一个抛硬币的问题，这里“搬运”过来，重新阐述下。","category":"page"},{"location":"essays/The_EM_Algorithm/#问题","page":"EM算法","title":"问题","text":"","category":"section"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"假设现在有两枚硬币，随机抛掷之后，正面朝上的概率分别设为theta_A和theta_B，然后我们做了5轮实验，每轮随机选一枚硬币（记为z_i），抛10次并记录结果（记为boldsymbolx_i），现在我们希望估计出theta_A和theta_B的值。","category":"page"},{"location":"essays/The_EM_Algorithm/#最大似然","page":"EM算法","title":"最大似然","text":"","category":"section"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"假设z_i是已知的，那么只需最大化对数似然log (x z theta)即可，根据采样独立性假设，将log似然对theta求导之后，可以得到theta的点估计：","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"$","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"\\begin{equation} \\hat {\\theta_A} = \\frac {选择硬币A时正面朝上的次数} {选择硬币A的次数} \\end{equation} $","category":"page"},{"location":"essays/The_EM_Algorithm/#EM","page":"EM算法","title":"EM","text":"","category":"section"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"假如隐变量z不可知，那么就无法通过上面的方法求解了。不过，我们可以先随机设置theta的一组取值，然后根据观测数据boldsymbolx“猜测”隐变量的分布z，再利用该隐变量的估计值和观测数据boldsymbolx，按照前面最大似然的做法去计算theta的值，如此迭代直至theta收敛。","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"需要注意的是，这里“猜测”的是z的分布，而不是具体的某个值，联系到K-means算法中，通常的做法是将每个中心点做替换，这里相当于只是做“软分类”。","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"具体流程见原图：","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"(Image: An Introduction of EM Algorithm)","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"下面我用Python代码将图中的流程复现下：","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"import numpy as np\nfrom scipy.stats import binom\n\nobserved = \"\"\"\nHTTTHHTHTH\nHHHHTHHHHH\nHTHHHHHTHH\nHTHTTTHHTT\nTHHHTHHHTH\"\"\"\n\nx = np.array([[1 if c==\"H\" else 0 for c in line] for line in observed.strip().split()])\nx_heads = x.sum(axis=1)\nx_tails = 10 - x.sum(axis=1)\nassert np.all(x_heads == np.array([5,9,8,4,7]))\n\ndef calc_z(theta):\n    za_est = binom.pmf(x_heads, 10, theta[0])\n    zb_est = binom.pmf(x_heads, 10, theta[1])\n    return za_est / (za_est + zb_est), zb_est / (za_est + zb_est)\n\ndef calc_theta(z):\n    h_A = (x_heads * z[0]).sum()\n    t_A = (x_tails * z[0]).sum()\n    h_B = (x_heads * z[1]).sum()\n    t_B = (x_tails * z[1]).sum()\n    return h_A / (h_A + t_A), h_B / (h_B + t_B)    \n\ndef is_nearly_same(theta_pre, theta_cur):\n    return np.abs(sum(theta_pre) - sum(theta_cur)) < 1e-5\n\ntheta_pre = [0.6, 0.5]\n\nfor i in range(1000):\n    theta_cur = calc_theta(calc_z(theta_pre))\n    if is_nearly_same(theta_pre, theta_cur):\n        print i, theta_cur\n        break\n    else:\n        theta_pre = theta_cur\n# 11 (0.7967829009034072, 0.51959543422720311)","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"显然，EM只能找到局部最优解，可以通过设置多个随机起始点来缓解这个问题，原文对这个问题有讨论。","category":"page"},{"location":"essays/The_EM_Algorithm/","page":"EM算法","title":"EM算法","text":"此外，一点个人感受，这里随机初始点有点像先验，然后通过似然更新，得到一次后验估计（即先验和最大似然的中和），如此迭代，有意思。","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#A-Deep-Dive-into-Distributed.jl","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-12-06</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-12-06</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-20</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-08-20</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='154' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='154' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='135' height='20' fill='#0F80C1'/><rect width='154' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='855' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='1250'>Distributed Computing</text><text x='855' y='140' transform='scale(.1)' textLength='1250'>Distributed Computing</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='54' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='54' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='35' height='20' fill='#0F80C1'/><rect width='54' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='355' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='250'>Julia</text><text x='355' y='140' transform='scale(.1)' textLength='250'>Julia</text></g></svg></div>","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"<iframe src=\"slide/index.html\" style=\"width: 100%;height: 50vh\"></iframe>","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"slide","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Distributed.jl is a standard library in Julia to do multi-processing and distributed computing. The distributed-computing section in the official julia docs already provides a nice introduction on how to use it. I assume most of you have skimmed through it. So here I'll mainly focus on how this package is designed and implemented, hoping that you'll have a better understanding after this talk.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"My talk will be organized in the Q&A style. So feel free to raise more questions in the end of this talk if anything is still unclear to you.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#1.-How-to-initialize-Distributed.jl?","page":"A Deep Dive into Distributed.jl","title":"1. How to initialize Distributed.jl?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"The easiest way is to start the julia with an extra parameter -p auto. Then based on the number of logical cores on your machine, the same number of julia processors will be created and connected on your machine. Or you can specify the number explicitly.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n                         ┌─────────────┐\n                    ┌────► myid() == 2 │\n                    │    └─────────────┘\n ┌─────────────┐    │\n │ julia -p 3  │    │    ┌─────────────┐\n │             ├────┼────► myid() == 3 │\n │ myid() == 1 │    │    └─────────────┘\n └─────────────┘    │\n                    │    ┌─────────────┐\n                    └────► myid() == 4 │\n                         └─────────────┘\n","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"To create multiple processors, we can provide a file like this:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"println(run(`cat $(joinpath(@__DIR__, \"local_machines\"))`))","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"And set it to the --machine-file argument. In the above file, we use the localhost 127.0.0.1 for simplicity.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n\n                                             ┌─────────────┐\n                                          ┌──► myid() == 2 │\n                              ┌────────┐  │  └─────────────┘\n                           ┌──► Node 1 ├──┤\n                           │  └────────┘  │  ┌─────────────┐\n                           │              └──► myid() == 3 │\n                           │                 └─────────────┘\n ┌──────────────────────┐  │\n │ julia --machine-file │  │\n │                      ├──┤\n │     myid() == 1      │  │                 ┌─────────────┐\n └──────────────────────┘  │              ┌──► myid() == 4 │\n                           │  ┌────────┐  │  └─────────────┘\n                           └──► Node 2 ├──┤\n                              └────────┘  │  ┌─────────────┐\n                                          └──► myid() == 5 │\n                                             └─────────────┘","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Of course, you can also set them dynamically with addprocs.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#1.1-Why-is-there-an-extra-processor-created?","page":"A Deep Dive into Distributed.jl","title":"1.1 Why is there an extra processor created?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"It's mentioned in the distributed-computing section from the official doc that:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Communication in Julia is generally \"one-sided\", meaning that the programmer needs to explicitly manage only one process in a two-process operation.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"This means that, by design the processor we created to launch workers will serve as the header. Its main goal is to dispatch jobs to workers instead of doing computing on its own. So in most cases, we just execute code on the header and tell workers what they need to do. That is what \"one-sided\" means above.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"So the header processor is just the extra one we created.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#2.-How-are-the-workers-created?","page":"A Deep Dive into Distributed.jl","title":"2. How are the workers created?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"This can be narrowed down to several more specific questions. But before answering them, let's see what's happening when we load the package with using Distributed first.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Let's ignore the first line for now. We'll discuss start_gc_msgs_task later. Two important global variables are initialized here, the first one is LPROC (Local Processor for short), which serves like an identifier of the current processor. The second one is PGRP, (Processor Group for short). It records the workers we'll create later. It will be initialized with the only one element LPROC here. And that's why you'll see only one worker with id 1 is returned from workers().","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"using Distributed\nworkers()","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"The function to create workers is provided by addprocs. By default, it will be dispatched to addprocs_locked(manager::ClusterManager; kw...) (Here ClusterManager is an abstract type, we'll introduce two typical implementations in Distributed.jl soon). Since two main public APIs are involved in its implementation, let's examine the code in detail here:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"First, it tries to call the launch method implemented by specific ClusterManager asynchronously. Then the main task will periodically check whether the launch task has been finshed or not every second. If not, it'll try to setup the the connection with workers which has already been added into launched by the ClusterManager. Note that the outer @sync will guarantee all the setup_launched_worker calls are finished (all connections between header and worker are initialized).","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"So what should launch do? As the doc says:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"launch(manager::ClusterManager, params::Dict, launched::Array, launch_ntfy::Condition)Implemented by cluster managers. For every Julia worker launched by this function, it should append a WorkerConfig entry to launched and notify launch_ntfy. The function MUST exit once all workers, requested by manager have been launched. params is a dictionary of all keyword arguments addprocs was called with.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"But what is WorkerConfig? Its definition in Distributed.jl is specifically tight with two ClusterManager and we'll discuss soon. Basically it describes where and how the header should send messages to (Like a IO stream, or a http connection). Once the ClusterManager has finished initializing the worker processor, we need to register this worker in the header:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Figure out where to read messages from (r_s) and write messages to (w_s) worker.\nBind the finalizer of the worker to tell its cluster manager when it's finalized.\nCreate an async task to handle messages from the worker.\nSend the header's information to worker so that the worker knows where the header is and how to send messages.\nWait until the worker confirms and joins the cluster. Otherwise, remove it if time is out.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#2.1-How-are-workers-created-on-my-local-machine?","page":"A Deep Dive into Distributed.jl","title":"2.1 How are workers created on my local machine?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Pretty straightforward, right? A new julia processor is created and then a worker config is properly set. But how does this new processor handle new messages sent from sender or other workers? Note that there's an extra option --worker in the cmd.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"With this option, the newly created julia processor will do some extra work for us to have everything properly set. Basically, it will create a new socked connection and handle messages coming in. You can use netstat -tunlp | grep julia to see which ports the workers are using.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#2.2-How-are-workers-created-across-different-machines?","page":"A Deep Dive into Distributed.jl","title":"2.2 How are workers created across different machines?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"To create workers across machines, Distributed.jl provides a SSH based cluster manager. Although the code in the SSHManager looks very complex, the core idea behind is similar to the LocalManager. We run the command to create a julia worker processor through SSH and record the process id. Then we can use this id to kill the worker if required.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#2.3-A-practical-example","page":"A Deep Dive into Distributed.jl","title":"2.3 A practical example","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"In ClusterManagers.jl, several common cluster managers are provided. You should definitely check it first if the default LocalManager and SSHManager don't apply in your environment. Now let's take a close look at an interesting one: ElasticManager.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"                                 ┌────────┐\n                               ┌─┤ worker │\n                               │ └────────┘\n      ┌─────────────┐ connect  │   ......\n      │ socket      │          │ ┌────────┐\n      │             │◄─────────┼─┤ worker │\n      │   - address │          │ └────────┘\n      │   - port    │          │ ......\n      └────▲───┬────┘          │ ┌────────┐\n           │   │               └─┤ worker │\n           │   │                 └────────┘\n           │   │\n           │   │ received new connection\n    watch  │   │\n  new conn │   │ check cookie\n           │   │\n           │   │ push into\n           │   │\n        ┌──┴───▼──┐\n        │ pending │\n        └────┬────┘\n             │\n             │\n             │\n        ┌────▼─────┐\n        │ addprocs │\n        └──────────┘","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"After initialization, the ElasticManageer created two background tasks: the first one is to watch on new connections, and the second one is to add new processors by reusing the addprocs function in Distributed.jl. In the launch step, it simply take take the pending socket and add it into launched. And in the manage step, it simply maintains a dict of active workers.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#3.-How-do-workers-communicate?","page":"A Deep Dive into Distributed.jl","title":"3. How do workers communicate?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"In the above section, we've mentioned that a worker processor will run start_worker first after initialization, and then wait for messages. But how are messages encoded and interpreted?","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n                  ┌─────────────────────┐\n                  │     .........       │\n                  │ ┌─────────────────┐ │\n                  │ │     BOUNDARY    │ │\n                  │ └─────────────────┘ │\n                  │                     │\n                  │ ┌─────────────────┐ │\n                  │ │ header          │ │\n                  │ │                 │ │\n               ┌──┼─►  * response_oid │ │\n               │  │ │  * notify_oid   │ │\n               │  │ └─────────────────┘ │\n               │  │                     │\n               │  │ ┌─────────────────┐ │\n ┌──────────┐  │  │ │                 │ │    ┌────────────┐\n │ send_msg ├──┼──┼─► builtin message ├─┼────► handle_msg │\n └──────────┘  │  │ │                 │ │    └────────────┘\n               │  │ └─────────────────┘ │\n               │  │                     │\n               │  │ ┌─────────────────┐ │\n               └──┼─►     BOUNDARY    │ │\n                  │ └─────────────────┘ │\n                  │     .........       │\n                  └─────────────────────┘\n","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Messages are serialized into a reader steam seperated by a collection of constant bytes (MSG_BOUNDARY). Each message has two parts, a header and a message body. In Distributed.jl, several predefined types of messages are provided. Each message then be deserialized and dispatched to a specific handle_msg implementation. Each header has exactly two fields, the response_oid and notify_oid. Now we are going to study two key concepts in Distributed.jl: remote call and remote reference.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#3.1-Remote-reference","page":"A Deep Dive into Distributed.jl","title":"3.1 Remote reference","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"In Distributed.jl, each worker has a unique id (myid()). To locate objects created by Distributed.jl, each of them will also have a unique id in that processor.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"As you can see, by default the id is auto-increment. And the whence is set to the current worker. Remember that each AbstractRemoteRef instance must at least contain these two basic id to locate it.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Future","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"A Future is an abstract container of a remote object (it can also reside in the current processor). Beyond the whence and id, it has two extra fields. The where indicates where the underlying value v is stored. Understanding the difference between where and whence is crucial. Let's say we're on worker 1 and would like to do a simple calculation of 1+1 on worker 2. Without the where field, we have to first send the remote calculation message to worker 2. Then the worker create a unique RRID and return it to worker 1. And when we want to fetch the calculation result v, we have to send the fetch command to worker 2 again and wait until the calculation is done and passed the result back to worker 1.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"\n                                timeline\n\n                                    │\n ┌───────────────────────────────┐  │  ┌────────────────────────────────┐\n │ worker 1                      │  │  │                        worker 2│\n │                               │  │  │                                │\n │          remotecall F: 1 + 1 ─┼──┼──┤►                               │\n │                               │  │  │  create a unique remote ref: R │\n │                waiting......  │  │  │                                │\n │                              ◄├──┼──┼─ pass back R                   │\n │        remote_ref R received  │  │  │                                │\n │                               │  │  │  do the calculation of F       │\n │    do some other calculation  │  │  │                                │\n │                               │  │  │  ......                        │\n │                       ......  │  │  │                                │\n │                               │  │  │                                │\n │ fetch result from remote_ref ─┼──┼──┤► wait F finish                 │\n │                               │  │  │                                │\n │                               │  │  │  ......                        │\n │                waiting......  │  │  │                                │\n │                              ◄├──┼──┼─ send back result              │\n │          remote value cached  │  │  │                                │\n │                               │  │  │                                │\n └───────────────────────────────┘  │  └────────────────────────────────┘\n                                    ▼","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"But if we have a where field to record where the calculation happens, then the first round could be reduced.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"                              timeline\n\n                                  │\n ┌─────────────────────────────┐  │  ┌───────────────────┐\n │  worker 1                   │  │  │          worker 2 │\n │                             │  │  │                   │\n │       create remote call F ─┼──┼──┤► received F & R   │\n │           and remote ref R  │  │  │                   │\n │                             │  │  │  do calculation   │\n │  do some other calculation  │  │  │                   │\n │                             │  │  │  ......           │\n │                     ......  │  │  │                   │\n │                             │  │  │                   │\n │  fetch reult from where(R) ─┼──┼──┤► wait F finish    │\n │                             │  │  │                   │\n │                             │  │  │  ......           │\n │              waiting......  │  │  │                   │\n │                            ◄├──┼──┼─ send back result │\n │        remote value cached  │  │  │                   │\n └─────────────────────────────┘  │  └───────────────────┘\n                                  ▼","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"RemoteChannel is similar, except that the underlying value can not be copied back and forth. We can only check whether it is ready and take! elements from it.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#3.2-Remote-call","page":"A Deep Dive into Distributed.jl","title":"3.2 Remote call","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Now let's examine what's happening in the following simple code:","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"using Distributed\n\naddprocs(2)\n\nx = @spawnat 2 begin\n    sleep(3)\n    rand(3)\nend\n\nprint(x[])","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"First, we create a worker with addprocs(2). Then we try to create a remote call which simply returns a random vector. The @spawnat macro will wrap the following expression into a parameterless function (usually known as a thunk) and turn it into a remotecall. In remotecall, a Future is first created to store the result in the future. Then the whence and id info of the future is extracted to form the message header (a RRID). The thunk is wrapped in a specific CallMsg and forms the message body. The whole message is serialized and written to the worker's r_stream. Note that the remotecall is async, so you can work on some other stuff and fetch the result later. On the worker side, once received a new message, it is deserialized and dispatched to the corresponding handle_msg call. For CallMsg, it will create a temp Channel(1) to store the result and associate it with the RRID in its global client_refs. Now when we try to fetch the result with x[], it will send another message of remotecall_fetch with a dedicated function fetch_ref and wait for the response. Once it receives the result. It will be cached in its :v field, so that future fetch calls will not do the remote call again.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"The following up question is, what about the original data on worker 2? Since now we have fetched and cached the value, we won't need it anymore.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Actually we can't remove it from worker 2 directly. Let's say we send the future x to another worker 3 before it fetches the result. If the result is removed from worker 2 immediately in respond to the fetch operation on worker 1. Then the worker 3 will never get the chance to fetch the result. But we still need to remove it sometime, right? Otherwise the memory usage will keep growing. In fact, the worker where the data of the Future resides will keep track of the connected workers of this Future. Everytime the GC hapens with a Future, we'll try to delete itself from the connected clients. And when no connected clients left, we're safe to remove it from client_refs.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Note that some expresions can't be executed through @spawnat (for example using SomePackage). That's why we have several different message types and handle_msg implementations. But the whole pipeline is almost the same.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#3.3-WorkerPool-and-pmap","page":"A Deep Dive into Distributed.jl","title":"3.3 WorkerPool and pmap","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"With the knowledge above, now we know how the Distributed.jl works. But still it is not very easy to use since we have to deal with the worker id directly. That's why WorkerPool and pmap are provided. pmap tries to divide the workload first and the worker pool can help to leverage computing resource more efficiently. This part is relatively easy to read and understand.","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/#Is-Distributed.jl-perfect?","page":"A Deep Dive into Distributed.jl","title":"Is Distributed.jl perfect?","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"Well, the standard answer is, there's no perfect design, only traceoffs. In my opinion, Distributed.jl is designed for HPC environments, where all the workers are quite stable. All the functionalities it provides are very fundamental and do not feature usability that much. On top of it, there's a Dagger.jl which is more usable for dynamic graph computing. And I'm also considering implementing a more flexible one. Stay tuned!","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/","page":"A Deep Dive into Distributed.jl","title":"A Deep Dive into Distributed.jl","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"keywords: Book CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#*Computer-Age-Statistical-Inference*-读书笔记","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"从MS Library借的这本书，两个作者都很给力，Trevor是ESL的合作者之一，Bradley是bootstrap的inventor。这本书是按照时间顺序展开的，读完有利于对过去几十年里统计推断的一些发展有个更清晰的脉络。这里随手记点笔记。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这本书有对应的网站，可以在上面查看电子版，数据集以及讨论等（评论用的disqus，所以需要翻墙的）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"前言里有句话挺有意思：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"Very broadly speaking, algorithms are what statisticians do while inference says why they do them.","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch1-Algorithms-and-Inference","page":"Computer Age Statistical Inference 读书笔记","title":"Ch1 Algorithms and Inference","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"书中举了个回归的例子，先用线性回归拟合了年龄与肾脏Tot指数之间的关系。顺便复习下标准差的计算：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\sigma{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}                \\approx \\sqrt{\\frac {\\sum{i=1}^{n} (x_i - \\bar{x})^2} {n(n-1)} } \\end{equation} \\label{se} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"上式中，sigma是整体的标准差，这里用样本的标准差来近似。关于如何计算线性估计的置信区间，可以看看Simplelinearregression，以及Standard Errors for Regression Equations.pdf。下面我用Julialang复现了下图一。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"using CSV\nusing Plots\nusing StatPlots\nusing DataFrames\nusing GLM\n\ngr()\ncd(raw\"D:\\workspace\\github\\blog-py\\blog\\static\\essay_resources\\Notes_on_Computer_Age_Statistical_Inference\") \n\nkidney = CSV.read(\"kidney.csv\", nullable=false)\n@df kidney scatter(:age, :Tot)\n\nX = hcat(ones(nrow(kidney)), kidney[:age])\ny = kidney[:Tot]\nOLS = fit(LinearModel, X, y)\n# GLM.LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,Base.LinAlg.Cholesky{Float64,Array{Float64,2}}}}:\n\n# Coefficients:\n#        Estimate Std.Error  t value Pr(>|t|)\n# x1      2.86067  0.359561  7.95603   <1e-12\n# x2   -0.0786009 0.0090557 -8.67972   <1e-14\n\nage_samples = collect(20:10:90)\nXtest = hcat(ones(length(age_samples)), age_samples)\npred = predict(OLS, Xtest, :confint)\n\nfor i in 1:size(pred, 1)\n    y_pred, y_lower, y_upper = pred[i, :]\n    display(plot!([age_samples[i],age_samples[i]], [ y_lower, y_upper], linewidth = 3))\nend\n\nplot!(age_samples[[1, end]], pred[[1, end], 1], legend=:none, linewidth=3)\nsavefig(\"Figure_1_1.png\")","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"(Image: Figure_1_1)","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"此外书中还用lowess和bootstrap方法拟合了该数据集，暂时对这二者不太熟，后面深入学习了再试着复现下。另外，Julia中的GLM这个库，感觉还是不够完善，对DataFrame的支持不是特别好，跟R语言是没法比的了，不过也还凑合，等我多一些Julia经验了去完善下。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"第二个例子是假设检验。首先选取了两种白血病人中第136号基因的活跃性作为对比，根据t检验的结果，按照一般的理解，应该得出0.0036的显著性假设（即该基因的活跃性有很大的区分度）。然而，该基因只是7128个基因指标中的一个，这又让该结果显得不那么令人感到惊讶，于是捎带引出了false-discovery-rate的概念。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"我的理解是，作者在第一章用这两个例子是想让读者理解Statistical Inference的概念。比如，第一个回归的例子中，用线性回归（或者其它多项式回归）来拟合观测数据（即Algorithm），然后再用Standard Error（或者lowess,bootstrap standard error等）衡量误差（即Inference）；第二个例子中，用t检验来检测Null Hypothesis，然后再用false-discovery-rate来衡量假设检验的结果。书中提到，这就有点像Tukey提出的explanation-confirmation系统，当然，作者认为如今Algorithm和Inference的概念要远比这二者更广泛。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch2-Frequentist-Inference","page":"Computer Age Statistical Inference 读书笔记","title":"Ch2 Frequentist Inference","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"假设我们观测到了211个肾脏病人的gfr（glomerular filtrate rate 肾小球过滤率）指标 boldsymbolx = (x_1 x_2  x_n)，该指标在所有肾脏病人中的分布为F（该分布是未知的），那么boldsymbolX = (X_1 X_2X_n)可以看作是n次从F中独立采样的结果，记作：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} F \\rightarrow \\boldsymbol{X} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"然后，假设我们想要得到的是从F中每一次随机采样的期望（注意下面式中的X不是粗体的），即：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\theta = E_F {X } \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"因此，需要根据已有的观测数据boldsymbolx估计出theta，","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\hat{\\theta} = t(\\boldsymbol{x}) \\end{equation} \\label{2.4} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"接下来很关键的一点，理解原书中的公式(2.5)，即：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\hat{\\Theta} = t(\\boldsymbol{X}) \\end{equation} \\label{2.5} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"eqref24","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"和eqref25的联系在于boldsymbolx可以看作是boldsymbolX的一个sample，因而theta也可以看作是Theta的一个实例。这样，频率学派的Inference可以定义为:","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"The accuracy of an observed estimate hattheta = t(boldsymbolx) is the probabilistic accuracy of hatTheta = t(boldsymbolX) as an estimator of theta（这句话有点绕，好难翻译，先贴个原文）","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"通常我们关心bias和variance，即：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\mu = E_F{\\hat{\\Theta}} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\mathrm{bias} = \\mu - \\theta \\quad \\mathrm{and} \\quad \\mathrm{var} = E_F{(\\hat{\\Theta} - \\mu )^2} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"实际使用中，通常会有一些折中手段，最常见的就是直接plug-in(其实就是eqrefse中的近似处理)","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} se(\\bar{X}) = [\\mathrm{var}_F(X) / n]^{1/2} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"其中mathrmvar_F(X)可以根据观测样本boldsymbolx来估计：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\hat{\\mathrm{var}}F = \\sum (xi - \\bar{x})^2 / (n-1) \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"所谓的plug-in就是直接用hatmathrmvar_F(X)去替换mathrmvar_F(X)。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"其它的几种做法在后面章节会有提及（重点看下pivotal statistics，比较另类）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"Ch2.2部分提到的likelihood ratio的思想似乎在其它地方见到过。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch3-Bayesian-Inference","page":"Computer Age Statistical Inference 读书笔记","title":"Ch3 Bayesian Inference","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"理解贝叶斯推断和频率学推断之间关系的关键在这章：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\mathcal{F} = { f_{\\mu}(x);\\ x \\in \\mathcal{X}, \\mu \\in \\Omega} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这里x是采样空间mathcalX中的一个样本（可能是一维的，也可能是多维的），而参数mu是参数空间Omega中的一个采样。书中举了两个f的例子（正态分布和泊松分布）来解释mathcalX和Omega的具体含义，这里不赘述。在频率学派中，mu是固定的，我们希望通过观测值得到其估计并推断出误差，而在贝叶斯推断中，mu是服从某种概率分布的，其先验为g(mu)，我们希望推断出g(mux)的分布。根据贝叶斯定理可以得出：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} g(\\mu|x) = g(\\mu) f_{\\mu}(x) / f(x), \\qquad \\mu \\in \\Omega \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这里f(x)是mu在Omega下的边缘分布。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"3.2部分有意思的是第二个example，作者用心良苦，引出了均匀先验、Jeffrey先验和Triangle先验。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"3.4部分对二者做了完整的比较，对于低维参数，下图非常形象（对于高维情况有所不同，书中有阐述）：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"(Image: )","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch4-Fisherian-Inference-and-Maximum-Likelihood-Estimation","page":"Computer Age Statistical Inference 读书笔记","title":"Ch4 Fisherian Inference and Maximum Likelihood Estimation","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"似乎，MLE刚出来的时候并不太受待见（计算太复杂）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"Fisher Information的核心是log似然相对于x微分的variance，这部分的推导以前没接触过，只是粗略知道说，MLE估计附近近似服从hattheta sim mathcalN(theta sigma^2n)。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"放在这一章介绍Fisher Inference，是因为它有点介于贝叶斯和频率派分析之间，用的是频率派的那一套，不过分析的是MLE。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这一章里还提到了Cramer–Rao lower bound，后面再回过头来详细讲讲这个。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch5-Parametric-Models-and-Exponential-Families","page":"Computer Age Statistical Inference 读书笔记","title":"Ch5 Parametric Models and Exponential Families","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这一章容纳的知识点有点多。目前为止所接触到模型的参数维度都还较低（不超过20维），与之对应的一个概念是非参数（nonparametric）。早期之所以青睐这类参数模型在数学上处理起来方便（mathematical tractability）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"首先介绍了一些常见的分布（Normal、Poisson、Binomial、Gamma、Beta），这里需要对这类分布之间的关系有个基本的熟悉，然后是多元正态分布的一些性质。比较重要的是式子（5.16），（5.17）和（5.18），多元正态分布可以被拆解，由此也引出了后面5.3节多参分布簇的Fisher's Information Bound，中间的推导有点复杂，不过最后的结论很重要（在其他地方有读到过），MLEmu_1的variance总是随着冗余参数的增加而上升的，这就导致最大似然以及其它近似无偏估计的方法都会过度关注“其它”参数（就是建模过程中必要但非我们关心的参数），而如今的应用都包含上千个这类参数，因而某些情况下，有偏估计反而更合适。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"此外，（5.21）的结论在后面也有用到，即mu根据观测值x得到的后验分布也是正态分布(其均值和方差的性质在第7章有用到)：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\mu| x \\sim \\mathcal{N} \\left(M + \\frac{A}{A + \\sigma^2}(x-M), \\frac{A\\sigma^2}{A + \\sigma^2}\\right) \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"5.4节将多项分布与单纯形（Simplex）以及泊松分布之间的联系描述得很清楚。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"Nonparametrics, and the multinomial, have played a larger role in the modern environment of large, difficult to model, data sets","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"没太理解5.4节结尾这句话，留着回头再看看。最后5.5节以泊松分布为例，将前面的那些分布上升到了指数簇的一般形式，这部分深究起来，还需要补许多知识点。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch6-Empirical-Bayes","page":"Computer Age Statistical Inference 读书笔记","title":"Ch6 Empirical Bayes","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"6.1中的例子很巧妙，Robbins' Formula，借用泊松分布的性质，在计算边缘分布的时候将先验消去了，然后根据样本估计得出参数期望的估计。这里稍微展开讲下，6.2也会用到。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"某一年中，欧洲的一家汽车保险公司有9461个投保人，其中7840人没有发生索赔，1317人有1起索赔，239人有2起索赔...(如下图所示)","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"(Image: Counts of Claims)","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"假设每个投保人在一年中索赔的次数服从以下泊松分布：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} Pr{xk = x} = p{\\thetak}(x) = e^{-\\thetak}\\theta^xk / x! \\label{61} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"其中，theta_k是x_k的期望（回顾下泊松分布的性质）。假设我们已经知道了theta的先验分布g(theta)，根据贝叶斯定理：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} E{\\theta | x }= \\frac{\\int^\\infty0 \\theta p\\theta (x) g(\\theta) \\ d\\theta}{\\int^\\infty0 p\\theta (x) g(\\theta) \\ d\\theta} \\label{6_2} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"然后，将eqref6_1带入eqref6_2中，就得到了下式：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} E{\\theta | x} = (x+1) f(x+1) / f(x) \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"其中边缘分布f(x)为：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} f(x) = \\int^\\infty0 p\\theta(x) g(\\theta) \\ d\\theta = \\int^\\infty_0 \\left[e^{-\\theta} \\theta^x / x! \\right] g(\\theta) \\ d\\theta \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这里用x在样本中的比例来作为f(x)的估计值：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\hat{f}(x) = yx / N, \\quad \\mathrm{with} \\ N = \\sumx y_x \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这样在不知道先验分布的情况下也完成了估计。6.2中的例子思想有点类似，但是感觉技巧性更强点......求期望的时候做了个指数展开。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"6.3中用一个完整的例子阐述了如何估计先验分布的参数，作者在这里是想强调21世纪以来，统计学的一些变化（逐渐在接纳indirect evidence）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch7-James-Stein-Estimation-and-Ridge-Regression","page":"Computer Age Statistical Inference 读书笔记","title":"Ch7 James-Stein Estimation and Ridge Regression","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这章花了不少时间来理解，仍然有许多细节没捋清楚，先记下些要点。借助第五章的内容，先得出了boldsymbolhatmu ^ Bayes与boldsymbolhatmu ^ MLE的均方差期望之间相差一个系数B，其估计值为：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\hat{B} = 1 - (N - 3) / S \\qquad \\left[S= \\sum^N_{i=1} (x - \\bar{x})^2 \\right] \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"然后boldsymbolhatmu^JS是boldsymbolhatmu^Bayes的一个plug-in，那么，当N gt 3的时候，boldsymbolhatmu^JS的risk更低（即所谓的shrinkage）。当然，根据James–Stein Theorem，该性质其实不受先验分布假设的影响。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"7.2部分用一个实际的例子，阐述了James-Stein的over-shrinking特性。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"(Image: Figure_7_1)","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"7.3是熟悉的Ridge Regression，参数lambda会对稀疏化程度有影响。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"(Image: Figure_7_2)","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"有点相当于给beta增加在0附近的先验(当然也有许多其他解释，书中提了下就一笔带过了）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"7.4对一类Corner Case做了解释和说明，尽管risk降低了，但是毕竟是有偏估计（这在某些情况下是不能接受的）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch8-Generalized-Linear-Models-and-Regression-Trees","page":"Computer Age Statistical Inference 读书笔记","title":"Ch8 Generalized Linear Models and Regression Trees","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"略过，GLM相关的内容此处讲得很简略，有其它书讲得更细致。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch9-Survival-Analysis-and-the-EM-Algorithm","page":"Computer Age Statistical Inference 读书笔记","title":"Ch9 Survival Analysis and the EM Algorithm","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"略过，这部分内容不是特别感兴趣。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch10-The-Jackknife-and-the-Bootstrap","page":"Computer Age Statistical Inference 读书笔记","title":"Ch10 The Jackknife and the Bootstrap","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"在有计算机之前，泰勒展开几乎是计算一些复杂指标的唯一方法。jackknife是1957年提出的，而bootstrap则是1979年。jackknife的思想很简单，但不得不佩服其开创性，从形式上有点像留一交叉验证(LOOCV)：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\hat{se}{jack} = \\left[ \\frac{n-1}{n} \\sum1^n \\left( \\hat{\\theta}{(i)}  - \\hat{\\theta}{(.) }\\right)^2 \\right] ^{1/2} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"其中hattheta_(i)是去掉样本x_i之后的估计， hattheta_()则是前者的平均：$ \\sum1^n \\hat{\\theta}{(i)} / n$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"Bootstrap则往前再迈了一步，原来hattheta的估计可以看作是分两步得到的：首先从概率分布F中得到样本boldsymbolx，然后根据某种计算方式s()得到估计值hattheta：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} F \\xrightarrow{\\text{iid}} \\boldsymbol{x} \\xrightarrow{s} \\hat{\\theta} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"而Bootstrap的做法则是，将F替换成了样本空间hatF，于是计算过程为：","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"$","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"\\begin{equation} \\hat{F} \\xrightarrow{\\text{iid}} \\boldsymbol{x^} \\xrightarrow{s} \\hat{\\theta}^ \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"关于bootstrap总结的部分，有意思的一点是，通常，B=200足够用来估计标准差hatse_boot，如果要计算bootstrap的置信区间，则可以需要1000或更多次的采样。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"10.3中的多种重采样方案是对前面用bootstrap估计标准差的一些扩展，与前面Simplex的思想进行了统一。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch11-Bootstrap-Confidence-Intervals","page":"Computer Age Statistical Inference 读书笔记","title":"Ch11 Bootstrap Confidence Intervals","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"如果分布近似正态分布，那么可以用经典的hattheta pm 196 hatse估计出95%区间，但对于有偏分布而言，如泊松分布，该估计并不准。这一章就是解释用Bootstrap估计置信区间的一些做法。Percentile的做法比较好理解，积分后利用transformation invariance特性，即可完成估计。后面Bias-Corrected方法理解不深。11.6提到了贝叶斯区间，大概是一般教科书中都有详细阐述，这里只是简单提及了下。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch12-Cross-Validation-and-C_p-Estimates-of-Prediction-Error","page":"Computer Age Statistical Inference 读书笔记","title":"Ch12 Cross-Validation and C_p Estimates of Prediction Error","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"虽然一直在实验里用CV，但是很少有了解过其细节，这一章对其演变历史有了很好地阐述。12.4部分阐述的现象在以前打比赛的时候经常碰到（时序预测问题中训练集/验证集划分的问题）。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"(Image: Figure_12_6)","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch13-Objective-Bayes-Inference-and-Markov-Chain-Monte-Carlo","page":"Computer Age Statistical Inference 读书笔记","title":"Ch13 Objective Bayes Inference and Markov Chain Monte Carlo","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"Ah, 终于到了贝叶斯推断。大多数内容在其它地方读到过，记下几点印象深刻的。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"Gibbs采样的做法是将其它变量积分掉了再采样，而MCMC的做法则是先随机候选样本然后决定接受或拒绝。想要详细了解恐怕这几页是不够的，不过这本书的好处就在于提供了很丰富的参考文献。","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"抽象出来看，Gibbs采样和MCMC的做法相当于是从参数空间Omega中采样得到了一个子空间A，然后替换掉贝叶斯公式中的边缘分布。（13.4有详细讲解）","category":"page"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/#Ch15-Ch21","page":"Computer Age Statistical Inference 读书笔记","title":"Ch15 ~ Ch21","text":"","category":"section"},{"location":"essays/Notes_on_Computer_Age_Statistical_Inference/","page":"Computer Age Statistical Inference 读书笔记","title":"Computer Age Statistical Inference 读书笔记","text":"这部分内容先不读了，几乎每一章都可以找本书来读，等以后有具体需要了再串起来读下。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"keywords: Julia,Python CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/From_Python_to_Julia/#写给Python用户的Julia编程指南[updating]","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"本文的目的是，为拥有Python编程经验的用户提供一些指引，方便其快速上手Julia。","category":"page"},{"location":"essays/From_Python_to_Julia/#准备","page":"写给Python用户的Julia编程指南[updating]","title":"准备","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/#下载和安装","page":"写给Python用户的Julia编程指南[updating]","title":"下载和安装","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"官网提供了各个系统下的安装包，不过我建议新手先安装Julia PRO，这个有点类似Python下的Anaconda，目前版本还没有1.0，这里以0.6.2为例，安装Julia的同时还会安装一些Julia下常见的包（省去了许多包管理麻烦，当然，也会带来一些新的小问题，这个碰到的时候再细说）。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"由于我日常开发在Windows下，所以以下内容中操作系统相关的部分都以Windows为主（Linux和Mac下要容易很多，应该问题不大）。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"安装后直接双击桌面的JuliaPro - Command Prompt 0621快捷键即可打开Julia的REPL界面，就跟IPython有点像（后面会详细介绍其与IPython的联系和区别），建议将JuliaPRO安装路径下Julia-062中的bin目录添加到环境变量Path中，这样可以直接在git-bash或者cmd中直接运行julia(如下图)。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"(Image: Julia_REPL)","category":"page"},{"location":"essays/From_Python_to_Julia/#Windows下开发学习的一点个人建议","page":"写给Python用户的Julia编程指南[updating]","title":"Windows下开发学习的一点个人建议","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"我个人对Windows的态度是不吹不黑，但老实说，Windows下开发的体验很差。强烈建议安装个Debian/Ubuntu的WSL，除了不能直接跟底层GPU打交道外，我目前的开发中没遇到什么大问题，日常一般是开了两个terminal，一个显示REPL，另一个在Debian中切到对应的目录下做文件读取和服务管理。","category":"page"},{"location":"essays/From_Python_to_Julia/#编辑器","page":"写给Python用户的Julia编程指南[updating]","title":"编辑器","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"一般Python的开发会选择PyCharm之类的IDE，不过Julia下还没有与PyCharm对应的IDE。安装JuliaPRO之后，桌面会有一个Juno for JuliaPro 0621，其实就是一个Atom上套了个插件，如果你原来就用Atom的话，也许你会喜欢这个编辑环境。我个人在Windows下倾向使用VSCode+Julia插件，不过社区里也有人用Vim和Emacs，选择一个适合你的就好。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"<div class=\"alert alert-warning\"> 使用VSCode的Julia插件的时候，需要配置(File -> Preferences -> Settings)julia的路径，如\"julia.executablePath\": \"D:\\workspace\\software\\JuliaPro-0.6.2.1\\Julia-0.6.2\\bin\\julia.exe\"。 </div>","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"当然，你一定注意到了桌面还有一个Jupyter 0621，其实就是Jupyter+IJulia的内核，如果你习惯Jupyter的话几乎可以做到无缝迁移。","category":"page"},{"location":"essays/From_Python_to_Julia/#REPL","page":"写给Python用户的Julia编程指南[updating]","title":"REPL","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"在IPython中，最常用的一个功能是查看函数的帮助文档，通过在函数/方法名后面加一个来实现，不过在Julia的REPL中，是先输入再输入函数名：","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"(Image: 使用？的例子)","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"另外，在IPython中，经常会执行一些类似ls,pwd等等系统命令，这类命令在Julia中是通过函数来实现的(如readdir(), pwd())。此外，原来的魔法函数也有对应的函数实现。不过如果是在REPL中，可以直接输入;进入shell模式，执行各种命令（自行对比iPython中加了!执行命令）。","category":"page"},{"location":"essays/From_Python_to_Julia/#包管理","page":"写给Python用户的Julia编程指南[updating]","title":"包管理","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"新版的Pkg管理模块比以前好用了很多，功能上有点像内置了一个pipenv。打开Julia的REPL后，按]进入Pkg管理模块，通过generate Foo即可新建一个Project，然后add Bar可以添加依赖，更多操作可以查看Pkg的Doc。","category":"page"},{"location":"essays/From_Python_to_Julia/#语法细节","page":"写给Python用户的Julia编程指南[updating]","title":"语法细节","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"下面从一些日常的操作来介绍如何从Python迁移到Julia。","category":"page"},{"location":"essays/From_Python_to_Julia/#代码结构","page":"写给Python用户的Julia编程指南[updating]","title":"代码结构","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"在Python中，代码是以目录结构组织起来的，然后用__init__py来区分包和普通的目录，Julia的代码以模块（Modules）组织起来的，一个典型的Julia文件有如下结构：","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"module MyModule\nusing Lib\n\nusing BigLib: thing1, thing2\n\nimport Base.show\n\nexport MyType, foo\n\nstruct MyType\n    x\nend\n\nbar(x) = 2x\nfoo(a::MyType) = bar(a.x) + 1\n\nshow(io::IO, a::MyType) = print(io, \"MyType $(a.x)\")\nend","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"首先，module定义了整个模块，其作用范围一直到最后一行end，module名称一般采用驼峰式，在module中也可以定义一个__init__函数，其功能有点类似Python下的__init__py文件（不完全对应，__init__py某种程度上提供了下面export的功能）。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"using Lib有点类似Python中的from xxx import *，此刻你脑海中想到的第一个问题应该是命名冲突！对，我一开始也这么想的，后来习惯了发现，好像问题不大，因为Julia是带类型的，一定程度上通过重载缓解了这个问题。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"using BigLib thing1 thing2就是显式地导入，类似from xxx import foo bar。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"个人感觉，Julia中import主要用于扩展某个函数的时候使用，这一点using做不到（using只用于提供查找变量的搜索空间）。~~importall就是import的扩展版~~(新版本中importall已废弃)。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"export则是，将该module内部的某些变量暴露出去。在Python中可能是通过__foo等来实现的。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"函数部分的区别和联系后面再详述。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"有时候，我们想直接从某个文件中导入，需要用include(foojl)来实现。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"有一个函数whos()可以用来查看当前的变量信息，有点像Python中的globals()。","category":"page"},{"location":"essays/From_Python_to_Julia/#数据结构","page":"写给Python用户的Julia编程指南[updating]","title":"数据结构","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/#index","page":"写给Python用户的Julia编程指南[updating]","title":"index","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"<div class=\"alert alert-danger\"> 在Julia中，按index访问访问元素的时候，是从1而不是0开始的。这大概是我自己从Python迁移到Julia最不习惯的一方面（一不小心就出错了）。访问最后一个元素要使用end关键字，有点像Python中的-1。另外，Julia中索引的时候，是左闭右闭的，不是Python中的左闭右开) </div>","category":"page"},{"location":"essays/From_Python_to_Julia/#string","page":"写给Python用户的Julia编程指南[updating]","title":"string","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"在Julia中，Char和String分别是用单引号和双引号初始化的，不能像Python中一样混用，三个双引号的用法是一致的。\n字符串的连接采用*符号，而不是+。\n字符串中支持变量替换，这个在Python3.6中有支持。二者只是表示上有所差别，Julia中是foo is 1 + 1，Python3.6中是ffoo is 1 + 1。\n前面你可能注意到了，Python中可以在string前增加f，r等实现某种特殊功能，在Julia中，可以自定义许多非标准的字符串解释器，这个很强大，谁用谁知道。\n读文件有一点稍稍不同，需要调用eachline函数，此外，Python中常常会用到的strip，Julia中对应的是chomp。","category":"page"},{"location":"essays/From_Python_to_Julia/#list","page":"写给Python用户的Julia编程指南[updating]","title":"list","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"Python中最常用的就是list了，Julia中并没有严格与之对应的数据结构，不过，就一般使用而言，可以把一维的ArrayAny1拿来用。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"push对应append，append对应extend方法，这里提一下，Julia还是函数式的风格，而Python中平常使用还是面向对象的风格为主。此外还有prepend等等对用的函数。\nPython中的list comprehension 一样可以使用，x * 2 for x in range(110) if x  3。我个人为了保持代码风格的一致性，习惯用map，filter处理。\nPython中list可以通过*来扩展，Julia中的Array并不能这样做（用repeat函数实现）。","category":"page"},{"location":"essays/From_Python_to_Julia/#Tuple","page":"写给Python用户的Julia编程指南[updating]","title":"Tuple","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"和Python中基本一致，~~未来也会~~目前支持类似Python3中的NamedTuple。","category":"page"},{"location":"essays/From_Python_to_Julia/#numpy","page":"写给Python用户的Julia编程指南[updating]","title":"numpy","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"这里单独说明下，Julia可以看作是自带了numpy的Python，Numpy的许多操作都能在标准库中Array部分找到。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"记录几个需要注意的点：","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"max和maximum的区别\n初始化矩阵的时候，julia中用来区分行\nnumpy中的数据类型一般通过dtype参数来指定（通过astype做类型转换），而Julia中，则是采用带参数类型函数来初始化（如ArrayT(mn)）\nJulia中，array的存储顺序是按照列存储的，因此对矩阵赋值的时候需要注意区别。A12 23 = 2 34 5和12 23 = 2 34 5的结果是有区别的。","category":"page"},{"location":"essays/From_Python_to_Julia/#iterator","page":"写给Python用户的Julia编程指南[updating]","title":"iterator","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"在python中经常会用到yield来生成迭代器，Julia中似乎没有找到对应的，我看到过一个相关的讨论，一定程度上可以用Channel来实现。但仍然有些繁琐，希望以后能支持。\nPython中有个itertools也经常用，这个在Julia中都是通过macro实现的，我个人感觉Lazy.jl基本够用，有些个性化需求的话，自己写一个也很方便。","category":"page"},{"location":"essays/From_Python_to_Julia/#struct","page":"写给Python用户的Julia编程指南[updating]","title":"struct","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"对比Python中的class","category":"page"},{"location":"essays/From_Python_to_Julia/#macro","page":"写给Python用户的Julia编程指南[updating]","title":"macro","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"这个先放这里，在Python中很少会接触，前期迁移到Julia中的时候，只需要掌握一些常用的宏就可以了。","category":"page"},{"location":"essays/From_Python_to_Julia/#Grammar","page":"写给Python用户的Julia编程指南[updating]","title":"Grammar","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"Julia中有些Python中没有的语法糖，个人感觉有些还算有意思，有些就比较累赘了。","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"do，这个没啥意思，就是把lambda搬了个位置\ncontrol flow上，因为没有了Python中的intent，需要用end来控制，虽然麻烦了点，但也可以理解。另外没有pass关键字。\nlet用于局部的变量重绑定，特定时候可以解决命名冲突问题，其实有很多方式绕开。有点怀念Clojure中的let","category":"page"},{"location":"essays/From_Python_to_Julia/#function","page":"写给Python用户的Julia编程指南[updating]","title":"function","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"如果不考虑类型的话，Julia下的function和Python相比，主要的差别是：","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"end作为结尾，默认返回最后一个表达式，基本不需要return语句\npositional，optional参数写法保持一致，keyword参数的写法用做了分隔，不过一般都这么写：\nfunction f(x; y=0, kwargs...)\n  ###\nend\n对于one-line definition，一般用f(x) = x的形式，如果一个表达式不够用，可以这样f(x) = (step1step2step3)。\nlambda函数的写法看起来更简洁点，x - x^x","category":"page"},{"location":"essays/From_Python_to_Julia/#operator","page":"写给Python用户的Julia编程指南[updating]","title":"operator","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"，向量化操作，起初觉得没啥意思，记得Clojure有个macro实现类似的语义，后来发现，这个点真心简洁\n+=，注意Julia中默认是immutable的，所以类似A += 3的操作其实是做了个rebinding\n,Python中会用*和**来对函数的参数解绑，在Julia是\n注意区分==和===，类比Python中的==和is","category":"page"},{"location":"essays/From_Python_to_Julia/#type","page":"写给Python用户的Julia编程指南[updating]","title":"type","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"这个应该是从Python转Julia最大的区别，没有捷径，好好阅读文档。这里我记下点自己觉得比较常用的几个知识点：","category":"page"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"typemax和typemin可以提供某些类型的取值范围(Int64,Float32等)","category":"page"},{"location":"essays/From_Python_to_Julia/#接下来？","page":"写给Python用户的Julia编程指南[updating]","title":"接下来？","text":"","category":"section"},{"location":"essays/From_Python_to_Julia/","page":"写给Python用户的Julia编程指南[updating]","title":"写给Python用户的Julia编程指南[updating]","text":"花点时间通读Julia Documentation。\n看看Introducing Julia这个wikibook，日常使用中的问题都可以在这里找到答案。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"keywords: Book CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#读书笔记【The-Senior-Software-Engineer】","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"图书馆意外翻到的一本书，读了读发现还挺有意思，随手写点读书笔记。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"关于 Senior，作者开篇就解释了，在大多数公司里，Senior区别于Junior，用来指代那些拥有更多决策权的员工。不过作者有意指出，题目中的Senior在我们这行一般是指工作了三年以上的人（从这个角度来说，我也勉强算是qualified的目标读者了......）。全书分十一章，阐述了作者18年来的一些工作心得，许多地方很有认同感，摘录下来，或许其他人读了也会有点收获？","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Focus-on-Delivering-Results","page":"读书笔记【The Senior Software Engineer】","title":"Focus on Delivering Results","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"这一章其实拆分成了3个部分：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Results\nFocus\nDelivering","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"首先是观念上的转变，作为SDE，一般认为产出就是代码，不过作者认为，产出一定是要体现商业价值：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"A result then, is an artivact of direct business value. Working code, documentation, and definitive statements are all results. Anything else must be understood as fundamentally different.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"然后是Focus，作者描述了工作中一个常见的场景：回邮件。阐述了为什么持续focus在当前的工作上要好于立即回复邮件（1. Distraction 2. We can forward to others 3. Keep promises to a minimum）。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"最后是 deliver smaller results more often，也是软件开发里常提到的一个概念，至于优点嘛：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"First, it turns a boring progress report into working, usable software. You won't have to merely tell the rest of the company how far along you are, you can show them. Secondly, promises of smaller value over shorter time are easier to keep. You are much more likely to accurately estimate one week's worth of work than you are one month's.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Fix-Bugs-Efficiently-and-Cleanly","page":"读书笔记【The Senior Software Engineer】","title":"Fix Bugs Efficiently and Cleanly","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"作者总结了自己修bug的一些best practice，我自认在工作中没这么规范的做过，但从心底还是认同书中提到的这个流程：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Understand the problem.\nWrite tests that fail (because the problem has yet to be solved).\nSolve the problem as quickly as you can, using your tests to know when you've solved it.\nModify your solution for readability, conciseness, and safety by suing your tests to make sure you haven't broken anything.\nCommit your changes.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"简单来说，就是test driven development 。核心思想就两点：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Thinking before coding\nSeparating \"getting it to work\" from \"doing it right\". It's hard to do both at the same time.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"自我反思下，大多时候只做到了\"getting it to work\"，尬。越是到了项目后期，\"doing it right\"的代价也越来越大。当然，也不能走极端了（Don't over-engineer and know when to quit），然后引用了《重构》中的一句话：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"[Refactoring is] restructuring an existing body of code, altering its internal structure without changing its external behavior.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"还有一点，记得及早commit，嗯，这一点感受还是很深的，不然，就等着哭去了......","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Add-New-Features-with-Ease","page":"读书笔记【The Senior Software Engineer】","title":"Add New Features with Ease","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"这部分内容中，自认为需要改进的应当是 Plan your implementation 这部分。列清楚 TODO list，找人交流讨论实现，然后预估每部分的大致时间。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Whatever you produce here is for your internal use only and is designed to capture your thinking at a high level about how to solve the problem and what bases need covering. Once you dive into the code, you will focus on much smaller concerns. Your \"plan\" here is for those moments when you get done with something and stick your head up to see where you are.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Deal-With-Technical-Debt-and-Slop","page":"读书笔记【The Senior Software Engineer】","title":"Deal With Technical Debt and Slop","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"第一次了解这个单词，Sloppy，不过，其描述的场景在工作中太常见了。复制，粘贴，再修修补补，Test全绿，Coverage蹭蹭涨，Well Done！不过，作为Senior的工程师，绝对不能ship这类代码。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"关于Technical Debt，书中的一个做法直接在comment里明确写出来了，感觉这个得有工具track，不然这些Debt大概率没机会偿还了......","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Play-Well-With-Others","page":"读书笔记【The Senior Software Engineer】","title":"Play Well With Others","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"这大概是Senior进阶路上最难的一步。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Translating your work to non-technical people is a skill that can be more valuable than any specific technical knowledge you have. It's what makes a senior developer in the eyes of others.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"作者的两个建议是：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Empathize with your audience.\nDistill what you know in a way your audience can understand.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"关于第二点，有一些更实际的建议：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Adapt Terms\nAvoid technical jargon of your own.\nListen carefully to the words people use and ask questions if you aren't 100% sure what they mean.\nDon't \"talk down\". The other person is likely a highly intelligent person who is capable of understanding what you're explaining. Treating them like a child will only make things worse. (这点确实在太常见了)\nDon't be afraid to use longer descriptive phrases in place of acronyms or other jargon.\nAbstract Cepts to Simplify Them\nAvoid technical details\nExplain things using analogies; don't worry about precision\nUse diagrams, visual aids, or demonstrations where possible.\nAlways offer to provide more details (这点已经听许多人说过了，挺受益的)\nIf a question has taken you off course, spend a few seconds re-establishing the context of your discussion. (这个需要反复练习，一是得清醒地意识到off course了，二是根据问题重新澄清讨论主题)\nBe prepared to \"justify\" your position if challenged.\n**Remember, it's not the other person's job to understand you, it's your job to make sure they understand.\nDon't be afraid to stop and re-group if things are going poorly. Find a colleague you trust or respect who can (or already does) understand the technical information in question and ask how they would handle it.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Make-Technical-Decisions","page":"读书笔记【The Senior Software Engineer】","title":"Make Technical Decisions","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"越往后走，就有越多（重要）的事情需要做决定，作者的建议是，从两方面出发，分别考虑：","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Identify Facts","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"注意区分 Facts 和 Opinions","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Identify Priorities","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"综合考虑多方的Priorities，自己的，整个team的，boss的等等","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"此外，注意区分fallicies （有意思的是，这里还提到了Clojure）。即使是一些非常聪明的人也会犯类似的错。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"If someone remains unconvinced by your arguments, rather than assume the person is \"not getting it\", take a moment to consider if your argument really is lacking. Give everyone the benefit of the doubt. Is there a fact you got wrong? A priority ou haven't identified? **Your mission isn't to prove that you are right, it's to deliver the best results you can **.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"还有一点非常值得学习：Document the decision-making process.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"A document like this is useful for two reasons. First, it can prevent someone else from going through the trouble that you've just gone through. Second, it keeps you from having to remember the details whe, sixmonths from now, a new team member asks why things are done a certain way.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Bootstrap-a-Greenfield-System","page":"读书笔记【The Senior Software Engineer】","title":"Bootstrap a Greenfield System","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"这部分涉及的内容反而在现有的项目里是做得比较好的一块（原因大概是，Dialog这块常做常新？）。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Learn-to-Write","page":"读书笔记【The Senior Software Engineer】","title":"Learn to Write","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"作者在这部分给出了许多关于写作的建议。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Three steps to better writing:","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Get it down","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"An outline, then each section.","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Revise it\nInstead of using demonstratives \"this\" and \"that\" or pronouns like \"it\" or \"they\", use the specific names of things, enven if it seems slightly redundant.\nName objects, concepts and procedures as specifically as you can.\nAvoid acronyms, shorthand, jargon unless you are absolutely sure the reader will understand it. (这个必须吐槽，OneNote上各种缩写满天飞)\nOrganize thoughts into paragraphs. (一段表达一个意思，避免所有内容都杂糅在一段里)\nWrite as if the readers are getting more and more rushed for time as they read. 尽量开门见山\nPolish it","category":"page"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"后面如何写Email和如何写技术文档可以单独找两本书来读了。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Interview-Potential-Co-Workers","page":"读书笔记【The Senior Software Engineer】","title":"Interview Potential Co-Workers","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"这部分可以跳过，帮助有限。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Be-Responsive-and-Productive","page":"读书笔记【The Senior Software Engineer】","title":"Be Responsive and Productive","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"Visibility 除了体现在代码上之外，还体现在 Responsiveness。学会处理各种interruption。","category":"page"},{"location":"essays/The_Senior_Software_Engineer/#Lead-the-Team","page":"读书笔记【The Senior Software Engineer】","title":"Lead the Team","text":"","category":"section"},{"location":"essays/The_Senior_Software_Engineer/","page":"读书笔记【The Senior Software Engineer】","title":"读书笔记【The Senior Software Engineer】","text":"这部分体会没那么深，可能，还没到这层境界？","category":"page"},{"location":"assets/revealjs/test/simple/#Slide-1.1","page":"-","title":"Slide 1.1","text":"","category":"section"},{"location":"assets/revealjs/test/simple/","page":"-","title":"-","text":"var a = 1;","category":"page"},{"location":"assets/revealjs/test/simple/#Slide-1.2","page":"-","title":"Slide 1.2","text":"","category":"section"},{"location":"assets/revealjs/test/simple/#Slide-2","page":"-","title":"Slide 2","text":"","category":"section"},{"location":"essays/Increase_Your_PPT_Skills/","page":"如何提高PPT的技巧","title":"如何提高PPT的技巧","text":"","category":"page"},{"location":"essays/Increase_Your_PPT_Skills/","page":"如何提高PPT的技巧","title":"如何提高PPT的技巧","text":"keywords: PPT, CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Increase_Your_PPT_Skills/#如何提高PPT的技巧","page":"如何提高PPT的技巧","title":"如何提高PPT的技巧","text":"","category":"section"},{"location":"essays/Increase_Your_PPT_Skills/","page":"如何提高PPT的技巧","title":"如何提高PPT的技巧","text":"随手记点做PPT的技巧","category":"page"},{"location":"essays/Increase_Your_PPT_Skills/#配色","page":"如何提高PPT的技巧","title":"配色","text":"","category":"section"},{"location":"essays/Increase_Your_PPT_Skills/","page":"如何提高PPT的技巧","title":"如何提高PPT的技巧","text":"(Image: CodeBlog_LanguagesXNLI_v2.png)","category":"page"},{"location":"essays/Increase_Your_PPT_Skills/","page":"如何提高PPT的技巧","title":"如何提高PPT的技巧","text":"这个表格的配色挺有意思。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"keywords: DeepLearning CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#Deep-Learning-相关库简介","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"本文将从deep learning 相关工具库的使用者角度来介绍下github上stars数排在前面的几个库（tensorflow, keras, torch, theano, skflow, lasagne, blocks)。由于我的主要研究内容为文本相关的工作，所以各个库的分析带有一定主观因素，以RNN模型为主，CNN相关的内容了解得不是特别深入（本文没有比较caffe和mxnet，其实主要原因还是自己C++太久没用了......）。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"阅读本文你会了解：","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"各个库是如何对神经网络中的结构和计算单元进行抽象的；\n如何用每个库跑RNN相关的模型；\n各个库学习和使用的难以程度对比；\n在各个库基础之上进一步改进和开发的难易程度；","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"本文不会涉及：","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"各个库运行时间效率的对比(我没有自己做过相关的对比实验，但是网上有很多数据可以查)；\nCNN相关模型的构建（前面提到了自己最近对这块了解得不多）；\nRNN相关模型的原理和解释（网上很多资料，可以先学习后再进一步阅读）；","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#先说说这几个库之间的大致关系","page":"Deep Learning 相关库简介","title":"先说说这几个库之间的大致关系","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"对于一个优秀的深度学习系统，或者更广来说优秀的科学计算系统，最重要的是编程接口的设计。他们都采用将一个领域特定语言(domain specific language)嵌入到一个主语言中。例如numpy将矩阵运算嵌入到python中。这类嵌入一般分为两种，其中一种嵌入的较浅，其中每个语句都按原来的意思执行，且通常采用命令式编程(imperative programming)，其中numpy和Torch就是属于这种。而另一种则用一种深的嵌入方式，提供一整套针对具体应用的迷你语言。这一种通常使用声明式语言(declarative programing)，既用户只需要声明要做什么，而具体执行则由系统完成。这类系统包括Caffe，theano和刚公布的TensorFlow。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"以上是摘自MXNet设计和实现中的一段话。理解了这段话后，对后面各个库的进一步理解很有帮助。MXNet的设计者表示融合了这两种编程模式，我们先抛开mxnet，如上所述torch是采用命令式编程，然后theano和tensorflow是采用声明式编程，skflow对常用的tensorflow的封装，lasagne是对theano的封装，blocks除了对theano进行封装之外还提供了额外的处理机制，keras则是用一套接口同时封装了theano和tensorflow。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#从theano说起","page":"Deep Learning 相关库简介","title":"从theano说起","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"前面说theano是声明式语言，其基本过程可以描述为以下几步：","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"定义输入变量(x,y)，输出变量(z);\n描述变量之间的计算关系(z = x + y);\n编译(f = theano.function([x, y], z);\n求值(f(1,2))；","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"那么，如果我想用theano写一个lstm呢？（具体参见这里)","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"准备输入变量x及xmask(维度为 batchsize * sentencelength * vectorsize)，目标变量target(维度为batch_size)\n定义并初始化lstm结构单元中的参数(i, f, o, c)\n定义好一个scan函数，在scan函数中完成每个结构单元的计算，根据lstm网络的性质，将结构单元的输出导入到下一步的输入。在这里，theano中的scan就是一个加强版的for循环\n计算loss，采用某种算法更新参数\n编译，f = theano.function([x, x_mask, target], loss)\n对每个batch求值","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"注意前面加黑的几个关键词，在后我们将反复看到每个库的设计者对这几个概念的不同理解。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#接着说tensorflow","page":"Deep Learning 相关库简介","title":"接着说tensorflow","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"tensorflow的设计思想和theano很接近。但是我感觉，tensorflow似乎更强调整体性和结构型。二者的明显区别在于：","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"tensorflow默认有一个Graph的结构，所有添加的结点都是在这个图结构上，但是theano中并没有这个概念。我的理解是这个Graph结构对于变量的管理会方便点。\ntensorflow目前能够在单机上多卡并行处理，其机制是通过指定gpu来分配计算过程的。因此，可以说其并行机制是数据层面的。而theano需要在载入包之前就指定gpu，","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"其余的很多地方都是相似的，只是换了名字而已，比如： tensorflow中的variable对应theano下的共享变量shared variables， tensorflow中的placeholder对应theano中的tensor变量， 另外tensorflow中为了避免变量的来回复制，其所用的tensor的概念和theano中不太一样","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"然后来看看tensorflow是怎么实现一个LSTM网络的，与theano不同，tensorflow已经对rnncell和lstmcell做了封装，因此写起来容易了很多。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"定义好输入及中间变量\n采用for循环将每个lstm_cell的输入输出组装起来\n剩下的也就没有新意了，计算loss，更新state","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"我们后面再讨论这种封装方式与其他库的对比。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#再说torch","page":"Deep Learning 相关库简介","title":"再说torch","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"torch的代码写起来有点像写matlab，本身torch是一个科学计算的大集合(我感觉只是借了lua这个语言一个外壳，方便和c及c++交互罢了，从这个角度来看，我觉得julia这门语言似乎大有潜力），这里我们主要是讨论其中的nn和rnn模块。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"我自己对lua及torch都不是很熟，但是好在语法不复杂，基本都能看懂，建议大家也能花点时间学习下，这样下次看到哪篇paper里实验部分用torch写的时候，不至于完全看不懂。尽管我对torch的了解不深，但是不得不说torch对剩下其它几个库的设计影响非常大！","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"在torch的nn模块里，首先对整个网络结构做了分类抽象。首先是最顶层的抽象Model，这个里面最基础的就是output和grad_output，记忆中和caffe的抽象是类似的，将计算结果和偏导结果用一个抽象类来表示了。然后是Sequential, Parallel 及 Concat这三个容器。Sequential用于描述网络中一层层的序列关系，典型的就是MLP，Parallel可以用于分别处理输入的不同维度，而Concat则可以用于合并操作。一般来说，我们现在的网络结构都可以通过这三种结构拼接得到。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"然后再看看torch的rnn模块中如何构建lstm网络的：","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"和tensorflow一样，首先是继承自AbstractRecurrent的一个抽象，然后是参数配置和初始化，不同之处在于，其对LSTM中的门结构也做了进一步抽象，最后，用Sequence代替了for循环的功能，从而提供一个完整的网络结构。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#小结","page":"Deep Learning 相关库简介","title":"小结","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"通过上面的简单描述，我们对这三个基本库有了些大致的印象。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"torch是最庞大的库，如果一开始就选择这个库作为工具的话，还算说得过去，否则学习的代价有点大，因为平常做实验涉及的往往不只是跑跑模型这么简单，还涉及到数据的预处理与分析，相关图表的绘制，对比实验等等。这样一来要学习的东西就比较多了。\ntheano由于借用了numpy，scipy等python下科学计算的库，相对torch来说要轻松一些。不过，theano本身并没有像其它两个库一样提供cnn，rnn等模型的抽象类，因此往往不会直接使用theano去写模型。\ntensorflow则更像是为神经网络相关模型而定制的。从顶层设计上就以graph为依托，通过不同的Session来控制计算流。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"从库的使用者角度来说，tensorflow和torch都还不错。但是，如果涉及网络结构（这里特指RNN相关的网络）修改，那么torch要相对容易一些，主要是多了一个Gate的抽象，中间参数的处理上不需要太操心，而tensorflow中LSTM和RNN抽象类的耦合比较紧，如果涉及内部结构的修改会稍稍麻烦点，需要重写的方法比较多。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"tensorflow开源时间不久，先抛开不计。由于theano缺少对神经网络结构的抽象，而torch中nn模块又设计得很合理，于是后面涌现的基于theano的库多多少少都有所参照。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#Keras","page":"Deep Learning 相关库简介","title":"Keras","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"keras设计的level有点高，其设想的就是底层的计算模块是可拔插的。这个功能当然看起来很炫酷，我想用tensorflow就用tensorflow，想用theano就用theano作为计算内核，然而代价也是有的，如果你想改其中的结构，复杂程度立马上去了。我觉得这个库的目标用户仅限于使用现有神经网络单元结构的人。如果你发现某个结构keras里没有？没事，这个项目开发者众多，发起个issue，马上就有人填坑（比如highway network, 我在其它几个库里还没发现，这里居然就有了，虽然并不复杂）。如果你想构造个自己的结构单元？那得了，您还是看看后面几个库吧。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"综上所述，keras最大的亮点就是，简洁而全面。正所谓人多力量大嘛！ 由于其底层处于兼容性做了一套自己的封装，想改的话稍显麻烦。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"如果你觉得看完keras还不知道怎么用？想来点更简单的？有！sklearn用过把，fit, predict两步即可，傻瓜式操作，人人都是机器学习大神。skflow就是类似的，看名字就知道了。不过是基于tensorflow开发的。我反正是没用过这个库......","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#Lasagne","page":"Deep Learning 相关库简介","title":"Lasagne","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"lasagne对网络结构的抽象和上面的几个库有很大的不同，在lasagne中基本抽象单元是Layer，对应到整个神经网络中的一层结构。这个layer可以是cnn也可以是rnn结构，除此之外还有一个MergeLayer，就是多输入多输出的结构。和torch一样，也对Gate门结构做了抽象。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"这样设计有好处也有麻烦的地方：","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"好处是，写出来的网络结构很简洁，网络结构的初始化和配置都包含在layer初始化参数里；\n不方便的地方是，只引入了layer结构抽象层，是在是有些单一，如果能再加一个类似torch中的Sequential结构就perfect了，因为一旦涉及到循环，就不得不回头去使用theano中的scan函数，说实话，scan函数设计得太复杂了点。（当然，作者是不这么认为的，设计者认为lasagne并不是要将theano完全隔离开，相反，lasagne中的所有变量都应该相对theano是透明的Transparency）。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"此外，lasagne中LSTM网络的实现与前面的大致相同，实现细节上，lasagne中的lstm类直接继承自MergeLayer，然后内部采用scan函数实现，像其它库由于有循环结构的抽象实现，因此每个lstm_cell类只需要完成单个结点内部的运算（也即只实现scan函数中的_step辅助函数）","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"总的感觉就是，lasagne在类的抽象上并没有过度设计，整个网络中的参数采用自顶向下的宽度优先算法获取，因此，只要你愿意，你可以任意在这个网络上“凿”个洞，得到该局部网络的关系。有一定的扩展性优势。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"##Blocks","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"这个库是我最看好的一个库，作者应该从torch中借鉴了很多思想。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"在这个库中，每一个运算都看做是一块砖，这块砖涉及配置、分配、应用和初始化这四步。更重要的一点是，brick与brick之间可以嵌套，从而得到更抽象的brick。这下子解决了我们前面一直碰到的一个问题，：抽象层次的把握！前面大多都是根据抽象层次的不同设计各自的类，而blocks通过嵌套将类统一起来，这样我们在设计自己的模块时，可以很方便地选取合适尺寸的brick。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"相比lasagne中直接根据layer.get_output来获取参数，blocks采用了ComputationGraph来管理整个网络结构，我的理解是，lasagne的那种方式还是有点野蛮......采用ComputationGraph之后，可以同时制定输入和输出对象，这样即使网络结构变得更复杂了，我们也可以随心所欲指定其中某个部分来更新。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"下面用blocks文档中关于rnn的一个模型来说明blocks在个性化定制方面是多么优雅。先看图：","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"(Image: An Introduction of RNN in BLOCKS)","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"如果要设计这样一个stack的模型，就需要make your hands dirty 了。在lasagne中，这个整体会被看做一个layer，所以需要自己重写一个layer，那跟直接用theano写无异了......keras中也没有提供现有的模型，所以......对于tensorflow和torch来说，需要重写AbstractRecurrent类，从而可以让其接受两个输入。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"相比之下Keras提供的解决方案就比较优雅，通过iterate将simplerecurrent在time_step维度上缩短到了1步，然后再将整个连接结构封装起来。（也许其它几个库也有类似的控制，暂时没发现）","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"当然，除了上面这些抽象层面的易用性，blocks还提供了丰富的可视化调试和控制接口，以及数据预处理的fuel模块。这些功能在整个工程变得越来越臃肿的时候还是很实用的。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/#总结","page":"Deep Learning 相关库简介","title":"总结","text":"","category":"section"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"在了解theano的基础上，如果只是想跑一下现有的模型不关注底层的实现，可以直接用Keras，上手快，模块清晰。如果打算持续投入，涉及大量网络结构改进，推荐使用bricks，其对训练过程的控制有着独特的优势。","category":"page"},{"location":"essays/Introduction_to_Deep_Learning_Libraries/","page":"Deep Learning 相关库简介","title":"Deep Learning 相关库简介","text":"另外需要注意的一点是，同样的数据，用不同库的同一个算法时，结果很可能会出现几个点的差异，这往往是不同库中对默认参数的初始化方式不同引起的，需要仔细检查下。","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"keywords: Algorithm CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/My_Interview_Questions/#我的面试题","page":"我的面试题","title":"我的面试题","text":"","category":"section"},{"location":"essays/My_Interview_Questions/#Update(20190918)","page":"我的面试题","title":"Update(20190918)","text":"","category":"section"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"面了一天，头都有点蒙了，","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"<hr>","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"最近在知乎的时间轴上总是出现面试相关的问题，忽然想到一个比较有意思的事情，不妨把我平时遇到的一些问题提炼出来，写一个面试题汇总，下次再有人砸简历过来的时候先扔过去自测下，哈哈哈~","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"计划先写10个问题，暂时没打算给出标准答案，但是会写出问题的来源、我的思考过程以及一些hint，内容会涉及方方面面。","category":"page"},{"location":"essays/My_Interview_Questions/#核心原则","page":"我的面试题","title":"核心原则","text":"","category":"section"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"~~来滴滴工作快一年了~~，关于公司文化，我印象最深刻的一点是：","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"招三年后能成为你上司的人","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"第一次看到这句话应该是在公司的洗手间。需要强调的是，这句话本身很值得玩味（刚去滴滴的时候恰好是四周年），成就他人，同时还要看到他人的增长潜力，对标自己现在的水平，以及目前自己上司的水平（技术/管理/沟通），呵呵，想出这句话来的人真有才。我个人对这个原则基本认同。","category":"page"},{"location":"essays/My_Interview_Questions/#那么，问题来了","page":"我的面试题","title":"那么，问题来了","text":"","category":"section"},{"location":"essays/My_Interview_Questions/#Q0:-你所掌握的语言是如何影响你的思维过程的？","page":"我的面试题","title":"Q0: 你所掌握的语言是如何影响你的思维过程的？","text":"","category":"section"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题来源：《程序开发心理学》第12章的思考题。","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题描述：大多数应聘的人都会在简历上描述自己掌握或者了解的编程语言都有哪些，有些人可能对某种语言的细节和各种奇技淫巧非常熟悉，有些人可能对各种工具库的使用情况了如指掌，不过，大多数人可能没有想过这些语言是如何影响我们的思维过程的。","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Hint: 每个人对这个问题的答案都不太一样，一方面是想从这个问题了解对方对于自己所掌握的语言的理解程度，从而对其编程能力有一个大致的预估；另一方面是了解对方的思维习惯和抽象能力，从而看出以后的工作中与此人共事是否愉快。对我自己而言，C中的指针（Reference）、Python中的Notebook（trial-and-error）、Clojure中的REPL和Macro（hot-fix，DRY等）是我一下子能想到的几点。","category":"page"},{"location":"essays/My_Interview_Questions/#Q1：概率","page":"我的面试题","title":"Q1：概率","text":"","category":"section"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题描述： 2M4. Suppose you have a deck with only three cards. Each card has two sides, and each side is either black or white. One card has two black sides.  e second card has one black and one white side.  e third card has two white sides. Now suppose all three cards are placed in a bag and shu ed. Someone reaches into the bag and pulls out a card and places it  at on a table. A black side is shown facing up, but you don’t know the color of the side facing down. Show that the probability that the other side is also black is 2/3. Use the counting method (Section 2 of the chapter) to approach this problem.  is means counting up the ways that each card could produce the observed data (a black side facing up on the table).","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"2M5. Now suppose there are four cards: B/B, B/W, W/W, and another B/B. Again suppose a card is drawn from the bag and a black side appears face up. Again calculate the probability that the other side is black.","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题来源：Statistical Rethinking一书第二章的习题","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Hint：这个问题很基础，但很有意思，与之相似的一个问题是“三门问题”。这个问题还可以从很多个角度去扩展，比如计算信息熵、交叉熵等，总的来说就是希望对方能够对先验、似然、后验等概念很熟悉。进一步，还会考察下宏平均、微平均、辛普森悖论，以及均值、中位数、众数等基础概念的理解，以确保日常的数据分析中不会犯一些常识性错误。","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题描述","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Simulation of a queuing problem: a clinic has three doctors. Patients come into the clinic at random, starting at 9 a.m., according to a Poisson process with time parameter 10 minutes: that is, the time after opening at which the first patient appears follows an exponential distribution with expectation 10 minutes and then, after each patient arrives, the waiting time until the next patient is independently exponentially distributed, also with expectation 10 minutes. When a patient arrives, he or she waits until a doctor is available. The amount of time spent by each doctor with each patient is a random variable, uniformly distributed between 5 and 20 minutes. The office stops admitting new patients at 4 p.m. and closes when the last patient is through with the doctor.","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"(a) Simulate this process once. How many patients came to the office? How many had to wait for a doctor? What was their average wait? When did the office close? (b) Simulate the process 100 times and estimate the median and 50% interval for each of the summaries in (a).","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题来源：Bayesian Data Analysis 3 ed. 第一章习题部分第9题","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Hint：这个问题之前似乎在某个面试题集锦中有看到过，能对结果做出解释就更好了。","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题描述：The question is to find the average number of rounds when playing the following game: P=6 players sitting in a circle each have B=3 coins and with probability 3⁻¹ they give one coin to their right or left side neighbour, or dump the coin to the centre. The game ends when all coins are in the centre.","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题来源：https://xianblog.wordpress.com/2017/12/29/cyclic-riddle/","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Hint:显然，如果只是简单地simulate一下，没有任何难度，难点在于，simulate之前，让面试者凭直觉猜，如何step-by-step地猜出结果，可以考验面试者的许多基础知识。（犹记得进微软面试的时候，shuneng问了我一个负泊松分布的问题，然而，当时还没读到《具体数学》里相关的部分，表现很糟糕:sweat:）","category":"page"},{"location":"essays/My_Interview_Questions/#Q2：Simulation","page":"我的面试题","title":"Q2：Simulation","text":"","category":"section"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题描述： ","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题来源：Mini Metro","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Hint：TODO","category":"page"},{"location":"essays/My_Interview_Questions/#Q3:-String","page":"我的面试题","title":"Q3: String","text":"","category":"section"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题描述：","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"给定一些模板（million级别，短文本），模板中某些词需要根据字典展开（thousand级别），然后根据在线的用户输入返回所有匹配到的substring。如果模板需要根据动态更新呢？","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题来源：","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"目前的chatbot在许多场景仍然需要根据规则匹配来实现特殊的功能，所以如何设计一个高效的匹配算法，至关重要。对于算法基础较好的人来说，能够比较容易解决这个问题。那么，进阶一点的，如何做billion级别的匹配和相似性计算。再复杂点，你会怎么设计General Entity Extraction？","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Hint：","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"考察多方面，Trie的应用，如何设计一个好的接口给别人调用，Aho-Corasick,理解faiss中的一些参数的含义，如何在实际业务中计算string的相似度。","category":"page"},{"location":"essays/My_Interview_Questions/#Q4:-Y-Combinator","page":"我的面试题","title":"Q4: Y Combinator","text":"","category":"section"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题描述:","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"给定2个函数，dec和zero?,如何不用递归实现is-even?和is-odd?？","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"问题来源:","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"EOPL Exercise 3.23, 3.24","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"Hint","category":"page"},{"location":"essays/My_Interview_Questions/","page":"我的面试题","title":"我的面试题","text":"目的主要是考察下思维切换的能力。如果能在给出Y Combinator的一般形式的情况下能写出来即可。当然，如果面试者对相关概念很熟，不妨再深入聊点进阶的话题。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"keywords: OCaml,DataStructure,FunctionalProgramming CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Notes_on_CS3110/#Why","page":"Why","title":"Why","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"最初看到[CS3110][]这门课也挺巧合的，之前写这个网站的时候，用到了clojure下的一个库[clojure.zip][]，然后知道其中的实现是根据[Functional Perl The Zipper][]这篇paper实现的，尝试去读这篇论文的时候，看到里面用的sample使用OCaml写的，里面的第一句话就是：","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"The main drawback to the purely applicative paradigm of programming is that","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"many efficient algorithms use destructive operations in data structures such as bit vectors or character arrays or other mutable hierarchical classification structures, which are not immediately modelled as purely applicative data structures. A well known solution to this problem is called functional arrays (Paulson, 1991)","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"然而，我连function arrays在这里是指什么都不知道，于是google了下，碰巧就看到了[CS3110][]这门课，初略看了下，感觉挺有意思的一门课，所以打算完整学习下，提升下自己对Functional Programming的理解。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"[CS3110]: http://www.cs.cornell.edu/courses/cs3110/2016fa/ [clojure.zip]: https://clojuredocs.org/clojure.zip [Functional Perl The Zipper]: https://www.st.cs.uni-saarland.de/edu/seminare/2005/advanced-fp/docs/huet-zipper.pdf","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-1","page":"Why","title":"LEC 1","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"这部分主要是关于FP的一些介绍，大部分内容在之前学习clojure的时候已经有所了解了，主要是关于immutability 和FP更elegant。有意思的是，在slides里看到了那句经典语句的出处：","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"“A language that doesn't affect the","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"way you think about programming is not worth knowing.”  – Alan J. Perlis ","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-2","page":"Why","title":"LEC 2","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"学习一门编程语言的5个方面：","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"Syntax\nSemantics\nIdioms  （个人感觉这一点需要在反复读别人代码的过程中加深体会）\nLibraries\nTools","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"有一个观点我觉得挺好，We dont complain about syntax，可能做研究的人更看重一门语言背后的思想，至于语法层面的东西反而不太care。不过咱大多数人都比价肤浅点，因而一门语言是否能被广泛推广的重要原因之一就是语法是否友好......","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"在OCaml中每一个expression包含了type-checking。这点是这节课终点介绍的内容，需要注意的是，function也是一种value，其对应的type则是由function的输入和输出的type共通构成的。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"后面的pipeline（即)与clojure中的-宏应该是一个意思。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"Every OCaml function takes exactly one argument.","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"这句话的意思应该是说，OCaml里的函数默认都是Currying了的。难怪在utop里打印出来的函数类型看起来都有点奇怪，一开始还很困惑如果返回值是函数的话为什么没有区分参数和返回值的类型。（今天看了个知乎的问题设计闭包（Closure）的初衷是为了解决什么问题？，又多了些理解。)","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-3","page":"Why","title":"LEC 3","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"这一课主要是list和模式匹配。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"这里list采用的语法糖来代替表示list的构建。需要注意的是，list成员的类型需要保持一致。在形式上与lisp中的list一致，不过在类型做出了限制。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"同样，由于类型系统的引入，pattern match的ei类型也需要保持一致。有意思的是，在这里做模式匹配的pattern不仅仅是类型的匹配，还把destruction解构的思想也引入了，从而可以做诸如abc的匹配。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"Listhd和Listtl分别对应first和rest（或者car,cdr），不过讲义里不建议用这个，更倾向模式匹配。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"另外讲义里还提到了尾递归（Tail Recursion），OCaml里是支持尾递归优化的。有兴趣的话可以深入了解下不同语言对尾递归优化的支持情况。","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-4","page":"Why","title":"LEC 4","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"let expression 是可以嵌套的。（感觉这写法有点蠢......） 不过这章的进阶版match介绍可以跟clojure中的解构匹敌了。加入类型后更复杂了。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"(p : t): a pattern with an explicit type annotation.","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"关于option，In Java, every object reference is implicitly an option.一句类比就解释清楚了。记得Scala中也有option，按照讲义中的解释，由于类型系统的存在，option能在一定程度上避免C/Java中不经检查使用空指针的问题。特地查了下，为啥clojure中没有类似的用法，了解下有助于理解不同语言的理念Why is the use of Maybe/Option not so pervasive in Clojure?。","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-5","page":"Why","title":"LEC 5","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/#LEC-5.1-type的基本理解","page":"Why","title":"LEC 5.1 type的基本理解","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"type的赋值应该可以理解为C中的typedef。这一章花了不少时间来消化（差不多5个上班前和下班后的时间），对type的认识稍微有些清晰了。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"在Python等语言里，抽象层次一般是从Object开始，然后是抽象类A，接下来各种类的继承。而在这一章的内容则是从底层的数据类型开始采用bottom-up的思想介绍type的。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"首先是最基础的int, float等类型，然后引入tuple后，有了int * int等类似的类型，不过这样的类型不太好描述，于是可以通过type对其重命名下type point = float * float，这类用法与以前对于type的理解一致。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"type的第二种用法是枚举，然而，这枚举有点不一样。课件里给了这样一个例子type day = Sun  Mon  Tue  Wed  Thu  Fri  Sat，课件里没提到的一点是，这里的枚举对象命名必须是大写开头的！而且这里的枚举对象并不是普通的int float等基本类型，应该把它当做一个独立的实体来看待。我一开始很难接受这样的定义，因为在Python语言里，Sun等必须是个变量要声明好，或者就直接是个string类型的基础变量，又或者像clojure一样独立出一个key这样的类型出来，否则很容易让人将这里的类型变量与普通的变量弄混。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"PS: 刚刚查看了下文档，看到大小写的变量名是有特殊意义的。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"Case modifications are meaningful in OCaml: in effect capitalized words are reserved for constructors and module names in OCaml; in contrast regular variables (functions or identifiers) must start by a lowercase letter","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"type的第三种用法是对第二种用法的扩展。将之前的枚举对象改成了构造器，type t = C1 of t1    Cn of tn讲义中的一个例子如下：","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"type point  = float * float\ntype shape =\n  | Point  of point\n  | Circle of point * float (* center and radius *)\n  | Rect   of point * point ","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"然后，可以传递构造器中指定类型的数据来得到对应类型的值，例如：","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"let p = Point (1. , 3.)\nlet c = Circle ((1., 2.), 3.)\nlet r = Rect ((-1., -2.), (1., 2.))","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"同时，上面的shape对象可以在类型匹配的过程中解构得到其中的基本元素，然后做相应的运算：","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"let pi = 4.0 *. atan 1.0\nlet area = function\n  | Point _ -> 0.0\n  | Circle (_,r) -> pi *. (r ** 2.0)\n  | Rect ((x1,y1),(x2,y2)) ->\n      let w = x2 -. x1 in\n      let h = y2 -. y1 in\n        w *. h\n        \nlet center = function\n  | Point p -> p\n  | Circle (p,_) -> p\n  | Rect ((x1,y1),(x2,y2)) ->\n      ((x2 +. x1) /. 2.0, \n       (y2 +. y1) /. 2.0)\n       \nlet area_of_p = area p\nlet center_of_r = center r","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-5.2-recursive-type","page":"Why","title":"LEC 5.2 recursive type","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"最典型的就是树结构的定义：","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"type node = {value:int; next:mylist}\nand mylist = Nil | Node of node","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-5.3-parameterized-variants","page":"Why","title":"LEC 5.3 parameterized variants","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"可以类比模板类，比如java中的ListInteger，只不过这里的语法有点不一样，类型是反过来了的，比如一个泛型的list是type a mylist =  Nil  Cons of a * a mylist这样定义的，对于一个具体的数据，前面代码中的a可以是任意实际的类型，比如int。let x = Cons (3 Cons (1 Nil))就是一个int mylist类型数据的实例。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"LEC 5 中的Natural numbers部分很有意思，以前看SICP的时候，对这个概念理解得不清楚，现在看了代码后又有了更深的理解。","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-6","page":"Why","title":"LEC 6","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"这部分主要是关于高阶函数的一些应用，理解起来应该难度不大，课后习题部分需要花点时间。有个需要注意的地方是fold_left与fold_right的区别。fold_left是可以做到尾递归优化的，而fold_right则不是，如果确实需要的话，需要把列表翻转后再使用fold_left。","category":"page"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"Pipeline的书写方式确实优雅一些，可能自己写代码的思维习惯还没有使用过来，感觉从右往左读代码也不是特别麻烦的一件事，只要有合适的缩进来表示。","category":"page"},{"location":"essays/Notes_on_CS3110/#LEC-7","page":"Why","title":"LEC 7","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"这部分主要是OCaml模块化的介绍，包的引入和抽象与其它语言是基本一致的，不同之处在于类型系统单独用一个接口文件来描述，有点像抽象类，但也不完全是。另外具体的实现文件并不是对应了以前Java中类的实现，反而是操作具体的数据。OCaml好像是有自己一套关于类的定义。","category":"page"},{"location":"essays/Notes_on_CS3110/#READING-LIST","page":"Why","title":"READING LIST","text":"","category":"section"},{"location":"essays/Notes_on_CS3110/","page":"Why","title":"Why","text":"Introduction to Objective Caml\nReal World OCaml","category":"page"},{"location":"blogroll.zh/#友链","page":"🔗 友链","title":"🔗 友链","text":"","category":"section"},{"location":"blogroll.zh/","page":"🔗 友链","title":"🔗 友链","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-16</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-08-16</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-12</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-08-12</text></g></svg></div>","category":"page"},{"location":"blogroll.zh/","page":"🔗 友链","title":"🔗 友链","text":"如果你觉得跟我志趣相投，欢迎点击右上角的 Edit on GitHub 发PR。","category":"page"},{"location":"blogroll.zh/#[laike9m](https://laike9m.com/)","page":"🔗 友链","title":"laike9m","text":"","category":"section"},{"location":"blogroll.zh/","page":"🔗 友链","title":"🔗 友链","text":"左兄写的文档是我等学习的典范~","category":"page"},{"location":"blogroll.zh/#[Ronnie-Wang](http://wattlebird.github.io/)","page":"🔗 友链","title":"Ronnie Wang","text":"","category":"section"},{"location":"blogroll.zh/","page":"🔗 友链","title":"🔗 友链","text":"在微软这边的同事，文如其人，非常有个性~","category":"page"},{"location":"blogroll.zh/#[Hongxu-Xu](https://xuhongxu.com)","page":"🔗 友链","title":"Hongxu Xu","text":"","category":"section"},{"location":"blogroll.zh/","page":"🔗 友链","title":"🔗 友链","text":"也是微软这边的同事，后生可畏，后生可畏啊！","category":"page"},{"location":"blogroll.zh/#[Roger-Luo](https://rogerluo.dev/)","page":"🔗 友链","title":"Roger Luo","text":"","category":"section"},{"location":"blogroll.zh/","page":"🔗 友链","title":"🔗 友链","text":"学习Julia语言过程中认识的，相当热心！","category":"page"},{"location":"blogroll.zh/#[pilgrim](https://pilgrimygy.github.io/)","page":"🔗 友链","title":"pilgrim","text":"","category":"section"},{"location":"blogroll.zh/","page":"🔗 友链","title":"🔗 友链","text":"在写ReinforcementLearning.jl过程中认识的，非常有潜力的小伙~","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"keywords: Life CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/A_Dream/#昨晚做了个梦","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"","category":"section"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"嗯，昨晚做了个梦。和往常许多的梦一样，这个梦本身没有任何特殊的地方，只是昨晚在梦中，忽然意思到自己在思考。","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"一般我醒来还记得的梦，都大致有那么一条故事线，尽管场景可能是各种混乱而复杂的交错。就拿昨晚的梦来说，其中一幕是拿着钱去小卖部里买东西，梦里似乎觉得路上不应该那么顺畅，于是路中间出现了一条沟，很泥泞，可是明明是晴天？不重要了，到了小卖部，敲门，那个小哥熟悉的面孔出现了，问要买什么，有那么一瞬间，梦境凝固了，因为我也不知道是来买什么的，只是要来买东西，谁让我来的？买什么？买完了要去哪？一无所知。BUT，我的潜意思似乎并不关心这些，它只关心这个梦必须继续进行下去，绝不允许卡壳。短暂的停顿之后，那个小哥叫了他姐姐出来帮忙，然后自己回卧室去了（似乎是忙着打游戏？），然后我被告知东西没有了（什么东西？），然后我就往回走了。","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"在梦里，大脑的计算量似乎很有限，无法完成许多复杂的因果关系推断，而且受到某种潜意识的压迫，还必须在有限的时间内做出快速响应，不过有些时候，潜意识似乎又很宽容，能让梦境多次被改写。","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"醒来之后，我一直在想一个问题，做梦的过程中，是否有思考的介入呢？","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"从形式上看，是我的脑海里首先有了个模糊的意识（要去买东西），然后大脑拼命从记忆深处抓取了各种各样的碎片拼凑在一起，而且，越是强相关的碎片，越是会被细化，而其它不甚相关的东西则随着时间推移被淡化了。等到这些似乎这些场景make sense了，空闲出来的大脑就开始做各种假设的合理性检验，将某些明显有bug的部分evict出去。接下来，受到最初的那个模糊意识的驱使，开始拼凑下一个画面。（感觉可以按照这个逻辑写个梦境生成的算法了，哈哈）","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"应该说，这其中唯一能体现所谓的思考的地方，也就是场景的合理性检验。假如未来，我们写了一个BOT，它也能像我做梦的时候一样，做出类似的假设检验与推断，那么它能否称得上是有思考的能力呢？（当然，前提是我能把自己的记忆dump出来喂给它）想想还是挺可怕的一件事，一方面，我们希望能有这样的BOT，辅助我们做出各种各样的design和trial，但另一方面，我们又感到恐惧，因为这意味着我们的思想逃逸了，没人能保证这个超出人脑之外的BOT完全受主体的控制。","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"以前要是有人跟我谈强人工智能，我只会嗤之以鼻（尽扯淡，看看现在的机器都能做啥？），不过现在有些动摇了，因为，我似乎觉得，人的思维从functionality的角度来讲，也许并不是特别复杂。","category":"page"},{"location":"essays/A_Dream/","page":"昨晚做了个梦","title":"昨晚做了个梦","text":"以上姑且当做扯淡好了，写出来只是觉得比较有意思，或许，有人跟我一样有过类似的感受？","category":"page"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"<p align=\"center\">   <a href=\"https://revealjs.com\">   <img src=\"https://hakim-static.s3.amazonaws.com/reveal-js/logo/v1/reveal-black-text-sticker.png\" alt=\"reveal.js\" width=\"450\">   </a>   <br><br>   <a href=\"https://github.com/hakimel/reveal.js/actions\"><img src=\"https://github.com/hakimel/reveal.js/workflows/tests/badge.svg\"></a>   <a href=\"https://slides.com/\"><img src=\"https://s3.amazonaws.com/static.slid.es/images/slides-github-banner-320x40.png?1\" alt=\"Slides\" width=\"160\" height=\"20\"></a> </p>","category":"page"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"reveal.js is an open source HTML presentation framework. It enables anyone with a web browser to create fully featured and beautiful presentations for free. Check out the live demo.","category":"page"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"The framework comes with a broad range of features including nested slides, Markdown support, Auto-Animate, PDF export, speaker notes, LaTeX typesetting, syntax highlighted code and much more.","category":"page"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"<h1>   <a href=\"https://revealjs.com/installation\" style=\"font-size: 3em;\">Get Started</a> </h1>","category":"page"},{"location":"assets/revealjs/README/#Documentation","page":"-","title":"Documentation","text":"","category":"section"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"The full reveal.js documentation is available at revealjs.com.","category":"page"},{"location":"assets/revealjs/README/#Online-Editor","page":"-","title":"Online Editor","text":"","category":"section"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"Want to create your presentation using a visual editor? Try the official reveal.js presentation platform for free at Slides.com. It's made by the same people behind reveal.js.","category":"page"},{"location":"assets/revealjs/README/#License","page":"-","title":"License","text":"","category":"section"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"MIT licensed","category":"page"},{"location":"assets/revealjs/README/","page":"-","title":"-","text":"Copyright (C) 2011-2021 Hakim El Hattab, https://hakim.se","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"keywords: Python CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#（6）一起用python之基础篇——数据结构","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"(撰写中。。。呃，写着写着，发觉其实原书写得很系统，一环扣一环，我这样子抽出来一点点地分析反而打乱了原有的结构。我这里写的，大致看下就好，不多说了，反正如果学习Python和数据结构的话，这本书非常非常推荐！）","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#写在前面","page":"（6）一起用python之基础篇——数据结构","title":"写在前面","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"本来，这部分计划在几个月前就完成的，无奈这中间忙其它事去了，断断续续地写了一点点。现在刚好闲下来了，争取正式在实验室开始干活之前把这部分写完。加油~","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"依照以往学习编程语言的经验，在熟悉了语言的基本语法和标准库的应用后，需要进一步深入到底层基本数据结构。一方面深入理解python中常用的数据类型是怎么实现的，另一方面通过自己实现这些基本数据结构来掌握python中类的写法。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"于是我大致找了一下python下数据结构方面的书，对比后发现Data Structures and Algorithms in Python这本书灰常好。其优点在于，非常适合本人的学习路线（粗略熟悉了python的使用，但是缺乏深入了解），而且本书的前面几章提供了很好的过渡。此外，对于各种类型的数据结构，作者都提供了完整的实现，可以说是学习的典范。当然，要说不足之处，就是最后图论部分内容稍微简略了一些。不过，考虑到本书已经七百多页，这部分从简是有道理的。个人觉得本书更侧重于数据结构部分，如果你只是想学习怎样用python实现基本的算法，可以参考这本书Python Algorithms - Mastering Basic Algorithms in the Python Language,胡家威同学写了个系列的，很值得一看http://hujiaweibujidao.github.io/python/。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#导读","page":"（6）一起用python之基础篇——数据结构","title":"导读","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"以下内容可以看做是Data Structures and Algorithms in Python这本书的导读。我会指出各章节中的一些亮点和核心内容。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch1 Python 基础知识","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"这部分对Python的基本语法做了一个简单的描述，主要目的是让本书的读者在一个相同的起跑线上，方便后面的内容展开。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch2 面向对象编程","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"首先谈到了面向对象的设计模式，然后以一个例子讲解了Python中如何定义一个类，以及类与类之间的继承关系。最后介绍了Python中类内的变量管理。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch3 算法分析基础","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"这部分几乎是算法书必备的内容。介绍如何分析算法的复杂度。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch4 递归","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"在开始讲数据结构之前，作者先介绍了一下递归的思想，个人感觉这个章节的安排稍微有些唐突，不过，也算是为后面做铺垫吧。作者对于递归的分类很有启发意义。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch5 基于Array的序列","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"忘掉Python下常用的list等等数据结构吧，作者先从最最基础的ctypes下的array结构开始构造类似于list的动态序列数据类型。这将为大家理解list类型奠定良好基础。C语言基础很好的话理解起来会很快。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch6 栈、队列与双向队列","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"作者从ADT（Abstract Data Type）出发，在前面实现的基于Array的序列基础上，实现了栈、队列、双向队列这三种数据结构。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch7 链表","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"该部分将前面已经实现的三种数据结构糅合在一起，在介绍了链表后，通过链表来实现上一章提到的集中数据结构。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch8 树","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"从树，再到二叉树，然后深入其中，借用Array序列和链表来实现树这个类。最后介绍了遍历树的简单算法。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch9 优先队列","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"同样，这部分先是介绍了优先队列后，分别用有序列表和无序列表实现了优先队列。然后由此引出了堆。再根据优先队列中的排序问题分别分析了选择排序、插入排序以及堆排序。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch10 Map、哈希表以及跳表","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"这部分内容的重点是介绍了Hash的思想。此外作者跳出Python下常用的字典类型，对Map进行了不同的分类并实现。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch11 搜索树","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"这部分内容主要围绕平衡树展开，介绍了AVL、红黑树等等。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch12 排序与选择","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"尽管前面已经提到了集中排序算法，这里作者补充了并排、快排以及桶排序等等算法并做了比较。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch13 文本处理","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"该部分主要是字符串查找的优化，重点分析了动态问题编程的思想。该部分还介绍了trie树（字典树）","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch14 图","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"该部分虽然简短，但覆盖面广，包含了图的结构、图的遍历、最短路径以及最小生成树等等。需要参考其他书作为补充。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"Ch15 内存管理与B树","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"介绍了Python中内存管理体系（内存分配，垃圾回收，缓存机制等等），并介绍了B树。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#Ch1-Python基础知识","page":"（6）一起用python之基础篇——数据结构","title":"Ch1 Python基础知识","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"这部分可以看做是个导读，都是一些比较基础的部分。在这里我指出几个需要格外注意的地方，算是备忘吧。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#\"\"操作对不同数据类型的影响-【16页】","page":"（6）一起用python之基础篇——数据结构","title":"\"+=\"操作对不同数据类型的影响 【16页】","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"对于list类型，+=操作相当于list的extend方法，","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"In [1]: a = [1,2]\n\nIn [2]: id(a)\nOut[2]: 139898553654536\n\nIn [3]: a += [3,4]\n\nIn [4]: id(a)\nOut[4]: 139898553654536\n\nIn [5]: a\nOut[5]: [1, 2, 3, 4]\n\nIn [6]: a.extend([5,6])\n\nIn [7]: a\nOut[7]: [1, 2, 3, 4, 5, 6]\n\nIn [8]: id(a)\nOut[8]: 139898553654536\n\nIn [27]: a = a + [7,8]\n\nIn [28]: a\nOut[28]: [1, 2, 3, 4, 5, 6, 7, 8]\n\nIn [29]: id(a)\nOut[29]: 139898553711688","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"如上所示,注意前面的+=操作和extend 对id(a)都没有影响,也就是说变量a的内存地址没有发生变化.但是=重新赋值时会重新开辟新的内存来存储新的数据.由此引出一个关于+=操作符的经典效率问题.","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"In [48]: %%timeit -n 100\n   ....: a = []\n   ....: for i in range(10 **3):\n   ....:     a = a + [i]\n   ....: \n100 loops, best of 3: 1.45 ms per loop\n\nIn [49]: %%timeit -n 100\n   ....: a = []\n   ....: for i in range(10 **3):\n   ....:     a += [i]\n   ....: \n100 loops, best of 3: 114 µs per loop","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"对于str这类immutable类型的变量, +=操作实际就是先对字符串拼接后再重新赋值.因而会涉及到重新分配存储空间的过程.","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"In [13]: s = 'ab'\n\nIn [14]: id(s)\nOut[14]: 139898582654064\n\nIn [15]: s += 'cd'\n\nIn [16]: s\nOut[16]: 'abcd'\n\nIn [17]: id(s)\nOut[17]: 139898553628352\n\n#对比下字符串类型 += 操作 和 = 操作的效率可以发现,二者差不多\n\n[56]: %%timeit\n   ....: a = ''\n   ....: for i in range(10 **3):\n   ....:     a = a + str(i)\n   ....: \n1000 loops, best of 3: 274 µs per loop\n\nIn [57]: %%timeit\n   ....: a = ''\n   ....: for i in range(10 **3):\n   ....:     a += str(i)\n   ....: \n1000 loops, best of 3: 273 µs per loop","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#迭代过程中改变原始数据-【39页】","page":"（6）一起用python之基础篇——数据结构","title":"迭代过程中改变原始数据 【39页】","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"这里只是简单的提到了一点,在for循环中改变list中的值时会对后面的循环过程有影响.举例来说:","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"In [5]: a = [0,1,2]\n\nIn [6]: for i,x in enumerate(a):\n    print('a before change: ', a)\n    print('i = ',i,'x = ', x)\n    a[(i+1)%len(a)] = -1\n    print('a after change: ', a)\n    print('--------------------------')\n    ...:     \n\na before change:  [0, 1, 2]\ni =  0 x =  0\na after change:  [0, -1, 2]\n--------------------------\na before change:  [0, -1, 2]\ni =  1 x =  -1\na after change:  [0, -1, -1]\n--------------------------\na before change:  [0, -1, -1]\ni =  2 x =  -1\na after change:  [-1, -1, -1]\n--------------------------","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"不过,除了更改之外,还有添加删除操作(如pop, remove, del等),但是,在这一点上,list和dict,set的表现很不一样.在遍历过程中,如果删除list的元素,并不会让遍历过程终止,删除某一元素后,后面的元素会向前移动并填补空缺(这在学习了ArrayBased Sequence后更容易理解),遍历的过程继续.如下所示:","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"In [10]: a = list(range(10))\n\nIn [11]: for x in a:\n   ....:     print(x, end=' ')\n   ....:     if x == 5:\n   ....:         a.remove(0)\n   ....:         \n0 1 2 3 4 5 7 8 9 ","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"但是,如果在遍历dict和set时删除了某些元素则会引发Runtime Error","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"In [15]: a = {1:1,2:2}\n\nIn [16]: for x in a:\n   ....:     a.pop(x)\n   ....:     \n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-16-c44bba0d19b6> in <module>()\n----> 1 for x in a:\n      2     a.pop(x)\n      3 \n\nRuntimeError: dictionary changed size during iteration","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"究其原因,可能是因为list结构采用的类似数组的实现方式,删除某一元素后,后面的元素可以对其填补.而set和dict采用的时链表一类的结构,删除某一元素后会导致结构不稳定(具体我还没找到).解决的办法一般时构造新的字典或者集合.","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"##Ch2","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#is关键字【76页】","page":"（6）一起用python之基础篇——数据结构","title":"is关键字【76页】","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"判断两个对象是否相同,一般有两种做法,a is b 和 a == b,这二者时有区别的. a is b用来判断两个变量是否绑定的同一个对象,而a == b则是调用两个变量的__eq__方法,根据具体的实现有不同的意义.比如下面的例子:","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":":::python\nIn [17]: a = [1,2,3]\n\nIn [18]: b = a\n\nIn [19]: c = a[:]\n\nIn [20]: a is b\nOut[20]: True\n\nIn [21]: a == b\nOut[21]: True\n\nIn [22]: a is c\nOut[22]: False\n\nIn [23]: a == c\nOut[23]: True","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"此外还有","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":":::python\nIn [24]: 0 == False\nOut[24]: True\n\nIn [25]: 0 is False\nOut[25]: False","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"也就是说, is 和 ==之间没有必然联系","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"最后还有个更奇葩的......","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":":::python\nIn [26]: a = 1\n\nIn [27]: b = 1\n\nIn [28]: a is b\nOut[28]: True\n\nIn [29]: a = 111111111111111111111111111111111111111111111\n\nIn [30]: b = 111111111111111111111111111111111111111111111\n\nIn [31]: a is b\nOut[31]: False\n\nIn [32]: a == b\nOut[32]: True","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"这一点在以前提到过,数字很小的1被缓存了,所以地址相同,从而当a和b都是1的时候,a is b 的值是 True","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#Ch4-递归","page":"（6）一起用python之基础篇——数据结构","title":"Ch4 递归","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"递归的核心就是3步.","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"判断终止条件\n计算具有共性的那部分\n收缩计算范围,使其趋于终止条件","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"在最后的部分([169页]),作者总结前面的递归例子后,将递归分这么三类,区别在于上面的第二步出现条件判断,从而发生多次回调行为:","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"线性递归(Linear recursion):最多只有一次函数回调\n二分递归(Binary recursion):函数体内部有两次回调\n多路递归(Multiple recursion):函数体内部有超过两次的回调","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"线性递归的最简单例子是,求阶乘以及求和等.例如:","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"def linear sum(S, n):\n    ”””Return the sum of the first n numbers of sequence S.”””\n    if n == 0:\n        return 0\n    else:\n        return linear sum(S, n−1) + S[n−1]","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"一般来说,线性递归可以很容易转换成循环去求解.(建议转换成循环,避免出现runtime error,python对递归的深度有限制,这点在文中有提到)","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"二分递归最常见,就是用于二分搜索.","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"多路递归,(我表示木有理解到精髓...)","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/#Ch5-列表","page":"（6）一起用python之基础篇——数据结构","title":"Ch5 列表","text":"","category":"section"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"列表这部分，作者使用ctypes下的py_object 作为基础。借用一个resize方法，实现了存储空间的动态增长。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"关于列表最重要的一部分是理解下图，由于前面的系列文章里对列表的分析较多，不再赘述。","category":"page"},{"location":"essays/[6]_Learn_Python_Together_Data_Structure/","page":"（6）一起用python之基础篇——数据结构","title":"（6）一起用python之基础篇——数据结构","text":"#该部分源自书中的源码    \nimport ctypes                                      # provides low-level arrays\n\nclass DynamicArray:\n  \"\"\"A dynamic array class akin to a simplified Python list.\"\"\"\n\n  def __init__(self):\n    \"\"\"Create an empty array.\"\"\"\n    self._n = 0                                    # count actual elements\n    self._capacity = 1                             # default array capacity\n    self._A = self._make_array(self._capacity)     # low-level array\n    \n  def __len__(self):\n    \"\"\"Return number of elements stored in the array.\"\"\"\n    return self._n\n    \n  def __getitem__(self, k):\n    \"\"\"Return element at index k.\"\"\"\n    if not 0 <= k < self._n:\n      raise IndexError('invalid index')\n    return self._A[k]                              # retrieve from array\n  \n  def append(self, obj):\n    \"\"\"Add object to end of the array.\"\"\"\n    if self._n == self._capacity:                  # not enough room\n      self._resize(2 * self._capacity)             # so double capacity\n    self._A[self._n] = obj\n    self._n += 1\n\n  def _resize(self, c):                            # nonpublic utitity\n    \"\"\"Resize internal array to capacity c.\"\"\"\n    B = self._make_array(c)                        # new (bigger) array\n    for k in range(self._n):                       # for each existing value\n      B[k] = self._A[k]\n    self._A = B                                    # use the bigger array\n    self._capacity = c\n\n  def _make_array(self, c):                        # nonpublic utitity\n     \"\"\"Return new array with capacity c.\"\"\"   \n     return (c * ctypes.py_object)()               # see ctypes documentation\n\n  def insert(self, k, value):\n    \"\"\"Insert value at index k, shifting subsequent values rightward.\"\"\"\n    # (for simplicity, we assume 0 <= k <= n in this verion)\n    if self._n == self._capacity:                  # not enough room\n      self._resize(2 * self._capacity)             # so double capacity\n    for j in range(self._n, k, -1):                # shift rightmost first\n      self._A[j] = self._A[j-1]\n    self._A[k] = value                             # store newest element\n    self._n += 1\n\n  def remove(self, value):\n    \"\"\"Remove first occurrence of value (or raise ValueError).\"\"\"\n    # note: we do not consider shrinking the dynamic array in this version\n    for k in range(self._n):\n      if self._A[k] == value:              # found a match!\n        for j in range(k, self._n - 1):    # shift others to fill gap\n          self._A[j] = self._A[j+1]\n        self._A[self._n - 1] = None        # help garbage collection\n        self._n -= 1                       # we have one less item\n        return                             # exit immediately\n    raise ValueError('value not found')    # only reached if no match","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"keywords: Julia,ReinforcementLearning CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/#从零开始用Julia写一个Reinforcement-Learning的库","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"","category":"section"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"今天看到Julia-0.7的alpha版本出来了，1.0应该也快了。我打算在这里完整记录下如何从零开始写一个Julia的库，估计有好多坑......","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"从田渊栋的一个talk里摘个图：","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"(Image: how_to_do_well_in_reinforcement_learning.png)","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"当然，右下角的配图（Python/C++）要打个❓","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/#Prepare","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"Prepare","text":"","category":"section"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/#Install","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"Install","text":"","category":"section"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"在Download页面的Upcoming Release部分可以找到对应平台的二进制文件。","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/#Package-Management","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"Package Management","text":"","category":"section"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"新版的Pkg管理模块比以前好用了很多，功能上有点像内置了一个pipenv。打开Julia的REPL后，按]进入Pkg管理模块，通过generate Foo即可新建一个Project，然后add Bar可以添加依赖，更多操作可以查看Pkg的Doc。","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/#Dependent-Packages","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"Dependent Packages","text":"","category":"section"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"从零开始用Julia写一个Reinforcement Learning的库","text":"✅PyCall\nPyCall用于跟OpenAI的Gym进行交互。封装了一个Environment.jl，目标是提供一个统一的接口。~~暂时还不支持Julia-0.7。 执行develop MacroTools更新MacroTools到master分支之后便正常了。~~\nKnet/Flux\n用于提供DL基础的工具包。我大致读完过Flux的源码，结构比较简单，但是有一些工具函数有所缺失。Knet相对而言文档丰富些，我暂时还没确定先用哪个（~~哪个先支持Julia0.7就先用哪个吧😋~~）。\n仔细考虑了下，决定用Flux，主要是可以很方便地在上面做个性化定制，Slack上相关的交流也很多（这点很重要）。具体关于Flux.jl的介绍可以查看最近写的一篇详细介绍:An Introduction to Flux.jl\n(Optional)CxxWrap\n有条件的话用CxxWrap封装一个可视化的库。\nTensorBoard\n有个小哥已经封装了TensorBoard.jl，不知道效果怎样，看README只是写了个prototype。\n✅VisualDL.jl\n  (尝试用CxxWrap封装了下，有个bug一直没调试成功，写入数据总是全是0.0，无奈)。后面如果确实有需要的话，用PyCall封装下Python的接口。\n\n  完成了用PyCall的封装，顺便熟悉了下发布一个package的流程，包括Unit Test, Travis, Documenter, Release等等。\n总的来说，CxxWrap用来对一些已经支持Python的C++库做封装还是蛮方便的，PyCall也很好用（只是需要注意1-based index和矩阵是按列存储的这两点）。","category":"page"},{"location":"essays/Write_a_Reinforcement_Learning_Package_in_Julia_from_Scratch/#Design","page":"从零开始用Julia写一个Reinforcement Learning的库","title":"Design","text":"","category":"section"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/index.en/#Notes-on-Distributional-Reinforcement-Learning","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"","category":"section"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/index.en/","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2022-01-13</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2022-01-13</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-12-29</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-12-29</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='94' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='94' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='21' height='20' fill='#555'/><rect x='21' width='73' height='20' fill='#4c1'/><rect width='94' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='110'>⇩</text><text x='115' y='140' transform='scale(.1)' textLength='110'>⇩</text><text x='565' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='630'>notebook.jl</text><text x='565' y='140' transform='scale(.1)' textLength='630'>notebook.jl</text></g><a target='_blank' xlink:href='notebook.jl'><rect width='94' height='20' fill='rgba(0,0,0,0)'/></a></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='160' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='160' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='141' height='20' fill='#0F80C1'/><rect width='160' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='885' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='1310'>Reinforcement Learning</text><text x='885' y='140' transform='scale(.1)' textLength='1310'>Reinforcement Learning</text></g></svg></div>","category":"page"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/index.en/","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"<iframe src=\"notebook.jl.html\" style=\"width: 100%;height: 100vh\"></iframe>","category":"page"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/index.en/","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/Oneday_Out_of_School/","page":"给自己放一天假~","title":"给自己放一天假~","text":"[toc]","category":"page"},{"location":"essays/Oneday_Out_of_School/#给自己放一天假","page":"给自己放一天假~","title":"给自己放一天假~","text":"","category":"section"},{"location":"essays/Oneday_Out_of_School/","page":"给自己放一天假~","title":"给自己放一天假~","text":"<div id=\"update-time\">2014-03-16 10:41:00</div> <div id=\"create-time\">2014-03-16 10:41:00</div> <div id=\"blog-id\">26</div> <div id=\"tags\">Picture,Life</div>","category":"page"},{"location":"essays/Oneday_Out_of_School/","page":"给自己放一天假~","title":"给自己放一天假~","text":"(Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: ) (Image: )","category":"page"},{"location":"essays/Oneday_Out_of_School/","page":"给自己放一天假~","title":"给自己放一天假~","text":"给自己放一天假，整理下心情~~~","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"keywords: ParallelComputing,Julia CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#自底向上理解Julia中的并行计算","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"最近看到一些有关Julia并行计算的提问，所以这里不妨开个头，介绍下Julia中并行计算的实现，希望能有更多人能参与进来一起讨论。在Julia文档中，有专门的一部分讲解Parallel Computing(中文翻译见并行计算)，采用的是一种Top-Down的方式分别介绍了协程、多线程及分布式处理。这里我打算采用一种Bottom-Up的方式来介绍下Julia中的并行计算，建议先读完官方文档后继续往下看。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#几个基本概念","page":"自底向上理解Julia中的并行计算","title":"几个基本概念","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#Task","page":"自底向上理解Julia中的并行计算","title":"Task","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"顾名思义，Task就是构造一段执行任务，Task的定义在task.c文件中，不过作为使用者，我们更关心的是调用接口：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"julia> methods(Task)\n# 1 method for generic function \"(::Type)\":\n[1] Task(f) in Core at boot.jl:377\n\njulia> methodswith(Task)\n[1] bind(c::Channel, task::Task) in Base at channels.jl:191\n[2] serialize(s::Serialization.AbstractSerializer, t::Task) in Serialization at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.0/Serialization/src/Serialization.jl:427\n[3] fetch(t::Task) in Base at task.jl:202\n[4] istaskdone(t::Task) in Base at task.jl:117\n[5] istaskstarted(t::Task) in Base at task.jl:134\n[6] schedule(t::Task) in Base at event.jl:95\n[7] schedule(t::Task, arg) in Base at event.jl:129\n[8] show(io::IO, ::MIME{Symbol(\"text/plain\")}, t::Task) in Base at show.jl:150\n[9] show(io::IO, t::Task) in Base at task.jl:58\n[10] wait(t::Task) in Base at task.jl:182\n[11] yield(t::Task) in Base at event.jl:166\n[12] yield(t::Task, x) in Base at event.jl:166\n[13] yieldto(t::Task) in Base at event.jl:181\n[14] yieldto(t::Task, x) in Base at event.jl:181\n\njulia> fieldnames(Task)\n(:parent, :storage, :state, :donenotify, :result, :exception, :backtrace, :logstate, :code)","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"task的构造函数只有一个Task(f)，其唯一的一个参数f必须是不带参数的函数，如果传一个带参数的函数，会在真正执行时触发MethodError。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"julia> t = Task((x) -> x + 1)\nTask (runnable) @0x00007f600e180d30\n\njulia> schedule(t)\nTask (failed) @0x00007f600e180d30\nMethodError: no method matching (::getfield(Main, Symbol(\"##11#12\")))()\nClosest candidates are:\n  #11(::Any) at REPL[29]:1","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"当然，每次都要记得构造一个闭包很傻，有一个@task宏可以用于简化这个过程：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"julia> t = @task println(\"Hi\")\nTask (runnable) @0x00007f600f25aa10\n\njulia> schedule(t)\nHi\nTask (queued) @0x00007f600f25aa10\n\njulia> t\nTask (done) @0x00007f600f25aa10","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"上面为了看到一个task的执行结果，我们使用了schedule函数，其作用是将这个runnable的task加入到一个全局的task队列中，然后将task的状态置成:queued，系统在空闲时会执行该task（TODO:调度的逻辑），执行结果存在:result字段下，并根据执行结果修改其:state状态（:failed,:done）。不过上面的例子似乎给人一种错觉，在执行完schedule(t)之后，task t立即就执行了，并没有感受到所谓的等待系统空闲。下面这个例子用一个计算密集型的任务来验证下：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"t = @task begin \n    println(\"begin task\")\n    inv(rand(2000, 2000))\n    println(\"end task\") \n    end\n\nbegin \n    schedule(t)\n    println(length(Base.Workqueue))\n    println(t.state)\n    println(\"begin computing\")\n    println(sum(inv(randn(1500, 1500))))\n    println(\"end computing\")\n    println(length(Base.Workqueue))\n    println(t.state)\nend\n\n# 1\n# queued\n# begin computing\n# 97.12983082590253\n# end computing\n# 1\n# queued\n# begin task\n# end task","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"可以看到，在schedule(t)之后，t并没有立即被执行，而是被添加到了Base.Workqueue中一直处于queued状态，主流程继续执行，先进行了求逆计算，结束之后，系统再进行task切换，执行t。以上，就是所谓的并发(Concurrency)。对于单一进程来说，并发执行计算密集型任务并没有太大收益，不过，对IO密集型任务来说，则非常有用，在等待的过程中，可以切换到其它任务，一旦条件满足，再切回来就执行，这样看起来，似乎是在同时执行多个任务（并发）。Julia对这里所谓的条件提供了一个统一的概念，称为Condition():","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"julia> fieldnames(Condition)\n(:waitq,)","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"Condition()只有一个类型为Vector的字段:waitq用于记录在等待该条件的所有task，在一个task内部，可以通过执行wait(c::Condition)，声明其正在等待某个条件，然后将自己添加到Base.Workqueue尾部，同时从中取出第一个task并做切换。当条件满足时，通过执行notify(c::Condition)再将这些task重新加入到Base.Workqueue中等待执行。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"julia> c = Condition()\nCondition(Any[])\n\njulia> t = @task begin\n           println(\"waiting condition\")\n           wait(c)\n           println(\"condition meet\")\n           end\nTask (runnable) @0x00007f2d954c07f0\n\njulia> schedule(t)\nwaiting condition\nTask (queued) @0x00007f2d954c07f0\n\njulia> notify(c)\ncondition meet\n1","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"除了通过执行wait进行task切换之外，还可以通过执行yield()主动进行task的切换（其实也是调用了wait()函数）。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"yield() = (enq_work(current_task()); wait())","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"下面看一个yield的例子：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"julia> t1 = @task begin\n       println(\"task1 begin\")\n       yield()\n       println(\"task1 resumed\")\n       end\nTask (runnable) @0x00007f2d954c2f50\n\njulia> t2 = @task begin\n       println(\"task2 begin\")\n       yield()\n       println(\"task2 resumed\")\n       end\nTask (runnable) @0x00007f2d954c31f0\n\njulia> begin\n       schedule(t1)\n       schedule(t2)\n       yield()\n       end\ntask1 begin\ntask2 begin\ntask1 resumed\ntask2 resumed","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"关于task，理解这些基本够用了。一个典型的应用是Timer，其中有个字段:cond就是一个Condition()，每当设定的时间周期到了的时候，就会notify挂在该:cond上的task。另外经常用到的@async宏其实就是先构造了一个task，然后执行了schedule（二合一了）","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"下面我们再深入理解一个更有意思的例子。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#Channel","page":"自底向上理解Julia中的并行计算","title":"Channel","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"Channel就是一个通道，不同的task可以从一端往其中写入数据，而另外一些task则可以从另外一端读取数据。Channel的结构很简单：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"mutable struct Channel{T} <: AbstractChannel{T}\n    cond_take::Condition                 # waiting for data to become available\n    cond_put::Condition                  # waiting for a writeable slot\n    state::Symbol\n    excp::Union{Exception, Nothing}         # exception to be thrown when state != :open\n\n    data::Vector{T}\n    sz_max::Int                          # maximum size of channel\n\n    # Used when sz_max == 0, i.e., an unbuffered channel.\n    waiters::Int\n    takers::Vector{Task}\n    putters::Vector{Task}\nend","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"其中state字段表示当前channel的状态（:open, :closed）,sz_max则表示channel的长度（该长度可以设为0，~~即无限大~~）。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"对于长度有限的channel来说，执行put!(c, v)写入数据时，如果当前data的长度已经达到了sz_max，则会调用wait()将当前task阻塞，然后每个事件周期都会检查data的长度是否已经小于sz_max，一旦该条件满足，就会往data中写入v，同时通知所有挂在cond_take字段上的task。而执行take!(c)读取数据时，如果当前data中有数据，则取出来，同时通知挂在cond_put上的task，否则，将当前task挂起到cond_take中，等待新的数据。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"对于~~无限长~~长度为0的channel而言，需要用到takers和putters字段。在写入数据时，如果takers为空，就将当前task写入到putters中(然后还会通知cond_take上的task，这类task是通过wait(c)挂在在~~无限长~~channel上的)，否则，从takers中取一个出来重新执行（这里用的是yield(t, v)操作）。取数据时，先将自己加入到waiters中，然后判断putters是否为空，若空，则调用wait()将自己挂起，否则从putters中取出一个执行。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"此外，关于Channel有个挺好用的函数Channel(func::Function; ctype=Any, csize=0, taskref=nothing)。关于Channel的例子实在太多了，手册中的那个生产者消费者的例子就挺不错的，这里不列举了。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#多线程","page":"自底向上理解Julia中的并行计算","title":"多线程","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"这里暂时先不深入介绍多线程，主要是这个Julia中老大难的问题了，目前的接口仍然是实验性的，此外也有一些PR正在做这方面的事情，建议subscribe一些multithreading的PR，了解下最新的进展（比如这个）","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#多进程","page":"自底向上理解Julia中的并行计算","title":"多进程","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"前面提到的都还是并发，要实现真正的并行，需要充分利用多核/多台机器。手册里有提到，Julia实现的并行机制有点类似MPI，不过是单向的（也就是说，有一个master进程负责给其它进程分配执行任务）。所有分布式相关的代码都在Julia源码的stdlib/Distributedpackage下，接下来我们一步步展开介绍（如果你想在REPL中测试下面的示例代码，记得先执行using Distributed）。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"首先讨论单机多进程的情况。在Julia中，一个工作进程称作一个worker，管理这些worker的进程是LocalProcess（也就是打开REPL后进入的进程）。每个进程都有自己的pid，LocalProcess的pid是1（为了表述方便，以下称其为master）。接下来先回答几个问题：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#1.-如何表示一个work中的对象？","page":"自底向上理解Julia中的并行计算","title":"1. 如何表示一个work中的对象？","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"对于master而言，worker中的对象有两种表示，一个是Future，另一个是RemoteChannel。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"mutable struct Future <: AbstractRemoteRef\n    where::Int\n    whence::Int\n    id::Int\n    v::Union{Some{Any}, Nothing}\nend","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"其中，where表示v所在的pid，whence和id一般通过RRID生成，分别表示生成该Future对象的进程的pid，而id则是从1开始自增的id。RemoteChannel也类似：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"mutable struct RemoteChannel{T<:AbstractChannel} <: AbstractRemoteRef\n    where::Int\n    whence::Int\n    id::Int\nend","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#2.-怎么发起远程调用？","page":"自底向上理解Julia中的并行计算","title":"2. 怎么发起远程调用？","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"Julia中，提供了一个底层函数remotecall来实现远程调用，执行后会立即返回一个Future对象，然后可以通过fetch将value写入到Future的v字段中（此时会发生数据转移，也就是导致并行计算性能瓶颈的地方）。例如：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"julia> using Distributed\n\njulia> addprocs()\n4-element Array{Int64,1}:\n 2\n 3\n 4\n 5\n\njulia> m = remotecall(rand, 5, 2, 2)\nFuture(5, 1, 6, nothing)\n\njulia> fetch(m)\n2×2 Array{Float64,2}:\n 0.109123  0.304667\n 0.454125  0.197551","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"此外，Distributed中还提供了一些工具函数和有用的宏，这里不深入介绍，我们更关心的是：","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/#3.-什么时候会发生GC？","page":"自底向上理解Julia中的并行计算","title":"3. 什么时候会发生GC？","text":"","category":"section"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"Distributed中有一个clear!函数用于将worker中的变量置成nothing，不过，如果不引入全局变量的话，大多时候并不需要手动进行该操作。fetch会自动执行send_del_client函数，并通知gc.此外手册里也提到，由于对master来说，一个RemoteReference的内存占用很小，并不会马上被gc，因而可以调用finalize，从而会立即执行send_del_client向worker发送gc信号。","category":"page"},{"location":"essays/An_Introduction_to_Parallel_Computing_in_Julia_From_Bottom_Up/","page":"自底向上理解Julia中的并行计算","title":"自底向上理解Julia中的并行计算","text":"TODO: 一个分布式并行计算的实例","category":"page"},{"location":"essays/Paraphrase_Generation/","page":"Paraphrase Generation","title":"Paraphrase Generation","text":"","category":"page"},{"location":"essays/Paraphrase_Generation/","page":"Paraphrase Generation","title":"Paraphrase Generation","text":"keywords: NLP CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Paraphrase_Generation/#Paraphrase-Generation","page":"Paraphrase Generation","title":"Paraphrase Generation","text":"","category":"section"},{"location":"essays/Paraphrase_Generation/#Paper-List","page":"Paraphrase Generation","title":"Paper List","text":"","category":"section"},{"location":"essays/Paraphrase_Generation/","page":"Paraphrase Generation","title":"Paraphrase Generation","text":"Paraphrase Generation with Deep Reinforcement Learning\nNeural paraphrase generation recently draws attention in different application scenarios. The task is often formalized as a sequence-to-sequence (Seq2Seq) learning problem. Prakash et al. (2016) employ a stacked residual LSTM network in the Seq2Seq model to enlarge the model capacity. Cao et al. (2017) utilize an additional vocabulary to restrict word candidates during generation. Gupta et al. (2018) use a variational auto-encoder framework to generate more diverse paraphrases. Ma et al. (2018) utilize an attention layer instead of a linear mapping in the decoder to pick up word candidates. Iyyer et al. (2018) harness syntactic information for controllable paraphrase generation. Zhang and Lapata (2017) tackle a similar task of sentence simplification withe Seq2Seq model coupled with deep reinforcement learning, in which the reward function is manually defined for the task. Similar to these works, we also pretrain the paraphrase generator within the Seq2Seq framework. The main difference lies in that we use another trainable neural network, referred to as evaluator, to guide the training of the generator through reinforcement learning.\nThere is also work on paraphrasing generation in different settings. For example, Mallinson et al. (2017) leverage bilingual data to produce paraphrases by pivoting over a shared translation in another language. Wieting et al. (2017); Wieting and Gimpel (2018) use neural machine translation to generate paraphrases via back-translation of bilingual sentence pairs. Buck et al. (2018) and Dong et al. (2017) tackle the problem of QA-specific paraphrasing with the guidance from an external QA system and an associated evaluation metric.\nSemantic Parsing via Paraphrasing\nCanonical utterance construction Given an utterance x and the KB, we construct a set of candidate logical forms Zx, and then for each z 2 Zx generate a small set of canonical natural language utterances Cz. Our goal at this point is only to generate a manageable set of logical forms containing the correct one, and then generate an appropriate canonical utterance from it. This strategy is feasible in factoid QA where compositionality is low, and so the size of Zx is limited (Section 4)\nParaphrasing We score the canonical utterances in Cz with respect to the input utterance x using a paraphrase model, which offers two advantages. First, the paraphrase model is decoupled from the KB, so we can train it from large text corpora. Second, natural language utterances often do not express predicates explicitly, e.g., the question “What is Italy’s money?” expresses the binary predicate CurrencyOf with a possessive construction. Paraphrasing methods are well-suited for handling such text-to-text gaps. \nParaphrase Detection in NLP(Slide)\nNeural Paraphrase Generation with Stacked Residual LSTM Networks(2016)\nSome old encoder decoder methods\nLearning Semantic Sentence Embeddings using Pair-wise Discriminator\nAn application of paraphrase\n(Image: )\nLearning Paraphrastic Sentence Embeddings from Back-Translated Bitext   (Image: )\n...finding clear differences in length, the amount of repetition, and the use of rare words.\nPushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations   Much larger compared above\nDeep Reinforcement Learning for Sequence to Sequence Models\nUsing RL to address the following two questions:\nexposure bias\ninconsistency between train/test measurement\nGet To The Point: Summarization with Pointer-Generator Networks\nFirst, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator.\nSecond, we use coverage to keep track of what has been summarized, which discourages repetition.\nA Deep Generative Framework for Paraphrase Generation   (Image: )\nSemantic Structural Evaluation for Text Simplification   We presented the first structure-aware metric for","category":"page"},{"location":"essays/Paraphrase_Generation/","page":"Paraphrase Generation","title":"Paraphrase Generation","text":"text simplification, SAMSA, and the first evaluation experiments that directly target the structural simplification component, separately from the lexical component. ","category":"page"},{"location":"essays/Paraphrase_Generation/","page":"Paraphrase Generation","title":"Paraphrase Generation","text":"Dynamic Multi-Level Multi-Task Learning for Sentence Simplification   (Image: )\nIntegrating Transformer and Paraphrase Rules for Sentence Simplification\nConditional Text Paraphrasing A Survey and Taxonomy   (Image: )\nA Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation\nSlot Alignment\nEvaluating the State-of-the-Art of End-to-End Natural Language Generation: The E2E NLG Challenge(80 pages /2019/07/24)\nConstrained-Decoding-for-Neural-NLG-from-Compositional-Representations-in-Task-Oriented-Dialogue.pdf\n(1) propose using tree-structured semantic representations, like those used in traditional rule-based NLG systems, for better discourse-level structuring and sentence-level planning;\n(2) introduce a challenging dataset using this representation for the weather domain;\n(3) introduce a constrained decoding approach for Seq2Seq models that leverages this representation to improve semantic correctness;\n(4) demonstrate promising results on our dataset and the E2E dataset\nSyntactic Manipulation for Generating More Diverse and Interesting Texts\nSyntactic Controled LSTM\n(Image: )","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"keywords: Life CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/About_Recent/#聊聊最近","page":"聊聊最近","title":"聊聊最近","text":"","category":"section"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"离上次更新有三个多月了吧，这期间乱七八糟的事很多，最近放了个长假，也该静下来了。今天先在这里记录点杂事，接下来尽量多写些有价值的东西。","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"10号域名到期，提前先续费了，懒得折腾域名的转入转出，继续用的namecheap，也就19刀。顺便看了下网站的统计信息，me域名的访问量只占了1/5，远不及ml域名，汗。。。","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"##学习","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"先说点学习上的。编程语言方面，最近在学Clojure，感觉这门语言学起来蛮好玩的。说起来也有点意思，其实一开始我是准备学习下scala的，跟风嘛，Spark这么火，怎么说也得了解了解。然后翻了几本scala方面的书，没太有感觉。主要是因为这货跟java太像了！然后还夹杂了一大堆语法。虽说写出来的代码相比java已经简洁了许多，但是出于对java的厌恶我学习的动力大大降低。在有java基础之后学习scala的迁移成本其实是很低的，但是我希望在学习一门新的编程语言的时候，这门语言不应该是我所熟悉的范畴（比如学完python后学ruby），否则很容易陷入到语言本身的语法设定中去了。我希望这门语言与我熟悉的语言之间有比较大的gap，能学到更多编程思想方面的东西。然后那段时间慢慢地就把scala放下了，偶然一次看到了关于jvm平台上的scala还有groovy和clojure的讨论，发现clojure似乎跟自己之前学过的语言有很大不同，主要是因为它是Lisp的一个分支，另外函数式编程的思想也贯穿其中，于是一头扎进去学到现在。","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"读的相关书主要有4本，《clojure编程》、《clojure编程乐趣》（这本书英文版的有第二版了，我对比了下，大部分是一样的，就是最后多了几个章节）、《clojure经典实例》、《七周七并发模型》（当然，这本书不只是介绍了clojure的并发模型，我对并发的内容缺少实践，这部分学得不是特别深）。目前还处于打基础的过程中，缺少一些实际项目来练手，了解storm似乎是个不错的开始。学习clojure带来的最大收获是思考问题上的改变。我发现函数式编程思想在数据处理问题上有很大优势，理解其中的精髓后发现现在写的python代码也越来越简洁了......以后总结下自己的学习心得后再专门讨论下这块。","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"nlp这块最近在做的就是把autoencoder和lstm融一下试试效果，感觉最近做科研的这块很无力。真的是很没有方向感，不知道该怎么深入下去，也就靠读读论文打发时间了......有时候看着那些水文啊，真是无力吐槽了，然后就会安慰安慰自己，唉，不读博也罢。说个上周的一件小事，为了做融合，先要把autoencoder那边的matlab代码改成python的，方便共享cost信息。其实我也没怎么看matlab代码，很久没用过了，听师弟讲了讲代码流程后大致明白了其结构和实现方式，于是花了一天时间草草写了个测试用例。同一个batch的数据反复迭代后，cost是呈现收敛趋势的，然后感觉应该没问题了。给大家讲了讲实现细节后修改了几处错误。","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"本以为这样就可以了，不过徐老师强调让我验证下matlab和python两边的输出结果是否一致。其实一开始我的内心是拒绝的。。。（其实是不屑的...）哥写的怎么会有问题呢？？？无奈，写样例，测试......打脸了......第一轮前向结果就不一致，甚至最后收敛的结果也总是相差了一点点。看了半天愣是没找出问题所在，更要命的是matlab的代码简直就是个blackbox。实在找不出问题了，我只能把问题归为matlab里神奇的边界条件所导致的结果差异......然而，老师并不信我这套，一定要两边输出结果一致才对！","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"“老师，这个，matlab的代码我不会debug...”","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"“那我们一起来看”","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"“。。。”","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"然后，一整个下午坐在老师旁边一行行读代码，测试，验证。最后的最后，坑在了一个实在是微不足道的地方。计算cost的时候通常为了避免对0求log会加上一个很小的实数10e^-10，然而，我的样本有一个mask操作，mask以外的cost都为0，本应该对mask部分的cost加上10e^-10后求-log，再求mean，结果我代码里为了图方便，先整体加上10e^-10后求-log再求mean。但是，-log^(0 + 10e^-10) 并不是趋于0的呀！！！因为自己的失误，还让别人跟着一起填坑......实在是惭愧。","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"总结下来，一是永远不要对自己过度自信，我不知道多少次因为这个毛病坑人坑己了......被女朋友说，被同学说，被老师说，以后还是要更务实一些；二是“凡是有可能出bug的代码一定有问题”，“墨菲定律”？，这个也不是第一次了，好几次隐约觉得可能代码写得有点问题，结果最后都被坑的不轻......","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"##找工作","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"再聊聊找工作的事。算了算，自己总共就投了5份简历，（BAT+美团+京东），其它的也就没投了，要么是显然去不了，要么是实在不感兴趣。剩下的时间，可能更有针对地去投几家外企，发现了两家还不错的公司，试试看～","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"百度那边走的就是正常的流程，宣讲会，投简历，面试。面试百度应该是自己的第一次正式面试，有点紧张......现在印象最深的就是二面问了个智力题，想了半天答错了@_@。三面的话，针对自己做的事情，聊的level稍高点。总的来说面试的人都还不错。阿里的话，我就不吐槽了。腾讯是唯一参加笔试的，本来就对腾讯不太感兴趣，好奇跟着参加了个笔试，出的都是什么题啊，简直了！美团那边面试的感觉页很不错，师兄推荐过去的，中午在那吃饭的时候听他们聊了些工作上的事，觉得和自己做的事情挺对胃口的。只是，有时候真的觉得对自己的职业生涯缺少很明确的规划。以至于真要做出选择的时候，很是迷茫......蛮感激曾师兄跟自己聊了许多，不管最后去不去美团，那次谈话都是很大的收获。京东的面试，就一个感觉，我是不是来错了地......面试的人一点都不鸟我......","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"其实从内心来讲，自己倾向于往计算广告方向发展，商业价值更大一些，但这块需要一个好的成长环境。不过呢，觉得做nlp这块好像也还不错，把功底打扎实了以后做周边的东西都能跟得上，不过总觉得有那么一丝丝想法，是不是有必要读个博把这块的工作做得更深入呢？唉，现实的情况是，先得找到个工作，然后再谈实现个人价值。理想和现实的纠缠......","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"##最后","category":"page"},{"location":"essays/About_Recent/","page":"聊聊最近","title":"聊聊最近","text":"这个网站的代码好久没更新了，积累了不少问题一直没改，近期打算做一些改进，当时图简便直接用的django框架，接下来如果有时间的化，可能会换个框架，说不定会拿clojure试水～","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"keywords: Algorithm,Julia,ReinforcementLearning CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#强化学习实战[updating]","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"[等我用Julia写个RL的库了再来继续更新。]","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"我一直希望找到一篇长文，能从实用的角度讲清楚强化学习。一年过去了，我决定自己动手写这样一篇文章。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#编程语言","page":"强化学习实战[updating]","title":"编程语言","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"本文将使用Julia作为主要的编程语言来实现Reinforcement Learning中的大多数算法。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"Why Julia?事实上，我更乐意使用Clojure，然而其基础工具库实在太匮乏，不得不放弃。Why not Python?我只是单纯觉得Julia写出来的代码更好看！不过阅读本文并不需要读者熟练掌握Julia，只需要有基本的编程思想即可，我会尽量将Julia这门语言独有的内容降到最低（必要的时候会给出解释和参考文献）。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#1.-Tabular-Methods","page":"强化学习实战[updating]","title":"1. Tabular Methods","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"“昨夜西风凋碧树，独上高楼，望尽天涯路。”","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#1.1-Day-1:-Where's-Eve?","page":"强化学习实战[updating]","title":"1.1 Day 1: Where's Eve?","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: eve_move)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"假设某个虚拟的世界中只有两个星球（黄色星球[Y]和红色星球[R]），每个星球上各有一枚硬币（正面朝上的概率本别是p, q），我们的机器人朋友Eve的初始位置在左边的黄色星球上(s_0=Y)，接下来，它每天都尝试投掷当前所在星球上的硬币，如果正面朝上，那么它移动到另外一个星球上，否则呆在原地不动。于是，我们可以计算出第t天Eve处于黄色星球的概率:P(s_t=Y)=P(s_t-1=Y)(1-p) + P(s_t-1=R)(q)，类似的，处于红色星球的概率为：P(s_t=R) = P(s_t-1=Y)(p) + P(X_t-1=R)(1-q).将其写成概率转移矩阵的形式如下：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\boldsymbol{P} = \\left( \\begin{matrix} 1-p & p \\\nq & 1-q \\end{matrix} \\right) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"于是，t时刻Eve所处状态的概率为：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\boldsymbol{s}t = \\boldsymbol{s}0 \\boldsymbol{P}^t \\end{equation} $ 这里，boldsymbols_0=(10)，即初始状态处于左边的黄色星球。由于该概率转移矩阵的特殊性质，boldsymbols_t最终会收敛到一个稳态。下图为(pq)分别取(0.5,0.5),(0.2, 0.1),(0.95,0.7)时，boldsymbols_t的收敛过程：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: eve_planet)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"假设我们的机器人Eve落在了一条数轴的原点处，它的任务是寻找到生命，在-3和5处分别有一盆花和一只小狗，Eve每天只能选择向左或向右移动一个单位，只要发现生命（花或者狗）后，任务便结束，然后Eve返回并获得相应的奖励（假设奖励分别是3和5，其它位置没有奖励）。 显然，对于这样一个简单而且确定的问题而言，有多种搜索的方法得到解，这里先假设Eve并不知道环境是确定的。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: Eve_Example)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"现在先给出如下定义：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"mathcalA\n：Actions, 动作空间,在这里包含两种可能left right\na_t\n: 在t时刻采取的行动\nmathcalS\n: States, 状态空间，这里就是Eve所有可能的位置-3 -2 -1 0 1 2 3 4 5\ns_t\n: 在t时刻所处的状态\nmathcalR\n:所有可能的奖励，这里由三个离散值0 3 5构成\nR_t\n：每一天获得的奖励，特别地，我们将游戏结束时的时间记为T，任务结束时获得的奖励为R_T","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"假设Eve很笨，它的记忆只有一天（并不记得它曾走过哪些地方），每天只会等概率地随机选择向左或向右移动，将其记作策略pi（尽管目前还只是随机游走，谈不上什么策略）。我们先观察以下两个指标：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"barR_T = fracsum_i=1^N R_T^iN\n，N次试验的平均收益(3746)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: 任务结束时获得的奖励分布)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"barT = fracsum_i=1^N T^iN\n，N次试验平均行动的次数(16164)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: 任务结束时，行动次数的分布)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"平均收益只有3.7左右，离最优解（5）还有点距离，此外平均实验次数居然到了16次。接下来，我们将一步步放松约束条件，改进Eve的行动策略。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"这里先将前面Eve与环境交互的过程用下图抽象出来：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: MDP的序列化描述)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"每一步的reward只由当前时刻的state和action共同决定（这里对于Eve来说，每天的reward其实只与state相关，环境并不受Eve的行动影响，当然，真实情况要比这复杂得多，我们一步步来），而下一时刻的state则只受上一个时刻的state和action共同决定。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#1.2-Day-2:-The-Value-of-State","page":"强化学习实战[updating]","title":"1.2 Day 2: The Value of State","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"某一天，Eve感到很迷茫，它不知道未来这么走下去，收益究竟有多少，我们可以给Eve算一下未来收益的总和G：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} Gt = Rt + R{t+1} + R{t+2} ... \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"不过，Eve可能并不这么认为，同样的收益，第5天得到还是第3天得到对于Eve来说有着不同的意义（显然后者的意义更大），所以不妨给每天的收益增加一个基于时间的折扣系数gamma（这么做有许多好处，数学上处理起来更方便，而且对于infinite的问题也更容易求解，当然，根据实际问题不同，你完全可以设计不同的G_t计算方式，比如averaged reward）。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} Gt = Rt + \\gamma R{t+1} + \\gamma^2 R{t+2} + ... \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"那么，根据Eve在t时刻所处的状态不同，假设可以算出收益的期望，称作value function:","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} Vt(s) = \\mathbb{E}(Gt | s) = \\mathbb{E}(Rt + \\gamma R{t+1} + \\gamma^2 R{t+2} + ... | s) \\label{valueequation} \\end{equation} $ 从上帝视角来看，在环境不发生变化的情况下，显然每个状态s都有一个对应的固定的V(s)，这样，每次Eve决定怎么走的时候，只需要看下这张表，从可以到达的所有状态中，找到价值最高的状态s，跳转过去即可。现在问题变成了如何计算V(s)。我们不妨先模拟下，将Eve放在不同的位置，然后分别执行原来的随机策略，计算平均收益hatG_t，来估计V(s)。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: 随机模拟估计V(s)，gamma=1.0)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"看起来上图似乎符合我们的直观感受。gamma越大，我们就越是看重长期收益，反之则更看重短期收益。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"不过，对我们的机器人Eve来说，手上并没有这样一张表，前面虽然通过模拟得到了这样一张表，但是效率还很低。那是否能找到解析解呢？首先引入状态转移的概念，这里Eve每一时刻所处的状态只与其上一时候所处的状态（和行动）有关，不受更早时候状态（和行为）的影响（即具有Markov性质），于是有：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} P(s'|s) = \\sum_{a \\in A} P(s' | s, a) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"对于前面Eve机器人随机策略而言，对应的概率转移矩阵为：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\begin{bmatrix} 1.0  &0 &0 &0 &0 &0 &0 &0 &0         \\\n0.5 &0 & 0.5  &0 &0 &0 &0 &0 &0      \\\n0   &0.5 &0 & 0.5 &0 &0 &0 &0 &0      \\\n0 &0   &0.5 &0 & 0.5 &0 &0 &0 &0     \\\n0 &0 &0   &0.5 &0 & 0.5 &0 &0 &0    \\\n0 &0 &0 &0   &0.5 &0 & 0.5  &0 &0  \\\n0 &0 &0 &0 &0   &0.5 &0 & 0.5 &0  \\\n0 &0 &0 &0 &0 &0   &0.5 &0 & 0.5 \\\n0 &0 &0 &0 &0 &0 &0   &0 & 1.0 \\\n\\end{bmatrix} \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"于是，eqrefvalue_equation可以写成：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} Vt(s) = Rt(s) + \\gamma \\sum{s' \\in S} P(s' | s) V{t+1}(s') \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"上式构建了不同时刻的价值函数之间的关系，在这里由于状态转移函数是固定的，最终会达到一个稳态（TODO: 这里需要展开说下，MRP），即：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\begin{bmatrix} V^(s_1) \\\n\\dots \\\nV^(sN)  \\end{bmatrix} =  \\begin{bmatrix} R(s1) \\\n\\dots \\\nR(sN)  \\end{bmatrix} + \\gamma \\begin{bmatrix} P(s1|s1) & \\dots &P(sN|s1)\\\n\\vdots  &\\ddots &\\vdots \\\nP(s1|sN) &\\dots &P(sN|sN)  \\end{bmatrix} \\begin{bmatrix} V^*(s1) \\\n\\dots \\\nV^*(s_N)  \\end{bmatrix} \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"采用矩阵的表示方法即是：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\begin{split} \\boldsymbol{V} &= \\boldsymbol{R} + \\gamma \\boldsymbol{P V}\\\n\\boldsymbol{V} &= (\\boldsymbol{I} - \\gamma \\boldsymbol{P})^{-1} \\boldsymbol{R} \\end{split} \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"P = diagm(repmat([0.5], 8), 1) + diagm(repmat([0.5], 8), -1)\nP[1,1], P[1,2], P[end, end-1], P[end, end] = 1, 0, 0, 1\nV(γ) = (diagm(ones(9)) -  γ*P)^-1 * R\nshow(V(0.9))\n# [30.0, 19.9416, 14.3146, 11.8686, 12.0601, 14.9316, 21.1213, 32.0046, 50.0]\nshow(V(0.95))\n# [60.0, 48.1992, 41.4721, 39.1104, 40.8656, 46.9225, 57.9186, 75.0113, 100.0]\nshow(V(0.99))\n# [300.0, 301.464, 309.018, 322.814, 343.132, 370.383, 405.115, 448.032, 500.0]","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"稠密矩阵求逆的复杂度为O(n^3)（TODO: 这里需要插入相关文献），接下来，我们将分别采用Value Iteration和 Policy Iteration来求解。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#Value-Iteration","page":"强化学习实战[updating]","title":"Value Iteration","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"让我们先从上帝视角来看看这个问题。我们的本意是希望得到一张表，让Eve每次行动的时候，能够查看它从当前位置往左和往右走的期望价值，然后从中选出期望价值最大的行动a作为决策Policy的结果。显然，最糟糕的情况下，我们需要遍历所有的可能A^S，不过通过Value Iteration，我们可以先找到稳态的V(s)，然后直接得出最优的Policy。可以证明在最优策略下（TODO: Reference Needed Here, Bellman Function），价值函数满足以下式子：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} V^(s) = \\underset{a \\in A}{max} \\left( R(s, a) + \\gamma \\sum_{s' \\in S}P(s' | s,a) V^(s') \\right) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"于是，我们可以先随机初始化V(s)，然后根据上式迭代计算并更新，直至收敛。下图动态地展示了该过程：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: gamma=0.9时，Value 迭代的过程)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"不同gamma对应的稳态Value:","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: 不同gamma对应的稳态Value)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"在得到稳态的V^*之后，即可根据下式得到对应的最优Policy：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\pi(s) \\leftarrow \\underset {a \\in A} {arg \\ max} \\left( R(s, a) + \\gamma \\sum_{s' \\in S}P(s' | s,a) V^*(s') \\right) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#Policy-Iteration","page":"强化学习实战[updating]","title":"Policy Iteration","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"Policy Iteration的思想是，先将所有状态对应的V置为0（也可以根据先验设置相应的值），针对每个状态，先随机初始化一个action(或根据前面设置的先验调整),记为pi_0，在给定Policy之后，我们可以算出下一步所有状态对应的V(s)，即(Policy Evaluation)：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} V^{\\pi}t (s) = R(s, \\pi(s)) + \\gamma \\sum{s' \\in S} P(s'|s, \\pi(s)) V^{\\pi}_{t+1}(s') \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"然后根据新得到的V_t+1(s),重新调整Policy，使得每个state对应的action都是朝着V(ss)最大的方向在移动，即（Policy update）:","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\pi{k+1}(s) = \\underset {a \\in A} {arg \\ max} \\left( R(s,a) + \\gamma \\sum{s' \\in S} P(s' | s, a) V^{\\pi_k}(s') \\right) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"如此迭代，直至Policy不再变化。如何证明最优呢？（TODO: 单调性）","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"(Image: Policy Iteration)","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#1.3-Day-3:-Monte-Carlo-Methods-in-Depth","page":"强化学习实战[updating]","title":"1.3 Day 3: Monte Carlo Methods in Depth","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"在前面1.2中，我们尝试将Eve的起点放在不同位置，然后计算每次实验结束时reward的期望的估计值，从而用来评价不同状态作为起始点的重要性。不过，在大多数问题中，我们关注的不仅仅是某一状态作为初始状态的情况。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"First Visit Monte Carlo Method 方法的思想就是，Agent在做出一次尝试之后，得到状态的序列s_0 s_1  s_T（将其想象成搜索空间中的一条路径），以及最终的r，然后，将该reward分配给路径上的第一次遇到的状态，重复多次之后，计算每个状态上r的平均值作为该状态的价值估计（显然，也不一定限制在first visit的state，只是这样处理更自然些）。假设我们对state之间的转换关系很清楚（即已知model），那么剩下的任务就是每次往前看一步，找到最优的state，跳转过去即可。对于model未知的情况，则需要考虑(state, action) pair，然后根据前面first visit的方法更新对应pair的价值，最后，在每个状态下找到使得pair的value最大的action即可。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"类比前面的Policy Iteration过程，这里我们同样可以借用MC得到的q value，然后迭代优化。（其实就是Generalized Policy Iteration的一种）这里有两个前提假设：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"exploring starts （引入 epsilon-soft解决该问题）\ninfinite number of episodes （根据GPI中的思想，一步步优化）","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#Off-Policy-MC","page":"强化学习实战[updating]","title":"Off-Policy MC","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"首先区分behavior policy 和 target policy(可以是某种固定的贪心算法)。根据behavior policy得出一条序列，然后按照重要性采样更新value。（TODO:这里需要展开）","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#MCTS","page":"强化学习实战[updating]","title":"MCTS","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"TODO: 这个需要讲个专题","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#1.4-Day-4:-Temporal-Difference-Learning","page":"强化学习实战[updating]","title":"1.4 Day 4: Temporal-Difference Learning","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"在前面MC部分中，我们需要等到一个episode结束后，得到最终的reward，然后用其更新state value，TD的思想则是，只需走一步，然后利用两步之间state value的差分修正上一步的state value(learn a guess from a guess, model free)。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} V(St) \\leftarrow V(St) + \\alpha (R{t+1} + \\gamma V(S{t+1} - V(S_t))) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#SARSA","page":"强化学习实战[updating]","title":"SARSA","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"直接学习action value。","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} Q(St, At) \\leftarrow Q(St, At) + \\alpha (R{t+1} + \\gamma Q(S{t+1}, A{t+1}) - Q(St, A_t)) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"变种，Expected SARSA","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} \\begin{split} Q(St, At)  & \\leftarrow Q(St, At) + \\alpha (R{t+1} + \\gamma \\mathbb{E} (Q(S{t+1}, A{t+1} | S{t+1}) - Q(St, At)) \\\n& \\leftarrow Q(St, At) + \\alpha (R{t+1} + \\gamma \\sum{a} \\pi(a|S{t+1}) Q(S{t+1}, a) - Q(St, At))  \\end{split} \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"Q-Learning","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"$","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"\\begin{equation} Q(St, At) \\leftarrow Q(St, At) + \\alpha (R{t+1} + \\gamma \\ \\underset {a } {max} \\ Q(S{t+1}, a) - Q(St, At)) \\end{equation} $","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"<div class=\"alert alert-info\"> 关于SARSA和Q-Learning的对比，可以参考这里的<a href=\"https://www.google.co.jp/search?q=sarsa+and+q+learning&oq=sarsa+and+q&aqs=chrome.0.0j69i57j0l4.3086j0j1&sourceid=chrome&ie=UTF-8\">Youtube</a>链接。 </div>","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"进一步，[Double Q-Learning][]，算是一种off-policy，behavior和target随机相互学习。摘要部分说得很清楚了：","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is introduced because Q-learning uses the maximum action value as an approximation for the maximum expected action value. We introduce an alternative way to approximate the maximum expected value for any set of random variables. The obtained double estimator method is shown to sometimes underestimate rather than overestimate the maximum expected value. ","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#2.-Approximate-Methods","page":"强化学习实战[updating]","title":"2. Approximate Methods","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"“衣带渐宽终不悔，为伊消得人憔悴。”","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#3.-Deep-Reinforcement-Learning","page":"强化学习实战[updating]","title":"3. Deep Reinforcement Learning","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"“众里寻他千百度，蓦然回首，那人却在灯火阑珊处。”","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#参考文献","page":"强化学习实战[updating]","title":"参考文献","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/#Books","page":"强化学习实战[updating]","title":"Books","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"[Reinforcement Learning: An Introduction. Second edition][]\n[Decision Making Under Uncertainty Theory and Application][]\n[Artificial Intelligence: Foundations of Computational Agents, 2nd Edition][]\n[Approximate Dynamic Programming: Solving the Curses of Dimensionality, 2nd Edition][]\n[Dynamic Programming and Optimal Control][]\n[Reinforcement Learning State of the Art][]\n[reinforcement learning and dynamic programming using function approximators][]","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"[Reinforcement Learning: An Introduction. Second edition]: http://incompleteideas.net/book/the-book-2nd.html [Decision Making Under Uncertainty Theory and Application]: https://mitpress.mit.edu/decision-making-under-uncertainty [Artificial Intelligence: Foundations of Computational Agents, 2nd Edition]: http://artint.info/ [Approximate Dynamic Programming: Solving the Curses of Dimensionality, 2nd Edition]: http://adp.princeton.edu/ [Dynamic Programming and Optimal Control]: http://www.athenasc.com/dpbook.html [Reinforcement Learning State of the Art]: https://link.springer.com/book/10.1007%2F978-3-642-27645-3 [reinforcement learning and dynamic programming using function approximators]: http://rlbook.busoniu.net/","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/#Papers","page":"强化学习实战[updating]","title":"Papers","text":"","category":"section"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"[Double Q-Learning][]","category":"page"},{"location":"essays/Reinforcement_Learning_in_Action/","page":"强化学习实战[updating]","title":"强化学习实战[updating]","text":"[Double Q-Learning]: https://papers.nips.cc/paper/3964-double-q-learning.pdf","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"keywords: Algorithm CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/#Understanding-Variational-Autoencoder","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"","category":"section"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"本文主要记录自己在学习Automatic Differentiation Variational Inference过程中的一些参考资料和理解。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/#熵（Entropy）","page":"Understanding Variational Autoencoder","title":"熵（Entropy）","text":"","category":"section"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"以下借用《Statistical Rethinking》一书中的部分内容来理解Entropy及其相关的内容。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"假设今天天气预报告诉我们，明天有可能下雨（记为事件A），该事件有一定的不确定性，等到第二天结束的时候，不论第二天是否下了雨，之前的不确定性都消失了。换句话说，在第二天看到事件A的结果时（下雨或没下雨），我们获取了一定的信息。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"信息：在观测到某一事件发生的结果之后，不确定性的降低程度。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"直观上，衡量信息的指标需要满足一下三点：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"连续性。如果该指标不满足连续性，那么一点微小的概率变化会导致很大的不确定性的变化。\n递增性。随着可能发生的事件越多，不确定性越大。比如有两个城市需要预测天气，A城市的有一半的可能下雨，一半的可能是晴天，而B城市下雨、下冰雹和晴天的概率分别为1/3，那么我们希望B城市的不确定性更大一些，毕竟可能性空间更大。\n叠加性。将明天是否下雨记为事件A，明天是否刮风记为事件B，假设二者相互独立，那么将事件A的不确定性与事件B的不确定性之和，与（下雨/刮风、不下雨/刮风、下雨/不刮风、不下雨/不刮风）这四个事件发生的不确定性之和相等。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"信息熵的表达形式刚好满足以上三点：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\nbeginequation\nbeginsplit\nH(p)  = - mathbbE log left(p_iright) \n      = - sum_i=1^n p_i logleft(p_i right) \nendsplit\nendequation","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"简单来说，熵就是概率对数的加权平均。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/#K-L散度（Kullback-Leibler-Divergence-）","page":"Understanding Variational Autoencoder","title":"K-L散度（Kullback-Leibler Divergence ）","text":"","category":"section"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"散度:用某个分布去描述另外一个分布时引入的不确定性。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"散度的定义如下：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} \\begin{split} D{KL}(p,q) & = \\sum{i \\in I} pi  \\left( \\log (pi) - \\log (qi) \\right) \\\n       & = \\sum{i \\in I} pi \\log \\left( \\frac {pi} {q_i} \\right)  \\end{split} \\label{KL} \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"KL散度是大于等于0的，可以通过[Gibb's不等式][Gibb's inequality]证明：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"首先，我们知道：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} \\ln x \\le x - 1 \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"于是，根据eqrefKL中KL散度的定义，可以得到如下不等式：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} \\begin{split} -\\sum{i \\in I} pi \\log \\left( \\frac {qi} {pi} \\right) & \\ge - \\sum{i \\in I} pi \\left( \\frac {qi - pi} {pi}\\right) \\\n &= -\\sum{i \\in I} (qi - pi) \\\n &= 1 - \\sum{i \\in I} qi \\\n &\\ge 0 \\end{split} \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"可以看出，只有当两个分布一一对应相等的时候才取0。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"如果将KL散度拆开，可以看作是交叉熵与信息熵之差：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} D_{KL} = H(p,q) - H(p) \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"关于KL散度，一个很重要的特性是，KL(pq)一般不等于KL(qp)，也就是说，KL散度是有方向性的。这里借用[Statistical Rethinking][SR]一书第6章中的例子来解释下。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"假设在地球上随机选一地点，该点位于水面和陆地的概率分别为0.7和0.3，记为q=(0703)，我们知道火星非常干燥，假设相应的概率为p=(001099)，可以算出KL(pq)=114，KL(qp)=262。可以看出，用火星上的分布去估计地球上的分布时，得到的散度更大。直观可以这么理解：一个地球人第一次到火星上时，有很大概率落在陆地上，根据他在地球上的先验，落在陆地上的概率为0.3，因而不会特别惊讶；相反，一个火星人第一次落到地球上时，大概率会落到水面上，这对于火星人来说，是非常惊讶的事（火星上只有0.01的概率），因而其KL散度更大。因此，通常如果选择一个熵值较大的分布去估计某个真实分布时，得到的KL散度会更小一些。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/#The-Evidence-Lower-Bound","page":"Understanding Variational Autoencoder","title":"The Evidence Lower Bound","text":"","category":"section"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"给定boldsymbolx = x_1n为观测变量，boldsymbolz=z_1m为隐变量，对应的联合概率为p(boldsymbolz boldsymbolx)，后验可以写成：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} p(\\boldsymbol{z} | \\boldsymbol{x}) = \\frac{p(\\boldsymbol{z}, \\boldsymbol{x})}{p(\\boldsymbol{x})} \\label{posterior} \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"其中p(boldsymbolx)称为证据：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} p(\\boldsymbol{x}) = \\int p(\\boldsymbol{z}, \\boldsymbol{x})d\\boldsymbol{z} \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"变分推断背后的思想是，用一些简单的参数化分布（记为Q_phi(boldsymbolz  boldsymbolx)）去拟合后验分布P(boldsymbolzboldsymbolx)，通过调整参数phi使得Q_phi尽可能接近P(boldsymbolzboldsymbolx)，从而转换成优化问题。衡量二者相似度的方法之一就是用前面提到的KL散度，按理说，我们应该最小化KL(PQ)，不过实际使用中通常是最小化KL(QP)，前面也介绍了，二者实际上是不同的，可以参考阅读[A Beginner's Guide to Variational Methods: Mean-Field Approximation][]一文中的Forward KL vs. Reverse KL和KL Divergence: Forward vs Reverse?部分来了解为什么优化KL(QP)。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} KL(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z}|\\boldsymbol{x})) = \\mathbb{E} [ \\log q(\\boldsymbol{z})] - \\mathbb{E} [\\log p(\\boldsymbol{z}|\\boldsymbol{x})] \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"这里的mathbbE是相对q(boldsymbolz)的期望，将eqrefposterior代入可得：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} KL(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z}|\\boldsymbol{x})) = \\mathbb{E} [ \\log q(\\boldsymbol{z})] - \\mathbb{E} [\\log p(\\boldsymbol{z},\\boldsymbol{x})] + \\log p(\\boldsymbol{x}) \\label{KLqp} \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"由于p(boldsymbolx)是固定的，于是最小化上式中的KL等价于最大化下面的证据下界：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} ELBO(q) = \\mathbb{E}[\\log p(\\boldsymbol{z},\\boldsymbol{x})] - \\mathbb{E} [\\log q(\\boldsymbol{z})] \\label{ELBO} \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"上式中的联合概率又可以表示成先验乘以似然，于是有：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} \\begin{split} ELBO(q) & = \\mathbb{E} [\\log p(\\boldsymbol{z})] + \\mathbb{E} [\\log p(\\boldsymbol{x}| \\boldsymbol{z})] - \\mathbb{E} [\\log q(\\mathbb{z})] \\\n& =\\mathbb{E}[\\log p(\\boldsymbol{x}|\\boldsymbol{z})] - KL(q(\\boldsymbol{z})\\| p(\\boldsymbol{z})) \\end{split} \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"直观上看，第一项是似然的期望，最大化ELBO意味着我们希望隐变量能够很好地解释观测数据；第二项是隐变量的先验与估计之间的KL散度，越小越好。由eqrefKLqp和eqrefELBO可以得到：","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"$","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"\\begin{equation} \\log p(\\boldsymbol{x}) = KL(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z}|\\boldsymbol{x})) + ELBO(q) \\end{equation} $","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"上面式左边是证据，由于KL散度大于等于0，因而右边的第二项ELBO也就称作证据下界。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/#Variational-Autoencoder","page":"Understanding Variational Autoencoder","title":"Variational Autoencoder","text":"","category":"section"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"关于VAE的文章很多，这里就不详细介绍了。[VAE][]的原文不太好读懂，建议先读[Tutorial on Variational Autoencoders][]，然后可以看看一些代码实现，比如Variational Autoencoder: Intuition and Implementation，和这里Variational Autoencoders Explained。","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/#Read-More","page":"Understanding Variational Autoencoder","title":"Read More","text":"","category":"section"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"[A Beginner's Guide to Variational Methods: Mean-Field Approximation][]\nVariational Coin Toss\nVariational Inference: A Review for Statisticians","category":"page"},{"location":"essays/Understanding_Variational_Autoencoder/","page":"Understanding Variational Autoencoder","title":"Understanding Variational Autoencoder","text":"[Gibb's inequality]:https://en.wikipedia.org/wiki/Gibbs%27_inequality [SR]:https://book.douban.com/subject/26607925/ [A Beginner's Guide to Variational Methods: Mean-Field Approximation]:http://blog.evjang.com/2016/08/variational-bayes.html [Tutorial on Variational Autoencoders]:https://arxiv.org/abs/1606.05908 [VAE]:https://arxiv.org/abs/1312.6114","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"keywords: FunctionalProgramming,Clojure CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/#Recursion","page":"Recursion","title":"Recursion","text":"","category":"section"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"在clojure中，主要靠递归来实现循环控制结构。记得在《c和指针》关于递归和迭代还有过详细介绍，有一些将二者互换的练习，如何形象地理解二者可以看这里。从时间复杂度上来说，二者是等价的。通常将循环结构改写成递归结构的伪代码可以这么写：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"for(init, end-condition, change-state)\n    do-something-here\n    \nf(state, & args)\n    condition-meet?\n        yes-do-something-and-return\n        no-please-recur(state-update, do-something-with-args-and-return-updated-args)","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"当然，递归调用可以发生在函数体内的任何地方，不过，有一类特殊的递归发生在函数返回的地方，称为尾递归（Tail Call）。正是因为发生在函数返回的地方，函数体内的运行时信息不再需要保存，因而可以做到尾递归优化(TCO)。不过，受限于JVM，clojure的实现里，并不能直接做到TCO，举例如下：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(defn f [n] \n  (if (> n 0)\n    (f (dec n))\n    0))\n\n(f 100)     ; 0\n(f 100000)  ; StackOverflowError   clojure.lang.Numbers$LongOps.combine (Numbers.java:419)","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"不过在clojure中，提供了一种类似goto的语法，即loop和recur来实现从函数尾部跳转。如果函数体内没有显式地提供loop语句，则会跳转到函数开始处。这里loop在语义上和let语句是等价的，只不过添加了一个标记方便编译器识别。使用recur需要注意的是只能写在函数的返回处，不能像普通的递归一样对递归调用的结果做二次处理。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(defn factorial [x]\n  (if (= 1 x)\n   1\n   (* x (factorial (dec x)))))\n;; it's ok, but...\n(factorial 10000N)  ;; CompilerException java.lang.StackOverflowError\n\n(defn factorial-recur1 [x]\n  (if (= 1 x)\n    1\n    (* x (recur (dec x)))))\n;; this version will not pass compile\n;; CompilerException java.lang.UnsupportedOperationException: Can only recur from tail position\n\n(defn factorial-recur2 [x]\n  (loop [n x\n         acc 1]\n    (if (= 1 n)\n      acc\n      (recur (dec n) (* n acc)))))","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"接下来考虑另一种情况，mutual recursion。假设定义了如下两个函数my-even和my-odd：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(declare my-odd? my-even?)    ;; make forward declarations first\n(defn my-odd? [n]\n      (if (= n 0)\n          false\n         (my-even? (dec n))))\n(defn my-even? [n]\n      (if (= n 0)\n          true\n         (my-odd? (dec n))))\n         \n(my-even? 10000)  ;; CompilerException java.lang.StackOverflowError","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"这里，由于在函数的结尾处是相互递归调用，需要保存堆栈信息，因此会造成StackOverflow，前面我们借用了loop和recur实现了优化，那么这里能否用同样的套路呢?结果是不能！因为这样做相当于从一个函数内部goto到了另一个函数内部，recur显然是不会支持这样的操作的。为了解决这个问题，clojure中提供了一个有趣的函数trampoline。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(defn trampoline\n  ([f]\n     (let [ret (f)]\n       (if (fn? ret)\n         (recur ret)\n         ret)))\n  ([f & args]\n     (trampoline #(apply f args))))","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"其思想就是，每次执行完函数后，判断返回值是否仍然是函数，如果是，则recur然后继续执行，否则返回该值。然后，我们可以将my-odd和my-even最后的函数互调用封装在一个lambda函数里，由trampoline去执行。由于返回值是一个lambda函数，相当于立即返回了，因而不会再有StackOverflowError的问题。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(declare my-even-helper? my-odd-helper?)  ;; make forward declarations first\n\n(defn my-even-helper? [n]\n  (if (zero? n)\n    true\n    #(my-odd-helper? (dec n))))\n\n(defn my-odd-helper? [n]\n  (if (zero? n)\n    false\n    #(my-even-helper? (dec n))))\n\n(def my-even-new? (partial trampoline my-even-helper?))\n(def my-odd-new? (partial trampoline my-odd-helper?))","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"除了用来解决mutual recursion的问题之外，trampoline还可以很优雅地用于解决有限状态机的问题，具体可以参考一些这里的例子.","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/#Memoize","page":"Recursion","title":"Memoize","text":"","category":"section"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"前面只是对recursion做了个简单的回顾，接下来聊一个自己写代码过程中实际遇到的问题。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"问题是这样子的，[Collatz Conjecture][]的简单描述如下：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"给定任意一个正整数：1) 如果这个数是偶数，则对它除以2；2) 如果这个数是奇数，则对它乘以3以后加1。如此循环下去，最后都能够得到1。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"找到1000000以内的某个数使得其收敛到1的步骤最长。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"这里先不做过多的数学分析，先看一个最naive的版本：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(defn collatz-cnt [x]\n  (loop [x x c 1]\n    (if (= 1 x)\n      c\n      (recur (if (even? x) \n               (/ x 2)\n               (inc (* 3 x)))\n             (inc c)))))\n             \n(time (reduce #(let [c (collatz-cnt %2)]\n                 (if (> c (first %1))\n                   [c %2]\n                   %1))\n              [0 0]\n              (range 1 1000000 2)))\n;\"Elapsed time: 8867.352869 msecs\"\n;[525 837799]","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"这么做显然很耗时，通过简单分析可以看出，遍历求collatz-cnt的过程中，会有大量的重复计算。如果能把中间结果缓存起来，那么应该能减少很多计算量。clojure中提供了一个memoize函数专门用来缓存函数调用的中间结果，与Python3中functoolslru_cache有点类似（不过没有lru）。其实现如下：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(defn memoize\n  [f]\n  (let [mem (atom {})]\n    (fn [& args]\n      (if-let [e (find @mem args)]\n        (val e)\n        (let [ret (apply f args)]\n          (swap! mem assoc args ret)\n          ret)))))","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"内部实际上就是通过(atom )来实现缓存的，于是，我先简单地写了个缓存的版本：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(def collatz-cnt-memo (memoize collatz-cnt))\n\n(time (reduce #(let [c (collatz-cnt-memo %2)]\n                 (if (> c (first %1))\n                   [c %2]\n                   %1))\n              [0 0]\n              (range 1 1000000 2)))\n;\"Elapsed time: 8916.976351 msecs\"\n;[525 837799]","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"不过跑完才发现，压根没有缓存，仍然是那么慢，仔细分析了下，是因为缓存的时候只对collatz-cnt-memo的参数做了缓存，并没有对collatz-cnt函数的参数做缓存。于是，写出了另一个版本：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(def collatz-cnt-memo2 \n  (memoize (fn [x]\n             (if (= 1 x)\n               1\n               (if (even? x) \n                 (inc (collatz-cnt-memo2 (/ x 2)))\n                 (inc (collatz-cnt-memo2 (inc (* 3 x)))))))))","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"看起来很完美，每次调用函数的时候，在尾部递归调用自己，而collatz-cnt-memo2函数又是缓存了的，效率应该提升很多。等等，似乎，这个并不是尾递归调用，会不会......StackOverflowError!!!试试(collatz-cnt-memo2 837799)果然如此。那，能否用recur来替换掉内部的递归呢？我自己试了下，几乎很难同时用recur和memoize来实现，比较接近一点的实现是不使用memoize函数，而是自己用宏实现一个类似的缓存机制（这样的做法显然不够优雅）。联想到前面的trampoline函数，可以尝试写出这样的版本：","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"(def collatz-cnt-memo3 \n  (memoize (fn [x c]\n             (if (= 1 x)\n               c\n               (if (even? x) \n                 #(collatz-cnt-memo3 (/ x 2) (inc c))\n                 #(collatz-cnt-memo3 (inc (* 3 x)) (inc c)))))))\n(def collatz-cnt-memo3 (partial trampoline collatz-cnt-memo3))","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"似乎，解决了StackOverflow的问题，然而，这个函数并没有实现真正意义上的缓存，因为函数内部迭代的时候，传入了两个参数x和c，显然我们希望缓存的是fn x而不是fn x c，但是，如果只传一个参数x，又没法做到尾递归（最后需要一个inc操作递归的返回值，使得count + 1），似乎，陷入了一个怪圈......","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"关于如何一步步优化这个问题的clojure代码，可以看这里(确实要比C++和python的代码都要慢很多)。接下来转向另外一个话题。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/#Y-Combinator","page":"Recursion","title":"Y Combinator","text":"","category":"section"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"看了一个周末，对自己的智商产生了怀疑......😂😂😂感觉，理解了是怎么回事，并没有体会到其中的精髓，建议看看wikipedia。","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/#Reference","page":"Recursion","title":"Reference","text":"","category":"section"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"Trampolining through mutual recursion with Clojure\nClojure Doc - trampoline\n详解Clojure的递归(上）—— 直接递归及优化\n详解Clojure的递归（下）——相互递归和trampoline\nIn Clojure, is it possible to combine memoization and tail call optimization?\nHow do I generate memoized recursive functions in Clojure?\nRecursions without names: Introduction to the Y combinator in clojure\nThe Y combinator in clojure\nY combinator real life application: recursive memoization in clojure\nThe Y Combinator (Slight Return)","category":"page"},{"location":"essays/Recursion_Memoize_Y-Combinator_in_Clojure/","page":"Recursion","title":"Recursion","text":"[Collatz Conjecture]:https://en.wikipedia.org/wiki/Collatz_conjecture","category":"page"},{"location":"blogroll.en/#Blogroll","page":"🔗 Blogroll","title":"🔗 Blogroll","text":"","category":"section"},{"location":"blogroll.en/","page":"🔗 Blogroll","title":"🔗 Blogroll","text":"Following are some interesting sites I'd like to share with you. Feel free to add yours here by clicking the Edit on Github link on the top right corner of this page.","category":"page"},{"location":"blogroll.en/#[laike9m](https://laike9m.com/)-(En/Zh)","page":"🔗 Blogroll","title":"laike9m (En/Zh)","text":"","category":"section"},{"location":"blogroll.en/#[Roger-Luo](https://rogerluo.dev/)-(En)","page":"🔗 Blogroll","title":"Roger Luo (En)","text":"","category":"section"},{"location":"blogroll.en/#[Ronnie-Wang](http://wattlebird.github.io/)-(Zh)","page":"🔗 Blogroll","title":"Ronnie Wang (Zh)","text":"","category":"section"},{"location":"blogroll.en/#[Hongxu-Xu](https://xuhongxu.com)-(Zh)","page":"🔗 Blogroll","title":"Hongxu Xu (Zh)","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"","category":"page"},{"location":"essays/Test/#keywords:-test1,test2","page":"Markdown Basics","title":"keywords: test1,test2","text":"","category":"section"},{"location":"essays/Test/#Markdown-Basics","page":"Markdown Basics","title":"Markdown Basics","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"以下是引用：","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"This is a MPE extended feature.","category":"page"},{"location":"essays/Test/#加粗，斜体，删除等","page":"Markdown Basics","title":"加粗，斜体，删除等","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"This text will be italic This will also be italic","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"This text will be bold This will also be bold","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"You can combine them","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"~~This text will be strikethrough~~","category":"page"},{"location":"essays/Test/#无序列表(嵌套)","page":"Markdown Basics","title":"无序列表(嵌套)","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"Item 1\nItem 2\nItem 2a\nItem 2b","category":"page"},{"location":"essays/Test/#有序列表（嵌套）","page":"Markdown Basics","title":"有序列表（嵌套）","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"Item 1\nItem 2\nItem 3\nItem 3a\nItem 3b","category":"page"},{"location":"essays/Test/#图片","page":"Markdown Basics","title":"图片","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"(Image: GitHub Logo)","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"(Image: Remote IMG)","category":"page"},{"location":"essays/Test/#链接","page":"Markdown Basics","title":"链接","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"http://github.com - automatic! GitHub","category":"page"},{"location":"essays/Test/#横线","page":"Markdown Basics","title":"横线","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"Hyphens","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"Asterisks","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"___","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"Underscores","category":"page"},{"location":"essays/Test/#Inline-code","page":"Markdown Basics","title":"Inline code","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"For example: lambda x: x^2.","category":"page"},{"location":"essays/Test/#Code","page":"Markdown Basics","title":"Code","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"python and julia only","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"import os\nos.listdir('.')","category":"page"},{"location":"essays/Test/#Tables","page":"Markdown Basics","title":"Tables","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"You can create tables by assembling a list of words and dividing them with hyphens - (for the first row), and then separating each column with a pipe |:  ","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"First Header Second Header\nContent from cell 1 Content from cell 2\nContent in the first column Content in the second column","category":"page"},{"location":"essays/Test/#Emoji-and-Font-Awesome","page":"Markdown Basics","title":"Emoji & Font-Awesome","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"This only works for markdown-it parser but not pandoc parser.   Enabled by default. You can disable it from the package settings.  :thumbsup:","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":":smile: :fa-car:","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":":smile:\n:fa-car:","category":"page"},{"location":"essays/Test/#Footnotes","page":"Markdown Basics","title":"Footnotes","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"Content [1]","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"[1]: Hi! This is a footnote","category":"page"},{"location":"essays/Test/#Mark","page":"Markdown Basics","title":"Mark","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"==marked==","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"==marked==","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"<div class=\"alert alert-success\"> Great! </div>","category":"page"},{"location":"essays/Test/#Equation","page":"Markdown Basics","title":"Equation","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"$","category":"page"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"\\begin{equation} a^2 + b^2 = c^2 \\end{equation} $","category":"page"},{"location":"essays/Test/#References","page":"Markdown Basics","title":"References","text":"","category":"section"},{"location":"essays/Test/","page":"Markdown Basics","title":"Markdown Basics","text":"Mastering Markdown\nDaring Fireball: Markdown Basics","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"keywords: Game,ReinforcementLearning,Hanabi CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Lets_Play_Hanabi/#Let's-Play-Hanabi!","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"Papers are removed. (2021-08-12)","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"This blog provides some detailed information for my lighting talk on JuliaCon 2019 (Let's Play Hanabi!).","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"You may find the slide here and the source code here.","category":"page"},{"location":"essays/Lets_Play_Hanabi/#The-Rainbow-Algorithm","page":"Let's Play Hanabi!","title":"The Rainbow Algorithm","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"Writing the Rainbow algorithm in Julia is relatively easy. It's just three dense layer together with a projection step. Although the structure is simple, it's not always that easy to make it work as we expect. Many parameters need to be tuned and some steps are not well documented in the original paper. (The evil lives in details!) You may read Understanding Prioritized Experience Replay to get a better understanding of what I mean here. To make things easier, I just keep all the parameters and loss calculation step the same with the original implementation in deepmind/hanabi-learning-environment. And the result shows that these two implementation behaves similarly, except the speed.","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"With CPU only, the Flux based implementation is much slower compared to the TensorFlow based one. One of the most important reason is that TensorFlow will utilize available CPU as much as possible, even I manually change tf.device(\"/cpu:*\") into tf.device(\"/cpu:0\") or tf.device(\"/cpu:1\"). So instead, I rerun the TensorFlow code in a docker environment with only 1 cpu allocated (by setting --cpuset-cpus=0) and the training speed decreased from 258 steps per second into 200. There's still an obvious advantage compared to my Julia implementation. I did some benchmark, it seems that the backpropagation step was the bottleneck. I tried to switch the Tracker into Zygote, hoping that it could be faster. However a strange error occurred and I was not sure how to fix it at that time.","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"With GPU enabled, the Flux based implementation is much faster. The speedup comes from two parts: the fused broadcast and @view. With fused broadcast, we can speed up the projection step. In theory, if we turn on the XLA in TensorFlow, we should witness similar improvement in the TensorFlow version. But I found that simply using the session config as described here in the original implementation seems not work. I guess that the reason is that some CPU computing steps are included in the training op. I haven't tried to manually optimize only the projection step yet.","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"The more interesting thing is that, the same Julia code runs faster on RTX 2080 TI compared to V100. The benchmark of a simple matrix multiplication shows that, for the size of 512 * 512 (the hidden layer size in my problem) it is about 1/3 faster on RTX 2080 TI. But for some large matrix multiplication, say 8192 * 8192, there isn't much difference on these two cards.","category":"page"},{"location":"essays/Lets_Play_Hanabi/#Distributed-Experience-Replay-Buffer","page":"Let's Play Hanabi!","title":"Distributed Experience Replay Buffer","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"You may think it is relatively easy to adapt the Rainbow algorithm to the distributed version, after all Julia has a good support for parallel computing. But after some attempts, I must admit that there's no easy way. If we choose the multi-threading based implementation, obviously it can't be applied to multiple machines. If we choose the multi-processing, then the performance is not that good (I'll explain it soon). So it seems that a hybrid mode would be great, but that needs a delicate design.","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"Th Ape-X contains a learner and multiple actors. Each one can live in an independent processor. The difficult part is how to communicate between learner and actors. Here learner and actor both run very fast. The learner runs on a GPU and the actor only do forward inference. And the communication contains four parts:","category":"page"},{"location":"essays/Lets_Play_Hanabi/#Parameter-Sharing","page":"Let's Play Hanabi!","title":"Parameter Sharing","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"Actors need to update their parameters periodically from the learner. Assuming that we have hundreds of actors, each time an actor invoke a remote call, it will slow down the speed of the learner. So the best way is that the learner periodically send it's parameters to a intermediate scheduler and let it communicate with other actors.","category":"page"},{"location":"essays/Lets_Play_Hanabi/#Experience-Updating","page":"Let's Play Hanabi!","title":"Experience Updating","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"Actors will generate experiences as fast as possible with priorities pre-calculated. Then those experiences are cached locally for a while and sent to the global Prioritized Experience Replay Buffer. There shouldn't be any problem if the global buffer is an independent processor.","category":"page"},{"location":"essays/Lets_Play_Hanabi/#Sample-Generation","page":"Let's Play Hanabi!","title":"Sample Generation","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"If the global Prioritized Experience Replay Buffer is in the same processor, then the experience updating step will slow down the learner. Otherwise, there's a overhead to copy experiences to the learner. I found it hard to balance these two.","category":"page"},{"location":"essays/Lets_Play_Hanabi/#Experience-Priority-Updating","page":"Let's Play Hanabi!","title":"Experience Priority Updating","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"All the experiences consumed by the learner will be updated with new priorities.","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"As you can see, there are multiple steps updating the global experience replay buffer simultaneously. In the pytorch implementation, there's a good picture demonstrating each component.","category":"page"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"My feeling is that, it's really hard to keep the speed of learner and actor well balanced.","category":"page"},{"location":"essays/Lets_Play_Hanabi/#Bayesian-Action-Decoder","page":"Let's Play Hanabi!","title":"Bayesian Action Decoder","text":"","category":"section"},{"location":"essays/Lets_Play_Hanabi/","page":"Let's Play Hanabi!","title":"Let's Play Hanabi!","text":"This method is really elegant. The only problem is that it runs too slow. I'll update this part once I finished changing the original policy gradient based implementation into value based methods.","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"keywords: Clojure,GIF CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/#About-Quil","page":"About Quil","title":"About Quil","text":"","category":"section"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"[Quil][]是Clojure下用来画图的一个库，对[Processing][]做了封装。Processing想必大家都知道，用来画图非常有意思，我第一次接触Processing是在图书馆里看到了代码本色：用编程模拟自然系统 [The Nature of Code：Simulating Natural Systems with Processing]。不过只是大致翻了翻，有个基本的印象，最近碰巧想到用clojure来画图，于是找到了quil这个库。Processing这个库本身是用java写的（现在已经有很多语言的扩展了），因此用clojure写起来相当方便，而且得益于clojure中许多函数式编程的思想，写代码的感觉非常顺畅！以后深入了解下二者后写个详细的对比分析。本文主要是记录下平时写的一些比较有意思的动图。","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"[Quil]:http://quil.info/ [Processing]:https://processing.org/","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/#Lissajous-曲线的动画演示","page":"About Quil","title":"Lissajous 曲线的动画演示","text":"","category":"section"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"第一次看到Lissajous曲线是从Matrix67的文章里看到的，这类曲线还是蛮有意思的，包括Quil官网上也有几个类似的例子，这里我也用Quil画了一个图~","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"(Image: Lissajous.gif)","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"代码如下：","category":"page"},{"location":"essays/Some_Interesting_Quil_Examples/","page":"About Quil","title":"About Quil","text":"(ns hello-quil.core\n  (:require [quil.core :as q]\n            [quil.middleware :as m]))\n\n(defn setup []\n  (q/frame-rate 30)\n  (q/background 255)\n  (q/color-mode :hsb 10 1 1))\n\n(defn f  [t]\n  [(* 200 (q/sin  (* t 13))) (* 200 (q/sin  (* t 18))) ])\n\n(defn draw-plot [f from to step]\n  (doseq [two-points (->> (range from to step)\n                          (map f)\n                          (partition 2 1))]\n    (apply q/line two-points)))\n\n(defn draw []\n  (q/with-translation  [(/  (q/width) 2)  (/  (q/height) 2)]\n    (let [t (/  (q/frame-count) 80)]\n      (q/stroke  1 1 1)\n      (q/line (f t)\n              (f (+ t (/ 1 80))))\n      (q/save-frame \"./data/Lissajous-####.png\"))))\n\n(q/defsketch trigonometry\n  :size  [500 500]\n  :draw draw\n  :setup setup)\n","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"keywords: Web,Django,Clojure,Flask,Python CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/About_This_Site/#About-This-Site","page":"About This Site","title":"About This Site","text":"","category":"section"},{"location":"essays/About_This_Site/#TODO","page":"About This Site","title":"TODO","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"貌似又出了一次故障，看来得抽空重写下这个后台了。。。 这次得好好思考下了（至少得管个三五年吧......）。","category":"page"},{"location":"essays/About_This_Site/#记录个意外","page":"About This Site","title":"记录个意外","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"前天手抽不知为何意外删除了Dropbox的同步目录，清楚地记得删的是软链接，卡住有两三秒没删完，猛地觉得不对，赶紧Ctrl+C撤销了，然并卵，网速出奇地好，Server迅速同步了。后来发现Dropbox居然还有恢复功能，兴高采烈地恢复了。然而，忘了关掉文件监视器，于是所有被删掉的文件又刷新了一遍。。。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"算了，懒得再恢复时间戳了，权当留个纪念吧。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"<hr>","category":"page"},{"location":"essays/About_This_Site/#BugFix","page":"About This Site","title":"BugFix","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"在尝试了OneDrive（最新版有个坑爹的bug，由于采用了lazy同步的模式，某些目录没法直接通过代码访问）、GoogleDrive（家里的电脑安装不上。。。居然没代理）之后，改用了Dropbox同步static file，刚发现其同步模式居然是先删掉本地文件再下载并创建，导致watchdog也同样做了一次这样的操作，于是文章的创建时间和更新时间都会变成最近一次更新。考虑到delete是低频且高危的操作，先将其从watchdog的监听事件里删了，这样只能手动到后台执行命令删除，算是个折中的解决方案吧。","category":"page"},{"location":"essays/About_This_Site/#Update","page":"About This Site","title":"Update","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"最近好不容易挤了些时间更新了下本站，算是保持了一年一更的节奏吧:laughing:。事实上，更新本站最主要的原因是，最近这段时间都没有用Clojure了，以至于一直没空做一些更新，这次干脆把许多想要做的更新都做了。后端用的flask，加了些同步机制和https。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"这半年变化挺大的，包括心态，工作，工具链等等。等了很久的Clojure 1.9终于发布了，不过却很少写了，倒是因为业余兴趣的需要，转向了Julialang，至于兴趣能坚持多久，随缘吧。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"原来tianjun.ml的域名，在十一长假期间忘了续，结果被抢注了，居然还有这种操作......，吓得我赶紧又注册了个juntian.me的域名重定向到了目前的这个网站上。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"这次更新的过程中，删了部分没啥营养的文章（主要是不知道怎么写英文的title，至于为什么文章title都换成英文的了，啊，说来话长），部分评论迁移的时候没了（真的是没了，不是我删了，要怪就怪disqus咯）。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"后面本站应该会频繁更新一段时间，主要是NLP方面的一些内容，也算是对过去的半年有个交代吧~","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"<hr>","category":"page"},{"location":"essays/About_This_Site/#记录下用Clojure重写的本站的过程","page":"About This Site","title":"记录下用Clojure重写的本站的过程","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"最早打算重写这个网站的原因是为了方便同步网站的信息。由于以前是自己写的后台管理页面，每次更新内容都需要在网页上写东西，以前可能不是太大的问题，不过现在在家里的网总是断断续续的，而且近来记录笔记的习惯也倾向于本地化记录了，所以打算在网站与本地之间开通个接口方便同步一些信息。另外，对网站的内容做了一些精简，希望以后写的东西还是更professional一些吧。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"其实，我也不知道整个过程花了多少时间，断断续续地，偶尔想起来的时候熟悉下相关库的api，遇到不懂的地方，也只能花时间死磕各个库的源码实现。不过，大部分代码应该是这几天放假的时候写的（总共也就几百行），源码可以在这里看到。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"记录几点体会吧：","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"抽象和隔离的意识要比以前强一些了，会有意识地从逻辑层和代码层抽出一些共通的部分出来；\n测试的引入会改变自己写代码的方式，会有意识地去考虑如何方便进行测试；\n对错误和异常的处理还缺少很深入的思考与实践；","category":"page"},{"location":"essays/About_This_Site/#BugFix-2","page":"About This Site","title":"BugFix","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"记录昨天fix的一个Bug，之前后台自动保存的功能出了个bug，直接导致一个文档的content同步覆盖掉了另一个文档的content。要命的是不知道怎么复现这个bug。查看log日志，所有的请求都正常。昨晚跟同学讨论了下，感觉应该是js自动保存逻辑出问题了。仔细review了下代码，果真是。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"原来的实现是，自动保存和markdown渲染封装在同一个按键检测事件里，并加入了一个10秒钟的延时，如果10秒钟内没有按键触发则发起PUT请求保存当前内容。原来的代码所存在的问题是，编辑一个文件的时候，如果10秒钟内切换到了另外一个文档，那么，会导致读取的id和content不一致，具体说明如下：","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"$('#response').keyup(function () {\n    var v = $('#response').val(),\n        s = markdown.core.mdToHtml(v);\n    $(\"#rendered\").html(s)\n    MathJax.Hub.Queue([\"Typeset\",MathJax.Hub,\"rendered\"]);\n\n    if(save_time_out) { clearTimeout(save_time_out); } //10 秒钟内检测到输入则重置延时\n    save_time_out = setTimeout(function () {\n        var ref = $('#tree-container').jstree(true),\n            sel = ref.get_selected();\n        if(!sel.length) { return false; }\n        sel = sel[0];\n        $.ajax({\n            type: \"PUT\",\n            url: \"/essays/\"+sel,\n            data: JSON.stringify({\"id\":sel, \"body\": v}), // 问题出在这里，\n            //PUT请求时，传递的是10秒钟前读到的v，\n            //而此时的blog_id（即变量sel）可能变了，\n            //导致一个文档的content更新到另一个文档里去了\n            // 更改后的代码每次PUT重新读取当前的content和id\n            // data: JSON.stringify({\"id\":sel, \"body\": $('#response').val() }),\n            contentType: \"application/json; charset=utf-8\",\n            datatype: \"json\",\n            success: function(data){\n                save_tree(\"Blog \" + sel + \" Content AutoSaved: \")\n            },\n            failure: function(err){console.log(err)}\n        })\n        }, \n        10000);\n});","category":"page"},{"location":"essays/About_This_Site/#Update-2","page":"About This Site","title":"Update","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"貌似这个网站保持每年更新一次的频率。最近这次又重新折腾了下，不过目前依然是半成品。这次折腾的时间稍微有点长，前前后后大概有一个月时间吧。先说说改版的原因：","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"印象笔记基本被我弃用，而且原来写的网站后台同步系统有点小bug一直没有修复；\n最近一段时间学习了下Clojure，挺有意思的一门语言，想动手实践下；\n原来的HTML5模板总觉得被我改的有点丑，想再重新写一版；\n希望将网站的后台管理系统设计成个性化的笔记管理系统，一定程度上替代印象笔记，为知笔记等；","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"针对上面几点，分别对网站做了以下改进：","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"抛弃原来的同步系统后，重写了后台的文档管理体系统，整个编辑界面借鉴了作业部落的设计方案，双屏切分（左边编辑，右边预览），导航栏用于管理文档结构，由于是自己用，舍弃了账户管理模块；\n网页框架采用了luminus，我觉得这就是个大杂烩，把各个优秀的部件组织在一起，然后提供一些高可用的模板，上手非常方便。数据存储方面，抛弃了之前用的SQLite，换了Redis（没别的原因，只是对Redis用着熟悉点），文件存储上，仍然采用了七牛云存储，qiniu-clojure-sdk的作者封装得真简洁......网页权限管理用到了之前说的Buddy，简单易行；后台管理的安全性方面，目前暂时把csrf模块给去掉了，因为后台有很多的ajax请求，还没想好该怎么绑定csrf-token，缺少这方面的经验，这应该是整个网站最大的安全漏洞；\n重写前端页面。这块挺花时间的，主要是自己对js不熟，又重新翻了下JavaScript高级程序设计这本书，然后熟悉了下jquery和react，感觉react写前端的想法确实有点不太一样，然后继续往前学习了下ClojureScript以及对react封装的库OM，完全刷新了我对前端的认识（我承认之前一直很BS前端干的活......)，然而时间精力有限，这些都仅仅是浅尝辄止。最后前端部分主要用jquery写的；","category":"page"},{"location":"essays/About_This_Site/#说说感受","page":"About This Site","title":"说说感受","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"整个从前端到后端全都写了一遍，说实话，觉得挺累的。很多地方都是从零开始，完全没有经验可谈。除了HTML是在WebStorm下写的，其余都是在vim下写的，并不是我排斥IDE，而是IDE用着效率太低了。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"总的来说，我挺喜欢Clojure这门语言的，简洁，有魔力！可惜的是我到目前为止还算不上入门，也没体会到其在处理并发问题上的优势。而且，最近写clojure的过程中，也读了不少框架的源码，感觉很多代码还是很难懂。接下来的一段时间估计没空深入学习了，毕竟clojure又不能拿来跑RNN......我能想到后面会用到clojure的地方估计就是用它来写SICP的习题了......","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"","category":"page"},{"location":"essays/About_This_Site/#写在前面","page":"About This Site","title":"写在前面","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"之前网站一直放在SAE上，除了每月扣点豆子，用着也没啥问题，除了扩展性不太好之外。不过，间歇性的出了几次意外，后台往sql中写入数据的时候，不知道是啥原因，提交后页面卡死了，然后再去sae后台一看，哗啦啦几百豆子没了......我总共才送了１.5k，无语了。想了半天也没找出时什么原因，只知道是全都扣在sql的读写上了。也罢，懒得在上面折腾了，写的东西暂时都放在印象笔记里。前些天忽然想起来github送的DigitalOcean优惠券还没用，最近有点闲时间，再折腾了一把。之前的后台是刚熟悉python的时候写的，现在再看看，真是渣渣......然后动手重新写了一遍部署到DO上（回头看了一下，其实还是渣渣......忧桑）。这段时间用印象笔记用着很爽，主要是方便，所以，这次后台的改动主要就一个，利用Evernote的api把网站后台跟印象笔记打通了，这样便于随时积累，持续更新。~~另外，rss给去掉了，有兴趣的话加个印象笔记吧～~~","category":"page"},{"location":"essays/About_This_Site/#整体结构","page":"About This Site","title":"整体结构","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"怕自己以后给忘了，画个图，以后再修改起来也方便。(Image: 图1 Site Design)","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"跟印象笔记api打交道的过程中，坑很多，最惨的一个莫过于，在sandbox中测试的好好的，换成印象笔记的token后就出错了,各种google，居然有人给出了解决方案,把service_host改一下就好了，另外这里只是简单采用轮询的方式，因为对实时性要求不高，所以没用所谓的webhook。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"目前网站布在新加坡节点，感觉速度上还行吧，没有网上说的那么差。万一不稳定了再换换。新加坡的节点有ipv6这个很不错。配合shadowsocks用着很快。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"其实本来打算把shares部分大改的，主要是想跟自己的虾米账户打通，已经写了一半了，忽然发现国外不能访问国内的虾米，真是个蛋疼的世界。唉，真是应了那句话。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"墙外的想到墙内去，墙内的想到墙外来......","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"算了，以后有空再弄弄，往所里的电脑上布个代理做跳板。也许下次会直接弄个music的二级域名出来。","category":"page"},{"location":"essays/About_This_Site/#说点细节","page":"About This Site","title":"说点细节","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"印象笔记和数据库的同步通过定时器实现，由于印象笔记的特殊性，每一条笔记对应正文和资源（包括图片等附件）两部分，因此将同步过程分为两步。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"首先查询对应笔记本中每条笔记的更新时间，同时检索本地数据库中每一条记录的更新时间。然后提取需要更新和新建的记录。正文部分用正则做一个粗过滤（替换掉div,br标签）后写入数据库（其实可以经过markdown渲染之后再写入数据库，这样响应会更快，不过，这部分响应时间相比建立连接的时间而言可以忽略不计，而且有时候需要在后台查看下过滤的结果），同时提取附件相关的内容转换成链接格式。并将涉及到的资源写入数据库中的一张表。\n扫描上面的资源表，对于没有下载到本地和同步到cdn的资源分别下载和上传，并校验。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"分成两步的最主要原因是，如果附件比较大，很容易出现下载上传失败的情况，从而导致整个文档更新失败。将下载和上传部分独立出来后，不会影响文档内容的同步，如果某些大文件没法自动同步可手动在后台同步。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"最后绑定下域名，分别把www.tianjun.ml和www.tianjun.me通过301重定向到主域名上。","category":"page"},{"location":"essays/About_This_Site/#谈谈感受","page":"About This Site","title":"谈谈感受","text":"","category":"section"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"自己这么亲自折腾一把后，才会对现在的云平台带来的好处感受更深。其实说到底，像安装配置apache这些都是dirty work，云平台把这些集成后，可以说大大免去了这些苦力活，稳定性也有保证。","category":"page"},{"location":"essays/About_This_Site/","page":"About This Site","title":"About This Site","text":"很久没写点东西了，最近会陆陆续续整理些出来，坚持坚持～","category":"page"},{"location":"AMA.en/#Ask-Me-Anything","page":"Ask Me Anything","title":"Ask Me Anything","text":"","category":"section"},{"location":"AMA.en/","page":"Ask Me Anything","title":"Ask Me Anything","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/Some_Interesting_Papers/","page":"记录读过的一些有意思的Paper & PPT","title":"记录读过的一些有意思的Paper & PPT","text":"","category":"page"},{"location":"essays/Some_Interesting_Papers/","page":"记录读过的一些有意思的Paper & PPT","title":"记录读过的一些有意思的Paper & PPT","text":"keywords: Papers,Resources CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Some_Interesting_Papers/#记录读过的一些有意思的Paper-and-PPT","page":"记录读过的一些有意思的Paper & PPT","title":"记录读过的一些有意思的Paper & PPT","text":"","category":"section"},{"location":"essays/Some_Interesting_Papers/#NLP","page":"记录读过的一些有意思的Paper & PPT","title":"NLP","text":"","category":"section"},{"location":"essays/Some_Interesting_Papers/#ChatBot","page":"记录读过的一些有意思的Paper & PPT","title":"ChatBot","text":"","category":"section"},{"location":"essays/Some_Interesting_Papers/","page":"记录读过的一些有意思的Paper & PPT","title":"记录读过的一些有意思的Paper & PPT","text":"[ ] NeuralApproachestoConversationalAI.pdf","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"keywords: QuantumComputing,Julia CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Quantum_Computing/#量子计算入门","page":"量子计算入门","title":"量子计算入门","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"本文用于记录我学习量子计算的过程。","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"(Suspended due to priority change.)","category":"page"},{"location":"essays/Quantum_Computing/#Some-Key-Concepts","page":"量子计算入门","title":"Some Key Concepts","text":"","category":"section"},{"location":"essays/Quantum_Computing/#Bloch-Sphere","page":"量子计算入门","title":"Bloch Sphere","text":"","category":"section"},{"location":"essays/Quantum_Computing/#Resources","page":"量子计算入门","title":"Resources","text":"","category":"section"},{"location":"essays/Quantum_Computing/#Web-Pages","page":"量子计算入门","title":"Web Pages","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"Quantum computing for the very curious\nMichael Nielsen 写的简介，读下来很有收获，重新点燃了学习的兴趣！\nThe best resources for learning about quantum computing\n目前找到的最好的入门资料汇总。\nAwesome quantum machine learning\n量子计算与机器学习的结合。","category":"page"},{"location":"essays/Quantum_Computing/#Books","page":"量子计算入门","title":"Books","text":"","category":"section"},{"location":"essays/Quantum_Computing/#[Introduction-to-the-Theory-of-Computation](https://book.douban.com/subject/12986396/)","page":"量子计算入门","title":"Introduction to the Theory of Computation","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"(Image: Introduction_to_the_Theory_of_Computation.jpg)","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"这本书用来补一下有关计算复杂度的知识。 很意外，这本书的Part 1 部分，填补了之前读EOPL的一些关于Parser的空白。关于自动机，正则表达式，CFG的讲解一气呵成。Part2部分对图灵机有了更多的了解，halting啥的不再停留在表面的认识。读完Part3之后对复杂性有了新的的认识，之前看到有一个书评说，如果你在别人高谈阔论P，NP，NP-complete等问题时感到一脸懵逼，请立即抱起这本书，这里有你想要的答案。","category":"page"},{"location":"essays/Quantum_Computing/#[Quantum-Computing-Since-Democritus][QCSD]","page":"量子计算入门","title":"[Quantum Computing Since Democritus][QCSD]","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"(Image: Quantum_Computing_Since_Democritus.jpg)","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"这本书没法评价。","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"因为压根没读懂，水平有限，摊手......","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"前几章跟Quantum Computing的关系不大，开篇的冷笑话，真的好冷......以至于我真的只记住了那句话(有兴趣的话，可以去看看作者的博客)：","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"But if quantum mechanics isn't physics in the usual sense - if it's not about matter, or energy, or waves, or particles -then what is it about? From my perspective, it's about information and probabilities and observables, and how they relate to each other.","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"我能体会到作者独特的视角，无奈，自己相关的基础并不扎实，强行读到了第十章，后面的部分只是草草翻了下。后来偶然在网上看到了别人写的一篇review，深有同感。总的来说，如果你看到chapter1~8的标题之后，确认你对相关内容不那么陌生（不是熟悉或精通），那么可以断定这是一本非常值得一读的书，否则真的很难跟上作者的脚步（当然，你也可以像我一样，不妨先读读试试～）。Anyway，即使只读了前十章，也依然收获颇丰，许多亮点与前面提到的那篇review有许多共通之处。这里只说我感受最深的一点：","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"There are two ways to teach quantum mechanics. The first way - which for most physicists today is still the only way - follows the historical order in which the ideas were discovered... The second way to teach quantum mechanics eschews a blow-by-blow account of its discovery, and instead starts directly from the conceptual core - namely, a certain generalization of the laws of probability to allow minus signs )and more generally, complex numbers).","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"作者首先提到了目前学习量子原理的两种方式（作者在书中采取的是后者），然后说道：","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"Quantum mechanics is what you would inevitably come up with if you started from probability theory, and then said, let's try to generalize it so that the numbers we used to call \"probabilities\" can be negative numbers. As such, the theory could have been invented by mathematicians in the nineteenth century without any input from experiment. It wasn't, but it could have been.","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"是的，实验先于理论。另外两个类似的例子是进化论和狭义相对论。读到这里时，我联想到的是目前深度学习的现状，何其相似。作者认为：","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"More often than not, the only reason we need experiments is that we're not smart enough.","category":"page"},{"location":"essays/Quantum_Computing/#[Q-is-for-Quantum][QfQ]","page":"量子计算入门","title":"[Q is for Quantum][QfQ]","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"(Image: Q_IS_FOR_QUANTUM)","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"吸取读上一本书的教训，还是先从简单点的入手。这本小册子很薄，总共150多页。作者构建了一个PETE BOX，用图形化的语言来阐述量子计算相关的一些概念。","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"PART 1 部分，对比经典计算机中的与或非门，清晰地描述了量子门(PETE BOX)的特性。","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"关键词：","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"superposition / misty state\ninterfere\ncollision","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"PART 2 部分，用一个很形象的例子（心灵感应?）讲清楚了一个很有意思的现象：","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"Entanglement","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"PART 3展开讨论了什么是REALITY，这部分相比前两部分理解得没那么透彻。照惯例，附上两篇书评：","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"Q is for Quantum & “reality”\nReview: Q is for Quantum by Terry Rudolph","category":"page"},{"location":"essays/Quantum_Computing/#[Picturing-Quantum-Processes][PQP]","page":"量子计算入门","title":"[Picturing Quantum Processes][PQP]","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"(Image: Picturing Quantum Processes)","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"感觉这本书更适合在有一点点量子计算的基础之后再读，然后应该会有种耳目一新的感觉，居然还能采用这种方式来描述。目前读了大约1/5，基本能跟上作者的节奏，读这本书之前稍微回顾下线性计算会好点，有利于融会贯通。暂时需要先放下来，因为读这本书对我这种新手来说会比较累，需要同时理解两套理念（尽管二者并非独立的关系），留到后面有一定基础了再看下。","category":"page"},{"location":"essays/Quantum_Computing/#[Quantum*Computation*and*Quantum*Information][QCQI]","page":"量子计算入门","title":"[QuantumComputationandQuantumInformation][QCQI]","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"(Image: Quantum_Computation_and_Quantum_Information)","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"这本书同步进行中。","category":"page"},{"location":"essays/Quantum_Computing/#[Linear-Algebra-Done-Right-(3rd-ed)][LADR]","page":"量子计算入门","title":"[Linear Algebra Done Right (3rd ed)][LADR]","text":"","category":"section"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"(Image: Linear_Algebra_Done_Right)","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"有些线性代数相关的部分需要回顾下。","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"这本书对应的Solution","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"此外，关于线性代数，3Blue1Brown这个视频合集也很不错。","category":"page"},{"location":"essays/Quantum_Computing/","page":"量子计算入门","title":"量子计算入门","text":"[QCQI]: https://book.douban.com/subject/6937989/ [LADR]: https://book.douban.com/subject/26265880/ [PQP]: https://book.douban.com/subject/26995979/ [QfQ]: https://book.douban.com/subject/27167701/ [QCSD]: https://book.douban.com/subject/12030716/","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"keywords: Python,Lisp,Hylang CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Write_Python_in_Lisp/#Write-Python-in-Lisp","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"","category":"section"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"上周在Clojure微信群里，Steve Chan分享了个关于Hylang的链接，让人眼前一亮，原来Python居然还可以这么写！经过这几天的摸索，意外地感觉不错，在这里推荐给大家试试，有兴趣的话可以看完官网的doc后再回来看下文。","category":"page"},{"location":"essays/Write_Python_in_Lisp/#Hylang是什么？","page":"Write Python in Lisp","title":"Hylang是什么？","text":"","category":"section"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"Hy是基于python的lisp方言，与python的互操作非常顺畅，有点类似clojure于java的关系。从安装上可以看出，Hy实际上就是一个普通的python库，在python代码中可以直接import hy之后，把.hy文件当做普通的python文件，import其中的变量。核心代码部分，该有的也都有（最重要的当然是macro），可以从clojure无障碍迁移过来。","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"由于是直接把lisp代码转换成AST，开启--spy模式之后，可以看到每一行lisp代码转换之后的python代码，各种库的操作也完全没有障碍。试用了一些常用的库，基本没有什么大问题。目前感觉不是够顺畅的地方，反而是一些外围，比如没有很好的编辑环境。社区的vim插件提供的功能很弱，为此我特地入坑spacemacs！emacs对应的插件稍微好点，提供了发送代码到repl的功能，不过最重要的仍然是，没有代码补全，网上有人提供了一些静态的补全方案，通过提取hy库中的关键词和当前buffer中的变量名来补全（没有配置成功......），不过实际使用中会大量调用python库，因此急需像python里的anaconda-mode一类工具提供辅助补全。再比如静态语法检查，调试。","category":"page"},{"location":"essays/Write_Python_in_Lisp/#Hylang不是......","page":"Write Python in Lisp","title":"Hylang不是......","text":"","category":"section"},{"location":"essays/Write_Python_in_Lisp/#Hylang不是Clojure","page":"Write Python in Lisp","title":"Hylang不是Clojure","text":"","category":"section"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"这个是首先需要意识到的一点。尽管在语法和许多函数上和clojure很像，但是因为底层实现和语言的定位不一样，这其中的许多函数不再是clojure中对应函数的完整复制。以下列举一些很容易碰到的问题：","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"muttable & immutable. Hylang本身的定位是鼓励与python的互操作，因此大量的操作都是基于python本身的数据结构，需要非常小心数据随时都可能改变。在写Hylang代码的时候需要时刻提醒自己，“我写的是python代码！代码都会最终转换成python代码去执行！”，社区里最近也在讨论引入immutable的数据结构，不知道这块以后会怎么发展。\nlazy. Hylang中大多数代码的lazy实现都是基于generators实现的了iterable，这下就蛋疼了。在python里，生成器访问一次之后，如果你不保存的话，数据就没有了......所以你会发现(take n coll)中，如果xs是一个iterable的数据，上面的代码执行多次是可能得到不同结果的。甚至如果不保存的话，没法访问已经被访问过的内容。不过好在0.12.0之后提供了lazy sequences，一定程度上缓解了这个问题。\nin-place operations.在python中，许多函数都是默认in-place的，比如sort,random.shuffle等，有些可能提供了对应的非in-place的函数（如sorted），有些则没有。这点需要格外注意，否则，定义变量的时候很可能返回值就是个None。不过在numpy,tensorflow,pandas等库中，这点考虑得比较全面\nscope. 看github上过去关于let绑定的issue，可以深入了解这块内容。在不确定变量名的scope时，可以看看对应的python代码。","category":"page"},{"location":"essays/Write_Python_in_Lisp/#体验过程中的一些坑","page":"Write Python in Lisp","title":"体验过程中的一些坑","text":"","category":"section"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"文件名。写过了clojure的话会习惯-作为连接符，hy的文件名需要转换成_连接符，否则在python代码中不能import。\n某些函数的的实现有bug。我自己在尝试的过程中就发现了partition函数的实现有点问题，在github上提了个issue。社区里的反应还是挺快的，第二天就解决并合并到master上了。\n参数传递过程中，运用apply传递positional和named arguments时，需要分别用list和dict对二者封装，不能偷懒直接用一个list搞定。","category":"page"},{"location":"essays/Write_Python_in_Lisp/#Hylang适合写点什么？","page":"Write Python in Lisp","title":"Hylang适合写点什么？","text":"","category":"section"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"写Hylang也就这几天，对macro的感受还不是很强烈，主要是写了点日常的数据分析代码和tensorflow中的tutorial，以下是一些个人感受：","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"如果只是写一些调用API的代码，其实不太适合。比如我在翻译tensorflow的tutorial过程中，需要反复去查对应的API，很繁琐，而且已有的框架会在不知不觉中对写lisp风格的代码有一些限制，从而使得python代码更适合命令式地处理逻辑。\n适合更抽象层的数据预处理逻辑。这块写起来会很舒服，对读代码和写代码的人来说，都是一种享受。可以将二者结合，这部分代码用hy处理后以接口的形式暴露给模型构建部分，最后再用hy糅合train,valid,test的过程。当然，现在某些库（tensorlayer）实际上把直接跟tensorflow打交道的部分做了很浅的一层封装，整体易用性更高了。","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"最后，一点学习经验：","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"When I’m learning something new, I sometimes find myself practicing EDD (exception-driven development). I try to evaluate some code, get an exception or error message, and then Google the error message to figure out what the heck happened. – Mastering Clojure Macros","category":"page"},{"location":"essays/Write_Python_in_Lisp/","page":"Write Python in Lisp","title":"Write Python in Lisp","text":"另外，这个语言还是太小众了，玩玩就可以了，别太当真......","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"keywords: Thought,Chatbot CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/#漫谈聊天机器人","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"","category":"section"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"本文的主要目的是记录下这段时间关于Chatbot的一些思考。","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/#Act-Like-Robot","page":"漫谈聊天机器人","title":"Act Like Robot","text":"","category":"section"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"Chatbot的最初形态是提供一种人机接口，能够根据指令像机器人一样完成一些预定的动作（即Act Like Robot）。该任务的难点在于语义理解（LU）部分，假设语言能准确无误地转换成指令，那么所有Robot的控制都可以扩展到语言这一接口上。","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"LU的过程既可以由人来做，也可以由机器来做，由于语言实在太丰富，目前实际的系统中，往往是二者的折中，即人们在使用产品的过程中，根据过去的经验，会将语言收缩到较小的范围内。比如，一般不太会去问明天最高温有没有38°以上？，而是会直接问明天的最高温。在该过程中，人承担了部分理解和推断的任务。","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"实际的系统中，目前的统计模型能够较好地解决收缩后的LU的解析（大约90%左右吧）。问题似乎不大，不过另一个实际的问题是，许多任务并不太方便通过一句话就完整地表述清楚（比如订机票），于是，系统设计层面就多出了任务切换/信息共享/多任务竞争/LU在不同语境下的解析等等一系列问题。以我对现有各大厂商的Chatbot的理解，大家并没有对这些问题的解决方案达成共识，一般都采取一些trick做了简化，这里先不详细展开。","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/#Act-Like-Human","page":"漫谈聊天机器人","title":"Act Like Human","text":"","category":"section"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"显然，人并不满足于只让Chatbot完成一些既定的任务，而是在某些方面Act Like Human，最典型的就是情感诉求。从系统层面上讲，只需要在对话中加入情绪识别，再辅以对话库作为支撑即可。然而，更多时候，我们希望在整个对话的过程中Chatbot能够真正Act Like Human:","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"质疑\n对状态切换的质疑\n对不可靠信息的质疑\n询问\n对缺失的参数提出询问\n对最终结果进行confirm\n分享\n与用户共享当前的状态信息\n共享预测信息","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/","page":"漫谈聊天机器人","title":"漫谈聊天机器人","text":"目前来看，由于询问类的提问能够很好地预测，因而比较好做，而另外两类不太好直接生产预定的response。","category":"page"},{"location":"essays/Random_Thoughts_on_Chatbot/#Think-Like-Human","page":"漫谈聊天机器人","title":"Think Like Human","text":"","category":"section"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"keywords: Web,Clojure CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/#理解Clojure中Buddy认证模块","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"","category":"section"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"有关加密解密的知识一直是自己的盲点，最近在看如何用用clojure写网站，顺带学习了下cookie和session相关的知识，在这里介绍下Buddy这个库，并总结下自己的理解，不对的地方恳请指正。Buddy提供了基于Ring的一些安全认证相关的接口，下面内容就此展开。","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"先解释几个术语：","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"Handler：在Ring中，request和response都可以看做map，handler就是对request的内容分析后返回相应response的函数\nBackend：Buddy模块中每个backend都包含2个部分Authentication和Authorization，其中Authentication包含parse（将需要的认证数据从request中提取出来）和authenticate（根据parse提取的信息判断是否通过认证）两个步骤，Authorization则包含发生认证错误后如何处理该错误并返回相应response的实现。","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"根据Authentication和Authorization的实现不同，Buddy模块提供了5种实现，下面以最简单的http基本认证为例：","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"##Httpbasic","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"Httpbasic的处理逻辑如下图所示：","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"(Image: )","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"Httpbasic方式的缺点参见这里：","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"密码采用base64编码，很容易反向转换；\n每次请求都要传输密码（增加了攻击概率；\n密码缓存在本地浏览器，容易通过CSRF窃取；","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"采用https协议的话，仅仅能解决第一点问题。","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"##Session","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"该方案舍弃了httpbasic中传输username passwd的步骤，把验证和授权独立开来，授权放在login界面逻辑里去处理，将request中的:identity字段作为验证结果。而验证部分则只考虑是否存在:identity字段。","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"##Token","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"基于Token的方法则是将原来Httpbasic处理过程里，request的header中Authorization内容改为了token，从而避免直接存储用户名和密码，然后服务器端存储token和用户的对应关系。","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"##JWS Token","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"由于上面的token需要保存在服务器端，在用户量很大的时候，token的存储压力会很大，JWS token的用途就是将用户名密码加入签名后写进header的Authorization中，这样服务器端并不需要存储token到username的映射关系，只需要对token解码即可。这样做的好处是，不像Httpbasic简单采用base64对用户名密码编码，签名后的token很难破解得到原始的用户名密码信息。","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"##JWE Token","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"JWE Token处理的过程和JWS Token很像，区别在于引入非对称加密，将一部分敏感信息用公钥加密，服务端用私钥解密。","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"##参考","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"关于无状态认证的两篇讨论，里面提到了如何用python实现：","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"http://lucumr.pocoo.org/2013/11/17/my-favorite-database/","category":"page"},{"location":"essays/Understand_Buddy_in_Clojure/","page":"理解Clojure中Buddy认证模块","title":"理解Clojure中Buddy认证模块","text":"http://www.niwi.nz/2014/06/07/stateless-authentication-with-api-rest/","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"keywords: DataStructure,OCaml,Clojure CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/All_About_Zipper/#1.-什么是Zipper","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"根据Wikipedia上的解释，zipper函数式编程语言中的一种数据结构，能够很方便地遍历和更新list, tree以及一些抽象的循环定义的结构。这个概念的特殊之处在于，函数式编程语言中对数据结构中某个元素的改变不会影响已有的变量，zipper要解决的就是在此条件下如何高效地查找和更新。","category":"page"},{"location":"essays/All_About_Zipper/#2.-如何理解Zipper","page":"1. 什么是Zipper","title":"2. 如何理解Zipper","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"最早关于zipper的介绍就是[FUNCTIONAL PEARL The Zipper][]这篇paper。文章里用OCaml语言详细描述了两种数据结构，一种是list zipper，另一种是binary tree zipper（自己第一遍读这篇paper的时候，对第一个例子想了很久也没理解清楚，后来忽然发现其实就是list zipper的实现）。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"个人感觉一开始直接去理解zipper的概念并不太容易，先用Church number这个简单的例子来加深下对lambda演算的认识。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"根据Wikipedia上的解释，一个有效的lambda算子包含以下3条规则：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"变量x,就是最基础的一个lambda算子\n(lambda xt)\n,（即输入为x，输出为t的匿名函数）\n(ts)\n,其中t和s都是lambda算子，将t应用于s，得到的仍然是lambda算子","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"0 => λf.λx.x  \n1 => λf.λx.f x\n2 => λf.λx.f (f x)\n...","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"上面几行是wiki里常见的表示Church number的一种方式。看着有点晕？根据前面的定义，我们把上面的表达式加点括号,然后变换下符号就好理解了：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"0 => (λt.(λx.x))        ;; 记作 C0\n1 => (λt.(λx.(tx)))     ;; 记作 C1\n2 => (λt.(λx.(t(tx))))  ;; 记作 C2","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"从上面可以看出，其实就是一个两层的匿名函数，上面的Church number可以看做是Ck t x经过Currying之后的表示，其中Ck表示对应整数k的Church数， t表示某种transform（可以理解为某种函数变换），x表示变量。假设t为lambda x x + 1，x为0，那么Church number就与整数一一对应了。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"本文并不打算对lambda演算进行深入探讨，在这里引入Church number的概念是为了说明，在函数式编程的概念中即使是整数n这样的基础数据类型也是通过递归来表示的。需要注意的是，递归的过程是有一个起点的，对于Church number的例子起点就是C0，如果想要得到Ck，则需要递归调用k次运算得到。","category":"page"},{"location":"essays/All_About_Zipper/#3.-List-Zipper","page":"1. 什么是Zipper","title":"3. List Zipper","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"[FUNCTIONAL PEARL The Zipper][]中的第一个例子如下：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"type tree = Item of item | Section of tree list;;\ntype path = Top | Node of tree list * path * tree list;;","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"理解前面的Church number之后，再加上一点点OCaml语法，就很好理解上面这两行代码，第一行首先递归定义了一个tree类型，其中Item是递归定义的起点，假设item的类型是int，下面几个例子都是tree的一些实例：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"let t0 = Item (0)             (* 最基本的一个item *)\nlet t1 = []                   (* 空的tree *)\nlet t2 = Section [Item(1);Item(2);Item(3);Item(4)]  \n(* 一个Section, 其中每个元素都是一个Item *)\n\nlet t3 = Section [\n\tSection [Item(1);\n\t\tSection [Item(1)]];\n\tSection [Item(2);Item(2)];\n\tSection [Item(3);Item(3)]]\n(* 一个Section中包含了3个Section，每个Section都是可以嵌套的 *)","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"第二行代码中的path类型就是一个tupple，包含3个元素，第一个元素是以tree为元素的列表，第二个元素是递归的path（起点是Top）,第三个元素仍然是以tree为元素的列表。下面仍然给出几个实例：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"let p0 = Node([], Top, [])    (* 最基础的一个path，左边和右边的元素都是空列表，中间是起点元素Top *)\nlet p1 = Node (t0, p0, t0)     \nlet p2 = Node (t1, p1, t2)","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"有了tree和path两个类型之后，就可以得到一个list zipper的类型了：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"type location = Loc of tree * path","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"这里location是一个长度为2的tupple，包含tree和path。一个location本质是很自由的，其中的tree和path都可以是任意实现，通过对二者做一些限制，即可得到一个list zipper的实现。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"从最简单的开始，一个最小list zipper的定义就是Loc (Item(0) Top)，从本质上讲，list zipper 是一种状态描述的结构，这里用paper中的一个例子来描述状态的变化过程。表达式((a * b) + (c * d))用前面定义的tree类型来表示就是","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"let t0 = Section [\n\tSection [Item(a); Item(*); Item(b)];\n\tItem(+);\n\tSection [Item(c); Item(*); Item(d)];]","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"此时，t0是最顶层的tree，定义此时的path为Top，便得到了t0对应的location为let l0 = Loc (t0 Top)。list zipper 定义了如下遍历规则：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"go_down，就是指从当前location往更深一层走，location的第一个元素tree如果是一个Item的话会报错（没有更深的一层了），否则就是一个list，对其解构取出其元素t_first t_rest，其中tfirst构成新location中的tree元素，``let pnew = Node ([],p,trest)则构成新location中的path元素这里p表示上一层location中的path左边的空list[]``表示当前Section中tfirst左边的tree（显然为空），trest则表示当前Section中tfirst右侧的tree。相关的OCaml代码表示可以从paper中找到。对l0执行go_down操作后，可以得到let l1 = Loc (Section Item(a) Item(*) Item(b) Node( Top Item(+) Section Item(c) Item(*) Item(d)))\ngo_up则是go_down的逆操作。对当前location中的path元素解构得到(left p_up right)，取出left和right与当前location中的tree元素拼接得到新的tree_up（left需要翻转）。\ngo_right，把当前location中path解构后，得到(left p rr_rest)，取出其中的r作为新location的tree，然后当前location中的tree拼接到left上，这样得到了新的location Node(r (treeleft p r_rest))。对前面的l1应用go_right后得到let l2 = Loc (Item(+) Node(Section Item(a) Item(*) Item(b) Top Section Item(c) Item(*) Item(d)))\ngo_left也就是go_right`的逆操作。需要注意处理边界情况。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"可视化的描述可以看下图：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"(Image: Fig-1: Zipper Illustration)","category":"page"},{"location":"essays/All_About_Zipper/#4.-Clojure中的zipper","page":"1. 什么是Zipper","title":"4. Clojure中的zipper","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"Clojure中的提供了一个[clojure.zip][]模块。与OCaml中的实现稍微有些不同，由于Clojure是动态类型的，并没有类似循环定义的结构类型，因此在[clojure.zip][]库中默认提供了3类zipper（seq-zip, vec-zip, xml-zip），实际上前面说了zipper的思想可以在任何递归的结构中应用，后面会提到如何在clojure中扩充数据结构类型。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"在Clojure中，一个zipper的基本形式如下：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"[node  ;; 这里node可以是seq, vec 或者是其它递归的结构\n  {:l left_nodes  ;; 当前层级下当前node左侧的nodes\n   :r right_nodes  ;; 同理，当前层级下当前node右侧的nodes\n   :pnodes nodes_from_root_to_up  ;; 从root node开始，一直到当前node的父node的列表\n   :ppath  ;; 递归定义，与前面的思想一致\n  }]","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"[clojure.zip]: https://clojuredocs.org/clojure.zip","category":"page"},{"location":"essays/All_About_Zipper/#4.1-Clojure中提供的zipper类型与方法","page":"1. 什么是Zipper","title":"4.1 Clojure中提供的zipper类型与方法","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"[clojure.zip][]中包含了以下几类操作zipper的方法：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"遍历：next, prev, up, down, left, right, children, lefts, rights, rightmost, leftmost\n查询：node, path, \n更新：edit, replace\n插入/删除: insert-child, insert-left, insert-right, remove\n判断： branch?, end?","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"比较有意思的一个实现是end，用来判断next的结果是否到达终点。可以先看个例子：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"user=> (zip/vector-zip [])\n[[] nil]\nuser=> (zip/next (zip/vector-zip []))\n[[] :end]","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"其实就是在next的时候加入了一些判断，因为next的实现是深度优先的，最后会回到root，然后把path设为end这样每次next的时候用end判断下遍历是否结束。另外需要注意的一个是remove，默认会返回根据深度优先排序当前location的前一个location。","category":"page"},{"location":"essays/All_About_Zipper/#4.2-如何扩展zippe到其它类型？","page":"1. 什么是Zipper","title":"4.2 如何扩展zippe到其它类型？","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"zipper的思想可以扩展到很多其他类型的数据结构。在[clojure.zip][]中提供了[zipper][]函数来构建新的zipper类型，这样就可以使用各种遍历更新的函数了。其中，需要提供一下几个函数：","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"branch，判断一个node是不是还能有children（可以为空）\nchildren，给定一个可以branch类型的node，返回seq类型的children\nmake-node，给定一个node和children，返回新的node\nroot，即root node","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"在[hickory][]中有一个hiccup-zip的实现，可以学习下如何进行扩展的。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"[zipper]:https://github.com/clojure/clojure/blob/59b65669860a1f33825775494809e5d500c19c63/src/clj/clojure/zip.clj#L18 [hickory]:https://github.com/davidsantiago/hickory/blob/master/src/hickory/zip.cljx","category":"page"},{"location":"essays/All_About_Zipper/#4.3-更高效的访问方法","page":"1. 什么是Zipper","title":"4.3 更高效的访问方法","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"尽管[clojure.zip][]库中提供了很丰富的遍历和更新函数，但是，想要优雅地修改递归类型的结构仍然是件很繁琐的事，很多时候都需要动手写loop  recur ，通常认为这样的操作是比较底层的。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"[specter][]就是用来提供高效访问的，其中对zipper类型的数据也提供了很好的接口，能够写出更简洁高效的代码。","category":"page"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"[specter]:https://github.com/nathanmarz/specter [FUNCTIONAL PEARL The Zipper]:https://www.st.cs.uni-saarland.de/edu/seminare/2005/advanced-fp/docs/huet-zipper.pdf","category":"page"},{"location":"essays/All_About_Zipper/#5-参考","page":"1. 什么是Zipper","title":"5 参考","text":"","category":"section"},{"location":"essays/All_About_Zipper/","page":"1. 什么是Zipper","title":"1. 什么是Zipper","text":"Tree visitors in Clojure","category":"page"},{"location":"AMA.zh/#Ask-Me-Anything","page":"Ask Me Anything","title":"Ask Me Anything","text":"","category":"section"},{"location":"AMA.zh/","page":"Ask Me Anything","title":"Ask Me Anything","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"index.en/#About","page":"👋 About","title":"👋 About","text":"","category":"section"},{"location":"index.en/","page":"👋 About","title":"👋 About","text":"<div class=\"avatar\"></div>","category":"page"},{"location":"index.en/#About-the-Avatar","page":"👋 About","title":"About the Avatar","text":"","category":"section"},{"location":"index.en/","page":"👋 About","title":"👋 About","text":"The original photo was taken in the summer of 2012 by my current wife. It was in a small garden in front of the library in the south campus of Central South University . I've forgoten which book I was reading, but I still remember that pen, a blue mechanical pencil.","category":"page"},{"location":"index.en/#About-Me","page":"👋 About","title":"About Me","text":"","category":"section"},{"location":"index.en/","page":"👋 About","title":"👋 About","text":"2023 until now, software engineer at 01.ai, building LLM infrastructure. (We are hiring🤗)\n2022~2023, software engineer at inspir.ai focusing on NLP and RL in games.\n2017~2022, worked on several natural language understanding related projects at Microsoft.\n2016~2017, I mainly worked on smart subsidies and dispatching at Didi Chuxing.\n2013~2016, master's degree on NLP at Institute of Automation - Chinese Academy of Sciences.\n2009~2013, bachelor's degree on automation at Central South University.","category":"page"},{"location":"index.en/","page":"👋 About","title":"👋 About","text":"Contact me:","category":"page"},{"location":"index.en/","page":"👋 About","title":"👋 About","text":"Twitter\nlichess. I'm still learning and practicing.","category":"page"},{"location":"index.en/","page":"👋 About","title":"👋 About","text":"You can also 🙋 Ask Me Anything here.","category":"page"},{"location":"index.en/#About-This-Site","page":"👋 About","title":"About This Site","text":"","category":"section"},{"location":"index.en/","page":"👋 About","title":"👋 About","text":"All contents published at this site follow CC-BY-4.0 by default.","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"keywords: Julia,ParallelComputing CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/#一文读懂Julia中的并行计算","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"","category":"section"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"最近阅读了Julia中的Distributed标准库，对Julia中的并行计算又多了一些思考。尽管官方文档中有一章详细介绍并行计算(中文, 英文)，我刚接触Julia的时候也写了一篇自底向上理解Julia中的并行计算，不过总感觉讲得不够透彻。本文的目的是用一些实际的例子帮助大家深入理解Julia中的并行计算。","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"本文将包括以下内容：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"Task\nChannel\nRemoteChannel\nClusterManager","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"本文不包括以下内容：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"XX问题应该选择哪种并行计算方式？","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/#Task","page":"一文读懂Julia中的并行计算","title":"Task","text":"","category":"section"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"通常我们并没有感知到究竟什么是Task，其实每次我们从命令行里输入julia，打开REPL界面之后，就进入了一个task中，通过current_task函数就可以获取到当前运行中的task对象：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> t = current_task()\nTask (runnable) @0x00007f34ded89600","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"可以看到，t的打印输出中，括号里提供了一个runnable信息，表明当前task t 是可执行的，除了runnable之外，task还有其它几个状态:","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"Symbol Meaning\n:runnable Currently running, or able to run\n:done Successfully finished executing\n:failed Finished with an uncaught exception","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"后面会介绍各个状态的具体含义，这里先留下个印象即可。这些状态存在t.state字段中：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> t.state\n:runnable","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"那什么是Task呢？一个task就是一段执行逻辑，可以直接通过Task来构造：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> t_hi = Task(() -> println(\"Hi\"))\nTask (runnable) @0x00007f34dec870d0\n\njulia> t_hi.state\n:runnable","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"这里Task可以接收一个lambda函数作为参数，构造一个新的task。此外还有一个@task宏，用来方便地将一段执行逻辑构造成一个task：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> t_hello_world = @task begin\n              println(\"I'm in a task!\")\n              \"Hello World!\"\n              end\nTask (runnable) @0x00007f34dc84b0d0","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"那么如何执行一个task呢？调用schedule即可：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> schedule(t_hello_world)\nI'm in a task!\nTask (runnable) @0x00007fb18f7eae10\n\njulia> t_hello_world.state\n:done\n\njulia> t_hello_world.result\n\"Hello World!\"","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"可以看到，上面的task顺利执行完之后，状态就变成了:done，对应的执行结果保存在t_hello_world.result字段中。此外还有几个函数用于检查状态：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"istaskstarted\nistaskdone\nistaskfailed","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"task中也可以报错，错误会保存在task 的exception字段中：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> schedule(t_error)\nTask (failed) @0x0000000012aef0f0\nOh no...\nerror(::String) at .\\error.jl:33\n(::getfield(Main, Symbol(\"##7#8\")))() at .\\task.jl:87\n\njulia> t_error.state\n:failed\n\njulia> t_error.result\nErrorException(\"Oh no...\")\n\njulia> t_error.exception\nErrorException(\"Oh no...\")","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"那么，schedule究竟做了什么呢？这里就涉及task的底层实现了。简单来讲，Julia 会给每个 thread 都生成一个队列，schedule所做的就是将该task按照一定规则（后面会再详细解释）加入到某个队列中。由于我们启动 Julia 的时候，并没有指定JULIA_NUM_THREADS环境变量，所以默认只有一个队列：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> Base.Workqueues\n1-element Array{Base.InvasiveLinkedListSynchronized{Task},1}:\n Base.InvasiveLinkedListSynchronized{Task}(Base.InvasiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(Base.Threads.Atomic{Int64}(0)))","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"将task加入队列中之后，调度器会在空闲时，负责从队列中顺序取task并执行。","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"<div class=\"alert alert-warning\"> 需要指出的是，前面的例子中，似乎执行完schedule(t_error)之后，t_error就立即执行得到了结果。其实，这是因为我们是在REPL中分步执行的，执行完schedule(t_error)之后，REPL就进入了等待的过程，此时调度器空闲了，就会按照既定的规则从队列中取task并执行。可以用下面的例子来验证下。 </div>","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> t = @task @info \"I'm in task\"\nTask (runnable) @0x0000000012a802f0\n\njulia> begin\n       schedule(t)\n       @info \"Hello\"\n       end\n[ Info: Hello\n[ Info: I'm in task","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"可以看到，Hello先打印了出来，然后 task t 接着就执行并打印 I'm in task。","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"目前为止，我们了解了什么是task (WHAT), 如何使用task (HOW)，那为什么要使用task呢？ (WHY)","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"这就涉及到我们还没提到的一个task的特性，在一段task的执行逻辑之中，我们可以（显式地/隐式地）指定某些地方能被中断和恢复。直接执行yield()就相当于显式地告诉调度器，“把我放到队列里取，让队列里其它task有机会被执行”，当然，如果全局的task队列中没有runnable的task，那么就会立即继续执行接下来的其它代码。下面举个例子：","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> t1 = @task begin\n       @info \"begin task1\"\n       yield()\n       @info \"end task1\"\n       end\nTask (runnable) @0x00007f7542e7e850\n\njulia> t2 = @task begin\n       @info \"begin task2\"\n       yield()\n       @info \"end task2\"\n       end\nTask (runnable) @0x00007f7542e7eb30\n\njulia> begin\n       schedule(t1)\n       schedule(t2)\n       yield()\n       @info \"Current task running\"\n       end\n[ Info: begin task1\n[ Info: begin task2\n[ Info: Current task running\n[ Info: end task1\n[ Info: end task2","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"这里先定义了两个task，每个task都是先打印begin信息，然后是执行yield()允许自己被中断，一旦被恢复后，再打印end信息。注意最后一个代码块，首先调度t1,然后调度t2,此时t1和t2都被加到了一个队列中，最后执行yield()把自己也加入到队列中，让调度器开始调度。从输出的顺序可以看出，t1先被执行，执行到yield()语句后，让出控制权，调度器从队列中选出t2执行，同样执行到yield()之后让出控制权，然后当前task被选中执行，此后t1再次被选中，执行结束，然后再执行t2，直至结束。","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"此外，yield还可以接收一个task作为参数，执行后会将该task放在队列的最前面被调度，比如，上面的例子中，试着将t2中的yield()改成yield(t1)，然后schedule(t2)试试？","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"那允许一段代码被中断的好处是什么呢？","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"并发","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"一个经典的例子是，在做网络请求的时候，会等待响应，若没有中断的机制，那么会一直阻塞，这样导致宝贵的计算资源在此期间白白浪费掉了。有了中断机制之后，在等待响应的过程中，可以主动切出去，让调度器有机会运行其它task，等获取到响应之后，再将自己放回到task队列中，等待被调度并执行。","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"TODO: Need a picture here","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"为了实现上述逻辑，Julia中提供了一个Condition对象，用来表示一类抽象的条件。task可以执行wait(c::Condition)，将自己挂载在该Condition下的链表末尾，并yield()出去，若Condition满足，则可以调用notify(c::Condition)，将挂载在该Condition的task链表上的task逆序添加到调度器的执行队列中，从而让其它task有机会被执行。","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"julia> c = Condition()\nCondition(#undef, 0, 0)\n\njulia> t1 = @task begin\n       @info \"task1 working...\"\n       wait(c)\n       @info \"condition satisfied\"\n       end\nTask (runnable) @0x00007f75412e45d0\n\njulia> schedule(t1)\n[ Info: task1 working...\nTask (runnable) @0x00007f75412e45d0\n\njulia> t1.state\n:runnable\n\njulia> notify(c)\n[ Info: condition satisfied","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"Julia中stream和Timer相关的操作都采用类似机制实现的。","category":"page"},{"location":"essays/A_Pratical_Guide_to_Distributed_Computing_in_Julia/","page":"一文读懂Julia中的并行计算","title":"一文读懂Julia中的并行计算","text":"理解上面的这些概念之后，就可以做很多有意义的事情了。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"keywords: Book CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"ScaffoldingSeamus Heaney, 1939 - 2013Masons, when they start upon a building,Are careful to test out the scaffolding;Make sure that planks won’t slip at busy points,Secure all ladders, tighten bolted joints.And yet all this comes down when the job’s doneShowing off walls of sure and solid stone.So if, my dear, there sometimes seem to beOld bridges breaking between you and meNever fear. We may let the scaffolds fallConfident that we have built our wall.","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"今天偶然想起了这本书里开篇的这首诗，似乎又多了一些理解。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"<hr>","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"最近这个月断断续续读完了Statistical Rethinking一书，感觉这本书还是挺适合入门的。作者的文风很好，每一章开头都会引入一个有意思的例子方便读者对本章的内容有一个大概的理解，不过书中的代码部分主要用到了自己写的一个库，这么做有好处也有坏处，好处是整本书中代码部分会相当简洁，侧重理解概念而不拘泥于代码细节；不过坏处是对于我这种不太熟悉R代码的人来说有种雾里看花的感觉，整体上讲，作者对二者平衡得很好，即使没有R基础也能很好地理解大部分内容，只是练习部分会稍微吃力点，后面感觉自己还会重读这本书。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"另外作者还录制了教学视频，大致看了几课，感觉蛮不错，不过不如看书来得快。最近作者又开始了新的一个学习，在Youtube上有同步更新，有兴趣的可以去看看。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"以下是本书中的一些要点：","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/#Chapter-2","page":"-","title":"Chapter 2","text":"","category":"section"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"提纲挈领的一部分。作者用small worlds类比观测到的世界，而large worlds则对应真实世界，我们无法知道真实世界是怎样的，只能根据观测到的世界去修正我们的猜测，由此引出了先验、似然和后验的概念。这章最核心的是要理解quadratic approximation，作者用map函数对其作了封装，前面几章会频繁用到。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"关于MAP、ML等有个很不错的介绍材料可以参考。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/#Chapter-3","page":"-","title":"Chapter 3","text":"","category":"section"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"理解HDPI的概念，可以尝试自己动手实现下这个函数，比我想象中要简单。可以参考下这里","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/#Chapter-4","page":"-","title":"Chapter 4","text":"","category":"section"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"重点理解高斯分布的内涵，这一点在PRML/MLAPP中也都有提到，思想是一致的。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/#Chapter-5","page":"-","title":"Chapter 5","text":"","category":"section"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"从一元线性回归过度到多元线性回归的时候，会遇到几个典型的问题。变量之间存在相关性时，后验分析会出现不符合常识的问题。此外还分析了引入哑变量对类别变量进行编码的影响。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/#Chapter-6","page":"-","title":"Chapter 6","text":"","category":"section"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"过拟合和欠拟合，一个经典问题。作者的出发点很新奇，从信息熵的角度出发，把交叉熵、KL散度、（样本内/样本外）偏差联系了起来，然后引入正则先验的概念。本章最关键的是信息准则，这对于我来说是个全新的概念，后面几章中都反复用到该指标进行模型比较和评估等。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"信息熵的表示如下：","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"$","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"\\begin{equation} H(p) = -\\sum{i=1}^{n}pi log(p_i) \\label{entropy} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"稍微改写下形式：","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"$","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"\\begin{equation} H(p) = \\mathbb{E}H(p_i) \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"其中mathbbE表示求期望，H(p_i)=log(frac1p_i)，其含义是概率越低信息量越大，求log是为了保证相互独立事件的信息量之和等于这些事件同时发生的信息量。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"K-L散度：用一个分布去描述另一个分布时引入的不确定性。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"(Image: KL Description)","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"$","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"\\begin{equation} \\begin{split} D{KL}(p,q) & = H(p,q) - H(p) \\\n & = -\\sum{i}pi log(qi)  - \\left(- \\sum{i}pi log(pi) \\right) \\\n & = - \\sumi pi \\left(log(qi) - log(p_i) \\right)  \\end{split} \\label{klexplained} \\end{equation} $","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"式子eqrefklexplained中的H(pq)表示交叉熵。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"关于KL散度，有一篇博客写得更详细写，可以参考。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"##Chapter 7","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"这一章重点分析了多个变量之间存在相互影响时的情况，感觉自己在做数据分析的时候，好像经常忽略了这点。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"##Chapter 8","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"MCMC和HMC的解释很直观。关于采样链（Chain），有效采样个数等都有说明。 开篇提到的Good King的例子很好玩，我也重写了下：","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"(def N 10)\n(def counts (vec (range 1 (inc N))))\n\n(defn move\n  [i]\n  (rand-nth [(mod (dec i) N)\n             (mod (inc i) N)]))\n\n(defn play\n  [i]\n  (let [j (move i)\n        count-i (nth counts i)\n        count-j (nth counts j)]\n    (if (or (> count-j count-i)\n            (<= (rand) (/ count-j count-i)))\n      j i)))\n\n(->> (iterate play (rand-int N))\n     (take 100000)\n     frequencies\n     (sort-by first))","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"##Chapter 9","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"简单介绍了下广义线性模型，理解这里提到的两类连结函数(link function)，本质上是将参数从不同的值域映射到-infty+infty，留意其中参数的可解释性。","category":"page"},{"location":"essays/Notes_on_Statistical_Rethinking/","page":"-","title":"-","text":"后面几章中看得比较粗略，我主要看了下多层模型、零膨胀问题和缺失值的问题。","category":"page"},{"location":"#About","page":"👋 About","title":"👋 About","text":"","category":"section"},{"location":"","page":"👋 About","title":"👋 About","text":"<div class=\"avatar\"></div>","category":"page"},{"location":"#About-the-Avatar","page":"👋 About","title":"About the Avatar","text":"","category":"section"},{"location":"","page":"👋 About","title":"👋 About","text":"The original photo was taken in the summer of 2012 by my current wife. It was in a small garden in front of the library in the south campus of Central South University . I've forgoten which book I was reading, but I still remember that pen, a blue mechanical pencil.","category":"page"},{"location":"#About-Me","page":"👋 About","title":"About Me","text":"","category":"section"},{"location":"","page":"👋 About","title":"👋 About","text":"2023 until now, software engineer at 01.ai, building LLM infrastructure. (We are hiring🤗)\n2022~2023, software engineer at inspir.ai focusing on NLP and RL in games.\n2017~2022, worked on several natural language understanding related projects at Microsoft.\n2016~2017, I mainly worked on smart subsidies and dispatching at Didi Chuxing.\n2013~2016, master's degree on NLP at Institute of Automation - Chinese Academy of Sciences.\n2009~2013, bachelor's degree on automation at Central South University.","category":"page"},{"location":"","page":"👋 About","title":"👋 About","text":"Contact me:","category":"page"},{"location":"","page":"👋 About","title":"👋 About","text":"Twitter\nlichess. I'm still learning and practicing.","category":"page"},{"location":"","page":"👋 About","title":"👋 About","text":"You can also 🙋 Ask Me Anything here.","category":"page"},{"location":"#About-This-Site","page":"👋 About","title":"About This Site","text":"","category":"section"},{"location":"","page":"👋 About","title":"👋 About","text":"All contents published at this site follow CC-BY-4.0 by default.","category":"page"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"","category":"page"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"keywords: Life CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Some_Thoughts_Recently/#最近的一些感悟","page":"最近的一些感悟","title":"最近的一些感悟","text":"","category":"section"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"看了下时间，距离上次更新博客差不多三个月了，也意味着来滴滴有三个月了。梳理了下，这三个月的事也挺多的，毕业答辩、毕业、实习和工作。现在回顾这三个月，感觉转变真的很大，趁今天入职培训有点闲暇的时间，记录下这段时间的感受，也算是分享下自己的近况吧。","category":"page"},{"location":"essays/Some_Thoughts_Recently/#1.-三个月里学到了些什么？","page":"最近的一些感悟","title":"1. 三个月里学到了些什么？","text":"","category":"section"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"回想三个月前，自己还坐在实验室的工位上写代码做数据分析，如今那地方早已被大一的小朋友们占满了，让人不得不感慨良多。自从上一篇博客烂尾后，就去了滴滴实习，也就是现在工作的地方。其实，前期并没做很多事情，因为毕业的事，实习也都是三天打鱼两天嗮网，到每个月底数工资的时候发现，其实一个月里也就半个月在公司。实际的工作时间虽然不多，不过这三个月下来也马马虎虎对整个项目流程有了些了解，对整个公司也有了更深的认识，随便记录点东西，留着以后回头再看。","category":"page"},{"location":"essays/Some_Thoughts_Recently/#1.1-Spark","page":"最近的一些感悟","title":"1.1 Spark","text":"","category":"section"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"以前虽然对spark也有所了解，然而并没有应用的场景。去组里最早的任务也就是熟悉下spark任务和相关的脚本了，期间对spark 的API有了一定的熟悉，不过到现在为止，也没怎么熟悉MLLib相关的应用和实现。最早的时候，是接手组里另外两个实习生的一些特征提取的工作，讲真，理解完代码时的一个感受是，“嗯，终于看到比我的Python写得还烂的了...\",不过呢，等到自己后面写的时候才发现，自己写出来的一些特征提取代码也强不到哪去（后面再细聊这块）。","category":"page"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"新人用spark面临的第一个问题一般就是，要不要学Scala呢？？？记得很久之前学了一段时间的scala，应该是2015年年底附近吧，到最近早就忘得一干二净了，记得当时Scala留给自己的印象就一个字，”杂“。深知这语言里的坑太多，于是实习期间的时候果断跳过了，平时的spark任务基本都是调的Python API，除了期间因为代码交流的原因，又复习了下Scala的语法。然而，大规模云平台上使用Python的一个问题是，包管理（据说Golang的人老习惯拿这点对比Python了）。如果要在这条路上继续走的话，我估计Scala还是得硬着头皮去掌握。。。闲暇的时候尝试了下clojure下的两个spark相关的库，一个是flambo，还有一个sparking，后者感觉还不错，写出的代码要优雅得多，不过，工作归工作，写出来的东西毕竟是要跟其他人沟通的，clojure还是太小众，也就自己玩玩而已了。","category":"page"},{"location":"essays/Some_Thoughts_Recently/#2.2-进度控制和管理","page":"最近的一些感悟","title":"2.2 进度控制和管理","text":"","category":"section"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"技术或者算法方面的学习不是特别多，不过这段时间学到的最重要的应该就是进度的控制和自我管理了。可能自己是自由散漫惯了，在所里的干活的时候都是看心情，早上可能都去得比较晚，完成实验什么的其实并没有什么具体的规划，走一步看一步的那种感觉吧，有状态的时候感觉效率奇高，没状态的时候基本一整天都莫名其妙地过去了。而去了公司的一个整体感受是，一整个项目的分工和拆解相当明确，个人负责自己的一块，再拼接成一个整体。其实刚开始那段时间很不适应，主要原因是总想着对整个项目都有个完整了解后，再考虑去完成自己擅长的那部分。然而，事实是我足足花了一个多月的时间去梳理整个项目，这期间自己的贡献基本为0（更要命的是我在新来的实习生身上似乎也看到了同样的现象）,后来观察组里其他人的工作方式，几乎都会把任务拆解到很小的可实现的几个点上，与此同时不断熟悉上下游的代码，这样同时兼顾了杂事的处理和业务逻辑的学习。要是回到3个月前，我一定要告诉自己的一件事就是，不要贪多，step by step!","category":"page"},{"location":"essays/Some_Thoughts_Recently/#2.-写项目和做比赛的一些区别","page":"最近的一些感悟","title":"2. 写项目和做比赛的一些区别","text":"","category":"section"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"知乎上有人讨论过一个问题你实践中学到的最重要的机器学习经验是什么，显然我还不够格去讨论这个问题，不过呢，我倒是可以分享一些关于完成项目和作比赛的一些区别。","category":"page"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"记得有天和陈大师聊到这个话题，讨论的重点是为啥滴滴比赛的时候都是各种模型的融合，咱做项目干的都是又low又苦逼的特征拉取工作（注意关键词）。后来陈大师说了句意味深长滴话：因为这样子效率最高呀！呵呵，会心一笑，不得不承认，同样的工作时间条件下，扩充特征确实是最保守的做法。","category":"page"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"个人觉得，做比赛和做项目的最大差别，就是特征抽取了。比赛过程里，一般数据集是给定的，我们根据数据集和问题的特性尽可能去构造出能够描述问题本质的特征体系。由于时间有限，这期间最重要的一件事不是去扩充特征，而是特征的筛选，因为在有限数据集的条件下，top级选手之间的特征差异往往并没有很大。至于筛选的方法，就各显神通了，有人倾向于根据模型得到的特征筛选，有人倾向于自动化的多模型筛选，也有人喜欢直接上神经网络的，总之，有用就行。","category":"page"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"其次，我认为是迭代效率的差异。很久以前，我一直认为，除了特征之外，最重要的就是模型融合了，最近好好想了下这个问题，其实比模型融合更重要的是迭代效率。同样走在一条未知的探索道路上，最接近终点的往往是试错最多的团队。迭代效率越高，短时间内尝试的方案也就越多，所以，模型融合也只是迭代效率高的表现形式之一而不是全部。此外，这也可以解释为什么一些横扫各大比赛的冠军队往往更容易在一个新的赛事上获胜，经验是其一，极高的执行效率和工具化的特征生产链也是重要的一环。这段时间的实际工作里，深切感受到了前期积累的重要性，很多生产流程都相当原始，许多事都觉得有些无能为力。","category":"page"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"最后是敢于尝试，项目相关的东西，总是偏向于保守的，而做比赛的包袱则没有那么大，许多最新的一些算法都是值得去尝试和改进的，从最近滴滴比赛的几个PPT里可以看到，还是有些队用了神经网络的一些东西，包括DNN，GRU网络等，也有不错的效果。","category":"page"},{"location":"essays/Some_Thoughts_Recently/#3.-一些工作了才发现的事","page":"最近的一些感悟","title":"3. 一些工作了才发现的事","text":"","category":"section"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"个人能做的事其实很小很小，平台的重要性远大于其它。\n缺少主动探索的精神，对大多数人而言，“工作”，也只是一份工作而已。\n时间不够用，真心觉得时间才是最宝贵的资源。（现在都不推塔了。。。）\n保持记录的习惯很受益，每天都写写wiki，有利于减少一些沟通成本。\n代码积累，以前可能都是随手写写脚本什么的，信手拈来。工作后写代码很重要的一个环节是代码复用，多积累一些snippets还是蛮有意义的。\n测试！对别人负责，也对自己负责。","category":"page"},{"location":"essays/Some_Thoughts_Recently/#4.-近期的一些规划","page":"最近的一些感悟","title":"4. 近期的一些规划","text":"","category":"section"},{"location":"essays/Some_Thoughts_Recently/","page":"最近的一些感悟","title":"最近的一些感悟","text":"重写下网站，保持更新的频率。发现公司的网没法访问blog，打算改写下后台文件的传输方式，还是回归到原始的推送到github方式算了，利用github上的hook同步到server端备份，撤掉后台管理。\n熟练掌握下tensorflow，这个毕竟还是以后工业级应用的主要工具库，theano之类的还是更偏学术点。\n熟练掌握下clojure并发的部分（主要是最近受了Golang的刺激......），此外就是结合业务思考下如何灵活地去写一些DSL相关的东西。\n读下手头上的书，《计算机程序的构造与解释》（刚看一半，后面两章应该要花不少时间）、《计算的本质 深入剖析程序和计算机》（挺有意思的一本书，Ruby还是不太熟，应该会拿Python来重写一遍）、《具体数学》和《统计学习基础》（算是扫尾吧，保持手感最重要~）\nFollow下顶会上一些有意思的paper，多动手实践下~","category":"page"},{"location":"notebook_demo/pluto/#Pluto-Demo","page":"Pluto Demo","title":"Pluto Demo","text":"","category":"section"},{"location":"notebook_demo/pluto/","page":"Pluto Demo","title":"Pluto Demo","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-13</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-08-13</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-12</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-08-12</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='56' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='56' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='21' height='20' fill='#555'/><rect x='21' width='35' height='20' fill='#4c1'/><rect width='56' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='110'>⇩</text><text x='115' y='140' transform='scale(.1)' textLength='110'>⇩</text><text x='375' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='250'>x.txt</text><text x='375' y='140' transform='scale(.1)' textLength='250'>x.txt</text></g><a target='_blank' xlink:href='../x.txt'><rect width='56' height='20' fill='rgba(0,0,0,0)'/></a></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='70' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='70' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='51' height='20' fill='#0F80C1'/><rect width='70' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='435' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='410'>Archive</text><text x='435' y='140' transform='scale(.1)' textLength='410'>Archive</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='52' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='52' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='33' height='20' fill='#0F80C1'/><rect width='52' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='345' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='230'>记录</text><text x='345' y='140' transform='scale(.1)' textLength='230'>记录</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='52' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='52' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='33' height='20' fill='#0F80C1'/><rect width='52' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='345' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='230'>Test</text><text x='345' y='140' transform='scale(.1)' textLength='230'>Test</text></g></svg></div>","category":"page"},{"location":"notebook_demo/pluto/","page":"Pluto Demo","title":"Pluto Demo","text":"<iframe src=\"../x.html\" style=\"width: 100%;height: 100vh\"></iframe>","category":"page"},{"location":"notebook_demo/pluto/","page":"Pluto Demo","title":"Pluto Demo","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"keywords: Julia CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/#Julia下的Packages概览","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"","category":"section"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"光说不练假把式。本着实用主义的精神，在造轮子之前，不妨先花些时间学习下现有的一些包。","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"20180319","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"|#|Stars|Link| |-|––-|––| |1|1206|IJulia| |2|1131|Gadfly| |3|1008|Mocha| |4|479|Knet| |5|456|JuMP| |6|444|DataFrames| |7|443|Plots| |8|433|DifferentialEquations| |9|416|PyCall| |10|402|DSGE| |11|331|Cxx| |12|299|TensorFlow| |13|288|MXNet| |14|287|Distributions| |15|286|Escher|","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/#准备","page":"Julia下的Packages概览","title":"准备","text":"","category":"section"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"首先，回顾下文档中关于Package的介绍。执行Pkg.add(\"PkgDev\")后，尝试构建一个新的Package，梳理下Package的基本结构。","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"(Image: CreatePkg.png)","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"REQUIRE文件中目前只有一个julia 0.6，深入了解某个Package之前，REQUIRE是首先要查看的，每一行表示了一个依赖（一般还会指定相应的版本信息）。\n.codecov.yml是代码覆盖率检查，.travis.yml和appveyor.yml是用来做CI的，这些可以先不管\nsrc/目录下现在还只有一个单独的文件Jun.jl\ntest/目录下只有一个runtests.jl","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"嗯，其实就是个空壳，啥也没有......","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"未来还有会有Pkg3，结构上不太一样了，等这个模块完善了再介绍下。","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/#Overview","page":"Julia下的Packages概览","title":"Overview","text":"","category":"section"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"尽管根据star数量来决定学习顺序似乎是个更务实的做法，不过各个库之间的依赖关系很复杂，而且不同库之间的复杂程度也很不一样，我决定从一些基础的开始。","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/#[Missings.jl][]","page":"Julia下的Packages概览","title":"[Missings.jl][]","text":"","category":"section"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"[Missings.jl][]这个库简单实用，可以看到，其REQUIRE文件只包含","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"julia 0.6\nCompat 0.45.0","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"第一行指定了julia的版本（前面提到过，新创建的库中都会包含这行），第二行Compat是用来对不同版本的julia提供兼容的。","category":"page"},{"location":"essays/Learn_Some_Julia_Packages/","page":"Julia下的Packages概览","title":"Julia下的Packages概览","text":"[Missings]: https://github.com/JuliaData/Missings.jl","category":"page"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"","category":"page"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"keywords: Java CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Optional_in_Java_8/#Java-8-中的Optional","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"","category":"section"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"最近在公司的一些内部服务中，主要都在用Java8开发，各种数据流的操作非常方便，虽然还赶不上clojure，但是也很不错了。在公司内部做服务的开发会有些头疼的问题，比如协作和代码审查。这里就聊聊协作中的一个细节：Optional。","category":"page"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"因为类的主体是自己设计的，中间一些参数传递的都是Optional类型，协作的时候，对方很困惑，为什么需要Optional呢？好处是啥？我说，“预防空指针的问题呀~”。然后对方默默地写了一行代码：long x = getFinishTime()orElse(null)，然后欢快地用if(x == null)else继续写代码去了。这个时候我就在思考另外一个问题：如果一个这样简单的概念都很难让大家广泛接受，那Haskell中那些复杂的特性又该如何可持续发展呢？","category":"page"},{"location":"essays/Optional_in_Java_8/#如何理解？","page":"Java 8 中的Optional","title":"如何理解？","text":"","category":"section"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"Optional的API介绍有很多，这里不重复介绍。我自己将其主要分为3类：","category":"page"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"initial（empty,of, ofNullable）\ntransform (filter, flatmap, get, isPresent, map, orElse, orElseGet, orElseThrow)\naction (ifPresent)","category":"page"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"初看可能觉得，transform和action只是些语法上的简便处理，我实际使用中最大的体会有两点，一是真的大大减少了空指针的异常，毕竟传递一个Optional变量的时候，就好像变量自己会说话，“Hey，注意检查我哦~”，通过合理地使用Optional变量，可以很方便地定位一些本不应该出现空指针的问题，这在协作的时候很方便；此外，Optional变量能够很好地嵌入到stream中（虽然还有一点点不太方便的地方，Java9中有改进），使得整体的代码更简洁，可阅读性更高。","category":"page"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"那有么有啥技巧呢？","category":"page"},{"location":"essays/Optional_in_Java_8/#减少get的使用！","page":"Java 8 中的Optional","title":"减少get的使用！","text":"","category":"section"},{"location":"essays/Optional_in_Java_8/","page":"Java 8 中的Optional","title":"Java 8 中的Optional","text":"显然，如果频繁使用get方法，那就意味着频繁使用isPresent，结果就是回到原来ifelse的老路上了。可以参考Java 8 Optional – Replace your get() calls理解如何做代码替换。当然，有一点需要注意，不必强制将所有get都替换掉，Java8的一些函数式方法不是特别完善，有时候灵活处理下反而更方便。","category":"page"},{"location":"AMA/#Ask-Me-Anything","page":"🙋 Ask Me Anything","title":"Ask Me Anything","text":"","category":"section"},{"location":"AMA/","page":"🙋 Ask Me Anything","title":"🙋 Ask Me Anything","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"keywords: Design,Julia CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/#A-Draft-Design-of-Distributed-Reinforcement-Learning-in-Julia","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"","category":"section"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"I've been thinking for a while about how to design a distributed reinforcement learning package in Julia. Recently I read through the source code of some packages again, including:","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"Ray/rllib\nReinforcementLearning.jl\nDopamine\ntrfl\nDeepRL","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"and some other resources included here by Joel. Although I still don't have a very clear design, I would like to write down my thoughts here in case they are useful for someone else.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"The abstractions for reinforcement learning in rllib are quite straightforward. You may refer RLlib: Abstractions for Distributed Reinforcement Learning for what I'm talking in the next.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"BaseEnv\nPolicy Graph\nPolicy Evaluation\nPolicy Optimizer\nAgent","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"It has been demonstrated that by using the concepts above most of the popular reinforcement learning algorithms can be implemented in rllib. However, it's not that easy to port those concepts directly into Julia. One of the most important reason is that we don't have an existing foundamental package like Ray. And the infrastructure of parallel programming in Julia is quite different. In the next section, I will try to adapt those concepts in Julia and describe how to implement some typical algorithms in the very high level.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/#Actors-Actors-Actors","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"Actors Actors Actors","text":"","category":"section"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/#Environment","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"Environment","text":"","category":"section"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"Let's start from the environments part first. Environments in RL are relatively independent. By treating all environments asynchronously, rllib shows that it would be very convenient to introduce new environments. So here we also treat environments as actors running asynchronously.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"First, we introduce the concept of AbstractEnv.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"abstract type AbstractEnv end\n\nfunction interact!(env, actions...) end\nfunction observe(env, role) end\nfunction reset!(env) end","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"Then we can wrap it into an actor","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"env_actor = @actor begin\n    env = ExampleEnv(init_configs)\n    while true\n        sender, msg = receive()\n        @match msg\n            (:interact!, actions) => interact!(env, actions)\n            (:observe, role) => tell(sender, observe(env, role))\n            (:reset!,) => reset!(env)\n            # do something else\n            (:ping,) => tell(sender, :pong)\n        end\n    end\nend\n\n# The code above can be further simplified by introducing an `@wrap_actor` macro\nenv_actors = @wrap_actor ExampleEnv(init_configs)","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/#Policy","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"Policy","text":"","category":"section"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"In the next, we can have a PolicyGraph object like the one in rllib:","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"abstract type AbstractPolicy end\n\nfunction act(pg, obs) end\nfunction learn(pg, batch) end\nfunction set_weights(pg, weight) end\nfunction get_weights(pg) end","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/#Evaluator","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"Evaluator","text":"","category":"section"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"An evaluator will combine Policy and Environment together.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"abstract type AbstractEvaluator end\n\nstruct ExampleEvaluator <: AbstractEvaluator\n    env_actor\n    policy\n    #...\n    ExampleEvaluator(env, policy, params..) = new(@wrap_actor env, policy, params...)\nend\n\nfunction sample(ev::Evaluator) end","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"Again, we can wrap it into an actor.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"ev_actor = @wrap_actor ExampleEvaluator(env, policy, params)","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"When the ev_actor is invoked, a environment actor will also be invoked (in the same processor by default)","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/#Optimizer","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"Optimizer","text":"","category":"section"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"An optimizer will interact with evaluators and do something like parameter updating and distributed sampling.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/#Demo","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"Demo","text":"","category":"section"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"Putting all components together. We have the following graph to show how each component is working in the Ape-X algorithm.","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"TODO: Add figure","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"And the pseudocode is:","category":"page"},{"location":"essays/A_Draft_Design_of_Distributed_Reinforcement_Learning_in_Julia/","page":"A Draft Design of Distributed Reinforcement Learning in Julia","title":"A Draft Design of Distributed Reinforcement Learning in Julia","text":"# 1. create environments\nenv_actors = @wrap_actor CartPoleEnv(configs)\n\n# 2. create policies\npolicy = DQNPolicy(configs)\n\n# 3. define evaluators\nmutable struct ApeXEvaluator\n    env_actor\n    policy\n    batch_size\n    n_samples\n    replay_buffer\nend\n\nfunction sample(ev::ApeXEvaluator)\n    while true\n        if ev.n_samples >= ev.batch_size\n            return sample(replay_buffer, evn.batch_size)\n        else\n            r, d, s = @await observe(ev.env_actor)  # it will be translated into send/receive\n            a = ev.policy_actor(s)  # it will be translated into send/receive\n            # update replay_buffer\n            # calc loss\n            # update grad\n        end\n    end\nend\n\nev_actors = @smart_actors ApeXEvaluator env_actors policy_actors\n\n# 4. optimizer\nmutable struct ApeXOptimizer\n    local_ev\n    remote_evs\nend\n\nfunction step(optimizer::ApeXOptimizer)\n    samples = @await get_high_priority_samples(optimizer.remote_evs)\n    # evaluate local_env\n    # broadcast local_weights\n    # update priority of replay buffer\nend","category":"page"},{"location":"essays/Locks_Threads_Tasks_Channels_Actors/#Locks,","page":"Locks,","title":"Locks,","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"keywords: Python,Book CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/#（4）一起用python之基础篇——入门书","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/#写在前面","page":"（4）一起用python之基础篇——入门书","title":"写在前面","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"从快毕业的时候在图书馆里借来第一本有关python的书算起，接触python的时间也不过半年有余。时间真的很短，很难有什么经验之谈，自己至今也仍有许多需要学习的地方。不过对于怎么入门这一块，倒是颇有感触。在这里记录下来，也许能对后人有所帮助吧~","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/#我是怎么开始了解python","page":"（4）一起用python之基础篇——入门书","title":"我是怎么开始了解python","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"快毕业的时候，在中南的图书馆里瞎逛，偶然之间看到这么一本书，《可爱的python》。第一眼看上去，只是觉得书名还挺新颖的，反正也是闲着，抽出来看看吧。“人生苦短，我用python”，这是我在封面上看到的第一句话，这感叹句实在太吸引眼球，以至于这么长时间后，我早忘了书中讲的什么内容。留在脑海中的就只有封面上的这句话和作者的前言。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"当时看完前言部分，我就感慨良多。一本好的编程入门书，不应该是一上来就告诉你怎么写Hello World，给你介绍变量、函数、控制流 blablabla...，而是作者站在一个朋友的角度来和你谈心，告诉你他自己学习这门编程语言的经历，他自己所体会到的这门编程语言的魅力在哪里，有哪些优点和不足之处，怎样能够更快更好地熟悉这门语言。这感觉就和当初学C++时候读的第一本书《Thinkng in C++》一样。作者提到，由于python这门语言的特殊性，对它的学习并不必拘泥于传统的教科书式的学习方式，而是重点在“使用”中学习，其基本思想就是用最短的时间掌握python最基础最核心的语法，然后在使用中碰到具体的问题时候，再去主动学习相关知识。这个观念对我的影响很深，可以说，回顾自己的历程，基本就是按照这个原则来的，而且收获确实很多。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"下面就结合我自己的学习经历，谈谈刚入门时候的基本原则。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/#你只需要掌握最基础的","page":"（4）一起用python之基础篇——入门书","title":"你只需要掌握最基础的","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"刚开始学习python的时候，可能会查看许多书，这些书为了能够涵盖得尽量全面，往往会涉及语言方方面面的细节。但是，并不是每一个知识点都是你所需要的。一开始你只需要掌握最基础的那部分知识。你可能会问，“我哪知道哪些是最基础的东西呢？” 我觉得，一个很简单的判断方法就是，拿起书都第一遍的时候，如果你能硬著头皮看下去并且能够理解里面所讲的内容，那很好，这就是最基础的。如果看了第一遍后云里雾里，鬼才知道哪天会用得上这些东西。OK，专门找个小笔记本，记下这部分内容方便以后查阅，然后，跳过这部分。我在第一次看decorator装饰器这个部分的时候实在看不下去，也不知道可能会有啥用，果断跳过，最近上高性能计算的课，学习下cuda的python接口时，里面都是装饰器修饰的函数，才又好好学习来一下，结合来自己的实际问题，这样理解起来也就更深入。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/#脚踏实地，出来混，迟早是要还的","page":"（4）一起用python之基础篇——入门书","title":"脚踏实地，出来混，迟早是要还的","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"记住，前面你跳过的那些问题，迟早是会冒出来的。你自己得清醒地意识到，这种刻舟求剑式的做法，是存在一些弊端的，虽然大多数时候，这些弊端不过是自己动手来实现一些别人已经实现来的东西，多花点时间精力罢了，但还有的时候，你可能会付出沉重的代价。类似的教训实在太多，比如看书的时候觉得itertools这个包没有太大用就跳过了，后来有一天要实现个排列组合的算法时花了很长时间来实现，结果偶然一天看到这货居然内置在iterrools里了；还有迭代器和生成器那部分，一开始以为自己可能用不到，后来要对一堆很大的文本做分析时候才发现内存不够了......所以说，出来混，迟早是要还的，那些跳过了东西，迟早某一天要出来坑你一把。那肿么办咧，跳还是不跳，这是个问题，个人觉得，刚入门的时候，还是能跳就跳吧。等自己对这门语言产生兴趣了，再来深入了解其语言的细节，也不算太晚。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/#多读书，都好书","page":"（4）一起用python之基础篇——入门书","title":"多读书，都好书","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"关于python的书虽不如C++，Java之类的那么多，但好书却不少了，这半年看了有十多本书了吧，整体感觉质量都挺不错。以下按照由浅入深的顺序来推荐给大家。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"相信我，你看的第一份文档，应该是The Python Tutorial。什么？英语的看不懂！我去，你都还没开始看！！！\n看完上面的教程后，你可能会有种意犹未尽的感觉，难道，只需要这么点知识我就算入门了吗？如果你看完毫无压力，我只能说真的，这样就算入门。不过除此之外还有另外一些讲解python基础书，也值得一看。你应该把大多数时间花在上面这份tutorial上，下面(1)中基础点的书应该是当作补充。看这几本书的时候，牢记上面的两条原则！(我是不会告诉你下面的这些书大多都有中文版的:~)\n基础点的：A Byte of Python, learn python the hard way\n稍稍进阶点的：dive into python 3\n需要当工具书一样看的：The Python Standard Library byExample\n骨灰级的：Python Cookbook, 3rd Edition","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/#好用才是王道","page":"（4）一起用python之基础篇——入门书","title":"好用才是王道","text":"","category":"section"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"看完上面这些书，你应该对python的基本语法特性，内部的标准库有了很深的了解。但是，我最想说的是，并不一定要等的你把这些书都读完了才开始做些事，（事实上，读完那份tutorial你就可以动手做很多事了）。你应该很清楚的知道自己要用python来做什么！！！想当初大一学c语言时候，学了也不知道为什么而学，所以啊，最后学完了那些语法知识后全都丢到一边，我那时候哪还知道c可以用来干那么多事。就我自己而言，学习python的目的是为了在一定程度上代替matlab作为科学计算工具，利用其丰富的包来实现许多功能，另外，用python写的代码可读性很高，不管是自己写还是读别人的代码，都是一种享受。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"我想，你也一定有自己使用python目的，比如想用python爬网络上的资源，比如要用python建个网站，又或者是要和服务器上的后台打交道...你总可以找到自己要学习的那个部分，记住，把重点花在这里！。然后，等你对python有一些感性认识了，某一天自然会想起来要了解下python的底层是怎么实现的，为什么这样做比那样做更好等等问题。","category":"page"},{"location":"essays/[4]_Learn_Python_Together_Basic/","page":"（4）一起用python之基础篇——入门书","title":"（4）一起用python之基础篇——入门书","text":"编程语言说到底也只是工具罢了，工具固然是越好用越好，但更重要的是你要知道拿这些工具去解决什么样问题，以及怎样去解决！","category":"page"},{"location":"essays/Notes_on_Artificial_Intelligence_Foundations_of_Computational_Agents/","page":"Artificial Intelligence: Foundations of Computational Agents读书笔记","title":"Artificial Intelligence: Foundations of Computational Agents读书笔记","text":"","category":"page"},{"location":"essays/Notes_on_Artificial_Intelligence_Foundations_of_Computational_Agents/","page":"Artificial Intelligence: Foundations of Computational Agents读书笔记","title":"Artificial Intelligence: Foundations of Computational Agents读书笔记","text":"keywords: Book,AritficialIntelligence CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Notes_on_Artificial_Intelligence_Foundations_of_Computational_Agents/#Artificial-Intelligence:-Foundations-of-Computational-Agents读书笔记","page":"Artificial Intelligence: Foundations of Computational Agents读书笔记","title":"Artificial Intelligence: Foundations of Computational Agents读书笔记","text":"","category":"section"},{"location":"essays/Notes_on_Artificial_Intelligence_Foundations_of_Computational_Agents/","page":"Artificial Intelligence: Foundations of Computational Agents读书笔记","title":"Artificial Intelligence: Foundations of Computational Agents读书笔记","text":"P11 It is instructive to consider an analogy between the development of flying machines over the past few centuries and the development of thinking machines over the past few decades. There are several ways to understand flying. One is to dissect known flying animals and hypothesize their common structural features as necessary fundamental characteristics of any flying agent. With this method, an examination of birds, bats, and insects would suggest that flying involves the flapping of wings made of some structure covered with feathers or a membrane. Furthermore, the hypothesis could be tested by strapping feathers to one’s arms, flapping, and jumping into the air, as Icarus did. An alternative methodology is to try to understand the principles of flying without restricting oneself to the natural occurrences of flying. This typically involves the construction of artifacts that embody the hypothesized principles, even if they do not behave like flying animals in any way except flying. This second method has provided both useful tools – airplanes – and a better understanding of the principles underlying flying, namely aerodynamics. AI takes an approach analogous to that of aerodynamics. AI researchers are interested in testing general hypotheses about the nature of intelligence by building machines that are intelligent and that do not necessarily mimic humans or organizations. This also offers an approach to the question, “Can computers really think?” by considering the analogous question, “Can airplanes really fly?”","category":"page"},{"location":"essays/Notes_on_Artificial_Intelligence_Foundations_of_Computational_Agents/","page":"Artificial Intelligence: Foundations of Computational Agents读书笔记","title":"Artificial Intelligence: Foundations of Computational Agents读书笔记","text":"这段类比很好，前段时间，关于深度学习的讨论（批评）很多，也提到了造飞机这个例子。某种程度上，目前的深度学习还是走的类似前一种研究方法（学习人脑的构造，思考方式，然后去模拟）。","category":"page"},{"location":"essays/Notes_on_Artificial_Intelligence_Foundations_of_Computational_Agents/","page":"Artificial Intelligence: Foundations of Computational Agents读书笔记","title":"Artificial Intelligence: Foundations of Computational Agents读书笔记","text":"P57 There is much evidence that people have multiple qualitatively different levels. Kahneman [2011] presents evidence for two distinct levels: System 1, the lower level, is fast, automatic, parallel, intuitive, instinctive, emotional, and not open to introspection, and System 2, the higher level, is slow, deliberate, serial, open to introspection, and based on reasoning.","category":"page"},{"location":"essays/Notes_on_Artificial_Intelligence_Foundations_of_Computational_Agents/","page":"Artificial Intelligence: Foundations of Computational Agents读书笔记","title":"Artificial Intelligence: Foundations of Computational Agents读书笔记","text":"这里提到了Thinking: Fast and Slow这本书里的概念，这里强烈推荐大家读这本书。","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"keywords: Julia,GPU,Sampling CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/#Categorical-Sampling-on-GPU-with-Julia","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"","category":"section"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"A great blog post has discussed this topic in detail: http://www.keithschwarz.com/darts-dice-coins/. I strongly suggest you read through it first.","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"Sampling from a categorical distribution is very straight forward in Julia. In Distributions.jl, there's a naive sampling implementation. As the name indicates, the implementation is very simple:","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"function rand(rng::AbstractRNG, s::CategoricalDirectSampler)\n    p = s.prob\n    n = length(p)\n    i = 1\n    c = p[1]\n    u = rand(rng)\n    while c < u && i < n\n        c += p[i += 1]\n    end\n    return i\nend","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"I usually use it as a warm-up interview question :smile:.","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"In StatsBase.jl, there are many more efficient implementations for both with or without replacement. The `sample! method in StatsBase.jl is smart enough to select an appropriate one according to the distribution.","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"Among those implementations, I'm more interested in the alias_sample!. As the documentation says, the alias sampling method takes O(n log n) for building the alias table (here n is the length of distribution), and then O(1) to draw each sample (consume 2 random numbers each time). This character makes it very suitable for some large scale simulations.","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"Next, we want to accelerate the alias sampling method further with GPU. Let's take a close look at the implementation in StatsBase.jl first:","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"function alias_sample!(rng::AbstractRNG, a::AbstractArray, wv::AbstractWeights, x::AbstractArray)\n    n = length(a)\n    length(wv) == n || throw(DimensionMismatch(\"Inconsistent lengths.\"))\n\n    # create alias table\n    ap = Vector{Float64}(undef, n)\n    alias = Vector{Int}(undef, n)\n    make_alias_table!(values(wv), sum(wv), ap, alias)\n\n    # sampling\n    s = RangeGenerator(1:n)\n    for i = 1:length(x)\n        j = rand(rng, s)\n        x[i] = rand(rng) < ap[j] ? a[j] : a[alias[j]]\n    end\n    return x\nend","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"Here the AbstractWeights is just a wrapper of a weighted vector with the sum pre-calculated. There're mainly two steps:","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"Create alias table\nSampling","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"To enable GPU acceleration, we can first generate the alias table on the CPU and then send it to the GPU. Then write a kernel on GPU to perform the sampling step.","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"The make_alias_table! function below is directly taken from StatsBase.jl with a small modification to make it compatible with Float32.","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"function make_alias_table!(w::AbstractVector{T}, wsum::S,\n                           a::AbstractVector{T},\n                           alias::AbstractVector{<:Integer}) where {S, T}\n    n = length(w)\n    length(a) == length(alias) == n ||\n        throw(DimensionMismatch(\"Inconsistent array lengths.\"))\n\n    ac = n / wsum\n    for i = 1:n\n        @inbounds a[i] = w[i] * ac\n    end\n\n    larges = Vector{Int}(undef, n)\n    smalls = Vector{Int}(undef, n)\n    kl = 0  # actual number of larges\n    ks = 0  # actual number of smalls\n\n    for i = 1:n\n        @inbounds ai = a[i]\n        if ai > 1.0\n            larges[kl+=1] = i  # push to larges\n        elseif ai < 1.0\n            smalls[ks+=1] = i  # push to smalls\n        end\n    end\n\n    while kl > 0 && ks > 0\n        s = smalls[ks]; ks -= 1  # pop from smalls\n        l = larges[kl]; kl -= 1  # pop from larges\n        @inbounds alias[s] = l\n        @inbounds al = a[l] = (a[l] - 1.0) + a[s]\n        if al > 1.0\n            larges[kl+=1] = l  # push to larges\n        else\n            smalls[ks+=1] = l  # push to smalls\n        end\n    end\n\n    # this loop should be redundant, except for rounding\n    for i = 1:ks\n        @inbounds a[smalls[i]] = 1.0\n    end\n    nothing\nend","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"The next step is to perform sampling on GPU:","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"function cu_alias_sample!(a::GPUArray{Ta}, wv::AbstractVector{Tw}, x::GPUArray{Ta}) where {Tw<:Number, Ta}\n    length(a) == length(wv) || throw(DimensionMismatch(\"weight vector must have the same length with label vector\"))\n    n = length(wv)\n    # create alias table\n    ap = Vector{Tw}(undef, n)\n    alias = Vector{Int64}(undef, n)\n    make_alias_table!(wv, sum(wv), ap, alias)\n    \n    # to device\n    alias = CuArray{Int64}(alias)\n    ap = CuArray{Tw}(ap)\n    \n    function kernel(state, alias, ap, x, a, randstate)\n        r1, r2 = GPUArrays.gpu_rand(Float32, state, randstate), GPUArrays.gpu_rand(Float32, state, randstate)\n        r1 = r1 == 1.0 ? 0.0 : r1\n        r2 = r2 == 1.0 ? 0.0 : r2\n        i = linear_index(state)\n        if i <= length(x)\n            j = floor(Int, r1 * n) + 1\n            @inbounds x[i] = r2 < ap[j] ? a[j] : a[alias[j]]\n        end\n        return\n    end\n    gpu_call(kernel, x, (alias, ap, x, a, GPUArrays.global_rng(x).state))\n    x\nend","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"<div class=\"alert alert-warning\"> Especially take care of the 15~16 lines of the code above. By doing so it will avoid bound error in some extreme cases. </div>","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"Now let's check the performance:","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"The result with GPU:","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"\nN, K = 10, 10^5\n\nwv = rand(Float32, N)\na = CuArray{Int64}(1:N)\nx = CuArray{Int64}(zeros(Int64, K));\n\n@benchmark cu_alias_sample!($a,$wv, $x)\n\n# BenchmarkTools.Trial: \n#   memory estimate:  5.22 KiB\n#   allocs estimate:  124\n#   --------------\n#   minimum time:     77.197 μs (0.00% GC)\n#   median time:      102.396 μs (0.00% GC)\n#   mean time:        107.162 μs (1.07% GC)\n#   maximum time:     18.155 ms (30.20% GC)\n#   --------------\n#   samples:          10000\n#   evals/sample:     1","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"The result with CPU:","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"wv = weights(rand(Float64, N))\nda = 1:N\ndx = zeros(Int64, K)\n@benchmark StatsBase.alias_sample!(Random.GLOBAL_RNG, $da,$wv, $dx)\n\n# BenchmarkTools.Trial: \n#   memory estimate:  640 bytes\n#   allocs estimate:  4\n#   --------------\n#   minimum time:     2.195 ms (0.00% GC)\n#   median time:      2.233 ms (0.00% GC)\n#   mean time:        2.240 ms (0.00% GC)\n#   maximum time:     3.434 ms (0.00% GC)\n#   --------------\n#   samples:          2230\n#   evals/sample:     1","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"About 20 times faster!","category":"page"},{"location":"essays/Categorical_Sampling_on_GPU_with_Julia/","page":"Categorical Sampling on GPU with Julia","title":"Categorical Sampling on GPU with Julia","text":"As you can see, in Julia we can easily leverage some existing code on CPU and port them to GPU without much effort!","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/#深入理解Julia中的Distributed.jl标准库","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-20</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-08-20</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-20</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-08-20</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='62' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='62' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='43' height='20' fill='#0F80C1'/><rect width='62' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='395' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='330'>分布式</text><text x='395' y='140' transform='scale(.1)' textLength='330'>分布式</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='54' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='54' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='35' height='20' fill='#0F80C1'/><rect width='54' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='355' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='250'>Julia</text><text x='355' y='140' transform='scale(.1)' textLength='250'>Julia</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='74' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='74' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='55' height='20' fill='#0F80C1'/><rect width='74' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='455' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='450'>并行计算</text><text x='455' y='140' transform='scale(.1)' textLength='450'>并行计算</text></g></svg></div>","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"Distributed.jl是Julia中的一个标准库，基于多进程进行分布式 计算。在官方（中文）文 档中，有专门的一章对此做了详细的讲解，如果你从未使用过 这个库的话，建议先读下官方文档。这里我将着重从这个库的设计和代码实现层面进行深入讲解，并在最后提供一个迷你版的实现。","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/#Distributed.jl-的启动流程","page":"深入理解Julia中的Distributed.jl标准库","title":"Distributed.jl 的启动流程","text":"","category":"section"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"                              +----------+\n                        +---->+ Worker_1 |\n                        |     +----------+\n+-----------------+     |     \n| ClusterManager  +-----+        ......\n+-----------------+     |\n                        |     +----------+\n                        +---->+ Worker_N |\n                              +----------+\n","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"如上图所示，Distributed.jl的基本思路是，主节点上先构造一个 ClusterManager 然后在各个子节点上构造worker进程，相互之间通过cookie（一段固定长度的随机字符串）确认身份。所有worker的信息都在 ClusterManager中有记录，包括IP、端口等。有了这些这些信息之后，剩下的就是约定如何通信了，Distributed.jl中使用了 Serialization.jl标准库来实现序列化和反序列化。此外，还提供了一 些常用的宏（@everywhere, @spawn）和远程对象(Future, RemoteChannel)来屏蔽一些底层的操作。","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"整体流程看起来比较清晰","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"启动的过程中，首先会创建一个 ClusterManager对象，该对象负责在本地或 者其它机器上创建多个子进程，维护子进程的连接信息。这个库原生提供了两个ClusterManager的实现，LocalManager和 SSHManager。接下来以LocalManager为例，来分析完整的Distributed.jl启动流程。","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"在本机启动多进程可以直接在运行julia时通过指定参数-p auto实现，或者在进入REPL之后，运行using Distributed，然后调用 addprocs函数实现。其中关键的函数调用栈如下：","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"addprocs\ninit_multi\ninit_bind_addr，配置当前进程绑定的IP和端口信息\ncluster_cookie，设置与其它进程通信用的cookie，确保后面不会连接到其它不认识的进程上了\nlaunch","category":"page"},{"location":"programming/A_Deep_Dive_into_Distributed.jl/index.zh/","page":"深入理解Julia中的Distributed.jl标准库","title":"深入理解Julia中的Distributed.jl标准库","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"keywords: Life CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#我在滴滴这一年","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"最终，还是决定离开这里。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#当初为什么来这里呢？","page":"我在滴滴这一年","title":"当初为什么来这里呢？","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"“......，当初为什么来这里呢？......”，决定离开前的一次谈话中，老大GPH[1]这么问我。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"[1]: 为避免不必要的麻烦，本文涉及的人名均以缩写替代。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"我还记得是2015年7月的某天，XJX在微信上给我发了个拉勾网上的链接，说滴滴那边招算法方面的实习生，有兴趣可以试试。虽说在所里也没时间实习，不过心想着试试也无妨，就当为9月份的校招练练手好了。那时候，对滴滴的规模有多大其实并没有感觉，当然，对他们的技术也是一无所知。面试的地点在农大南路某个写字楼里，面试就俩人，其中一个人简单聊了聊简历，写了个算法题，推了下LR公式，然后问我最近在看什么机器学习方面的书？我说正在读ESL，PRML？这本倒没读，只是上课的时候读了部分MLAPP。然后他介绍了下自己的背景，清华毕业的，刚从HULU那边过来，这边机器学习相关的东西都才刚起步，以前的都是些规则系统，代码用C++，现在打算做些改造，很缺人手。不过我实习时间上没法满足，于是作罢。临走前问我，“后面校招的时候会考虑滴滴吗？”，按正常人的逻辑一般是不会直接拒绝吧，不过我那时回复的是，“大概不会考虑，感觉在滴滴这种小公司里没啥成长。”，呵呵呵，哪知后面啪啪啪打脸了。（一年后进了公司，我才知道当时面我的是GD，出于感谢，我在钉钉上跟他简单聊了下，哪知道人家对我根本没印象，:joy:）","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"中间校招面试的过程在《聊聊最近》一文中有简单介绍，当时的想法是这样子的：","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"其实从内心来讲，自己倾向于往计算广告方向发展，商业价值更大一些，但这块需要一个好的成长环境。不过呢，觉得做nlp这块好像也还不错，把功底打扎实了以后做周边的东西都能跟得上，不过总觉得有那么一丝丝想法，是不是有必要读个博把这块的工作做得更深入呢？","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"当时对于继续做NLP有些犹豫，很重要的一点是，我看不清这块未来的发展方向，回到两年前，深度学习在NLP方向的应用有着井喷之势，但身处其中的时候，其实很难看到自己该往哪个方向发展，我很焦虑自己会一头扎到其中后难以再跳出来，也就没有准备读博（现在看来这种想法可能有些可笑）。而我对推荐和广告感兴趣的一个主要原因是，之前参加过一些比赛，觉得挺有意思（是的，兴趣占了很大因素），但是后来在和许多人沟通之后明确了一点，这个方向大概不会有很大的突破性进展了，更多的是工程性和技巧性在里面，算法相对成熟，而且即使有突破也能难形成壁垒，（当然，从个人学习的角度来讲，还是会很有收获的，只是总觉得少了点什么）。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"就在我纠结的时候，面了滴滴，也顺利拿了offer，加上中间对滴滴要做的事情有了些许了解。那时刚成立滴滴研究院，LW也去我们所里做了演讲（搞笑的是院长没多久走了，LW后来也去了腾讯AILab），感觉滴滴这边也算是个机会。一方面，这里算法刚起步，是个学习和应用算法的试验田；另一方面，可以学习下快速成长期的公司，在工程方面是如何迭代和打磨的（这样的机会还是挺难得的，毕竟以后有的是机会去大公司里了解一些成熟的体系）。于是乎，来了滴滴~","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#这一年里都做了些啥？","page":"我在滴滴这一年","title":"这一年里都做了些啥？","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"“你怎么评价自己过去这段时间的工作？”，年初公司薪资普调的时候，老大一对一私聊的时候这么问我。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"回首这一年，很惭愧，对于团队只做了一些微小的工作（不是谦虚，而是事实）。虽然很多工作都很枯燥，像处理数据、服务开发与维护等，但自己也算是尽心尽力在做好自己的本职工作。所以当时我的回答是，“感觉自己工作量完成得一般，还可以做得更好！”。老大也表示了认同，然后鼓励我工作中多主动一些（其实我明白他的意思是，薪资上我已经尽力为你争取了，该加班的时候还是多加加班赶下进度......）。我对加班啥的其实没有那么大的反感（虽然我这一年加的班总共也不到一个星期），前提是得有值得这么做的事情啊......不过老大在这方面很open，从来没说过我什么。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"那次谈话之后，断断续续做了些算法方面的探索和实践，然而方向多次调整，感觉有些累了，每次调整都让人觉得前面的努力都是徒劳（包括公司层面和个人层面）。在公司目前这个阶段，任何一个方向想要有较大的突破，都需要持续的耕耘和迭代，像这样反复调整，很伤士气。虽然自己的title是算法工程师，然而，这一年里与算法相关的工作少得可怜，质和量都有所停滞，主要靠业余的兴趣在支撑，不过工程方面的经验似乎有不少提升，有得有失吧。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#再读《程序员修炼之道——从小工到专家》","page":"我在滴滴这一年","title":"再读《程序员修炼之道——从小工到专家》","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"Programming isn’t hard!Programming well is very hard!","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"这几天休息的日子里，我又读了一遍这本书，工作后再读，感触颇深，再过几年之后，我应该还会重读的。下面结合我的一些工作经历和书中的内容，简单聊几点。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#Provide-Options,-Don't-Make-Lame-Excuses","page":"我在滴滴这一年","title":"Provide Options, Don't Make Lame Excuses","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"刚开始工作的时候，给自己定的工作计划总是会有延期的情况发生，归结其原因，无非是中途有各种各样的琐事插入进来，于是会有各种各样的借口。后来慢慢意识到，本质上，这是一种极其不负责任的态度，既然承诺某件事定期完成，就应该同时考虑到各种风险因素，即便有某些意外发生，也需要尽量提供选择而不是找各种蹩脚的借口（不过我看组里这点似乎不太好，拿最近DSP项目而言，大家提供的选择就俩字：“加班”，这往往掩盖了背后的风险控制、对外的资源协调等一系列问题）。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#Don't-Live-with-Broken-Windows","page":"我在滴滴这一年","title":"Don't Live with Broken Windows","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"老实说，这点没做到。好几次接手别人代码的时候，就已经是烂代码了，当然，也不是那么烂。拿补贴地图的代码为例，逻辑其实很清晰，定期读配置、聚合，然后解析请求、返回补贴信息，然而中间的配置解析写得很繁琐，字符串的拼接、时间越界判断等等都杂糅在一个函数中，以至于后来在其之上加入一些新功能的时候，心态就变成了，“唉，前面已经写这么烂了，新加的这个功能再怎么写好也都是徒劳的了，先草草修改下实现功能再说吧~”，砰~又一扇窗破了。等到临走前自己做代码交接的时候，我也成了烂代码的贡献者之一......(心疼交接的那哥们1s)","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"“发现一个破窗户就修一个”","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"不过，代码如果一开始就是自己写的，情况又有些不一样了，毕竟没人愿意看着自己的代码一点点膨胀到无序状态。在写洋流那边的项目时，我都会尽量做好类和功能的抽象，review代码的时候也尽量会让代码风格保持一致。当然，实践中会遇到些问题，比如你没法让不熟悉Java8的人，强制用函数式风格，但总的来说，充分的沟通和交流是极其必要的。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#Stone-Soup-and-Boiled-Frogs","page":"我在滴滴这一年","title":"Stone Soup and Boiled Frogs","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"重读这一节的时候，有些伤感，因为团队的发展简直活生生地将“石头汤”的故事演绎成了另一个版本。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"在石头汤的故事里有两层语义。士兵戏弄了村民，他们利用村民的好奇，从他们那里弄到了食物。但更重要的是，士兵充当催化剂，把村民团结起来，和他们一起做到了他们自己本来做不到的事情——一项协作的成果。最后每个人都是赢家。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"和Uber中国合并后，老大带着大家从补贴转做调度（掏出了石头），依稀记得我们这帮村民那时候其实都是将信将疑的，既没有方向，也没有抓手。出于信任，慢慢地大家也就投入进来了（拿来了食材），然而和石头汤故事的结尾不一样，最终也没能等到“拿出石头的时候”。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"现实与故事的最大区别在于，故事里，有了村民的食材，就一定会等来一锅鲜美的汤，而现实则是，你可能做了所有的准备，却依然一无所获。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"还记得“温水煮青蛙”的故事吗？大环境变了！","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#Debugging","page":"我在滴滴这一年","title":"Debugging","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"The easiest person to deceive is one's self.","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"过去这一年里写了不少代码，也出了不少bug，内存泄漏啦，异常检查啦之类的坑没少踩，真正算得上严重的bug有两个。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"一个是日志解析与入库。很简单的任务，每天定期将请求日志解析之后入写入hive库，然后做一些数据分析。代码测试后，没有任何问题。后期做数据分析的时候发现，上了某个策略之后请求跌到了以往的一半，按理说不应该有这么大的反应，可是数据不会说谎啊，想了好久也没想出原因可能是什么。于是提出了一些激励方案，虽然数据上有明显回升，但是仍然没恢复到以前的水平。后来有一天，另外一份日志也需要每天进行调度分析，复用之前代码的时候，惊奇地发现调度的触发时间是每天中午，而分析的日志也是当天的！这就是为什么请求量跌到了原来的一半！","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"另一个是请求第三方ETA服务。基本流程走通后，中间做过一次sharding的修改，最后做实验结果分析的时候发现，准确率上不去。查了半天觉得ETA的服务有问题，结果显示ETA的误差率接近50%，“这群吹B的，天天声称xx%，明显没达到嘛！”，我心里一边默默地吐槽，一边问他们这怎么搞的。“真的能达到呀，不信你拿XX表验证下”，自己验证了下发现还真是声称的那么好，实在想不通为什么自己请求的结果误差这么大，汇报了下情况，还没来得及找到原因，咔嚓，这个先不做了。因为这个模块同时在给另一个团队用，最近做项目交接的时候，ZDS跑来跟我说，“嘿，你这里参数是不是传错了？”，定睛一看，简直要吐血。看了下commit记录，应该就是那次sharding改造的时候，传参的两个变量名很像，给弄混了。感觉这个项目被砍自己有很大责任......","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"花这么长篇幅写这两个bug，是因为这二者都有一个共性，“最容易欺骗的人就是自己！”，并非这两个bug藏得有多深，许多时候我们都是被自己的自信给蒙蔽了。“这一定不是我的问题！”，我想，下次再调试的时候，恐怕得把叹号改成问号了。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#Don't-Program-by-Coincidence","page":"我在滴滴这一年","title":"Don't Program by Coincidence","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"最近读《概率论沉思录》的时候，开篇就提到了一个概念，叫Plausible Reasoning。有意思的是，其实我们日常写代码的时候，会不自觉地代入许多这样的推理过程。这么写一段代码试试？嗯，好像没问题。再加入些外围代码，看起来似乎能工作了。巧合！大多时候，这么写出来的代码只是看上去能正常工作，我们没法对每一步的推理过程设置某个明确的值，然后计算出整体的可信度并根据某个阈值来判断接受与否！","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"不要靠巧合编程，尽可能测试代码，测试所有的假设条件！","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#为自己投资","page":"我在滴滴这一年","title":"为自己投资","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"Invest Regularly in Your Knowledge Portfolio","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"这一点要单独拉出来说说。根据RescueTime软件的统计显示，我最近14个星期（非付费版的统计时长只有这么久）的时间分配如下图所示：","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"(Image: rescuetime)","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"总结下：","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"约1/3的时间花在了软件开发上（主要是iterm2、Idea和Emacs）；\n约1/5的时间花在文献阅读和查资料上；\n约1/10的时间用在写文档方面；\n约1/8的时间花在email和钉钉等沟通上面（似乎低于平均水平）；\n数据显示，（我在）滴滴确实没怎么加班，所以大家以后就不要乱喷这点了；\n接上面，滴滴的时薪还是蛮高的；\n以后公司计算投入产出的时候，应该在心里默默地打个75折；","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"下面是分几点聊聊这一年里，我在工作中和工作之外的一些额外投资。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#算法","page":"我在滴滴这一年","title":"算法","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"工作中用到的算法其实不算特别复杂，更多的还是理解算法在现实问题中的局限性，基本还是LR、XGBoost、CNN、RNN那一套。额外抽空看了下TensorFlow的代码，熟悉了下TensorLayer（蛮不错的），虽然用的机会不多。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"年前把强化学习那块学习了下，对我来说确实是个全新的领域，用Clojure把Reinforcement Learning: An Introduction中前几章的例子也都重写了一遍，基本概念都理解了，不过距离实际应用还有段距离，这块发展很快，在对话领域应该会有广阔的前景，后来陆陆续续看到公司里有一些项目也用到强化学习，还是蛮欣慰的。以后应该还会深入学习。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"年初忽然对贝叶斯分析那块很感兴趣，买了些比较经典的书在读，花了不少时间，补了补统计学方面的内容，本来想在公司内部的某个项目上应用的，一直没机会做，:joy:","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#编程","page":"我在滴滴这一年","title":"编程","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"从零开始学习了下Emacs，不过作为Vim党还是更喜欢Spacemacs，不得不说，用起来确实很顺手，无障碍迁移，所以现在日常编程基本都在Spacemacs下了。当然，写Java还是用idea......","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"编程语言上，没有大的突破，跟着HD同学撸了一阵子Haskell，感觉很好玩，然而，太花时间了，可能，得等好久以后才会再捡起来了。Clojure最终也没在生产环境中用，也就自己玩了玩。Python方面在读Fluent Python，还是很有收获的。后面有两个项目用Java8写了下，感觉很顺手。Scala则一直没下决心去深入学习，短期内也不会有特别大的动力。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"工作中对一些通信协议有了一些新的理解，中间跟许多服务有打交道，对系统设计这块似乎也有些感觉了，这块等以后有经验了可以再单独写写。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"最重要的还是跟人打交道，代码只是实现需求的一种方式（充分非必要）。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#离开","page":"我在滴滴这一年","title":"离开","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"我并不想仓促行事，因为仓促本身就是20世纪最要不得的态度，当你做某件事的时候，一旦求快，就表示你再也不关心它，而想去做别的事。——《禅与摩托车维修艺术》","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#最后的谈话","page":"我在滴滴这一年","title":"最后的谈话","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"“为什么一定要现在就离开？”","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"当初选择滴滴，最看重的是在这里成长的加速度，在这里工作一年之后，老实说，我已经看不到上升的空间在哪了，大概是，有些绝望吧。又看了看最近部门重组的邮件，不免有些伤感，当初决定做的那几个方向里，随便拧出来一个都是现在的二级部门，借用某同学的一句话说，“明明有一手好牌，最后打得稀烂......”，怪谁呢？只怪这世间无可奈何的事情太多......","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"其实，对我们底下这群干活的算法工程师来讲，最看重的无非是能有良好的成长环境和明确的上升渠道，对于成长环境这块，滴滴先天就有劣势，业务场景单一导致算法在这里落地的场景很有限，然后大家还要争做“明星项目”，心累。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"滴滴文化里有这么一句话：“一切问题都是管理者的问题。”，哈哈，我当然没敢直接跟老大这么说过。只是我忽然在想，如果有一天，我也做了管理者，该怎么解决这些问题。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"理解团队里每个人的诉求。刚工作的时候，对这点没太有体会，感觉大家都一样，应届生嘛，学习和成长才是最主要的事。后来组里陆陆续续有人换岗，有人离开，又有新人进来，才对“天下熙熙，皆为利来；天下攘攘，皆为利往。”这句话多了些理解，此本人之常情，无可厚非。作为管理者，最重要的是在理解每个人诉求的基础上，让团队朝着同一个方向前进。有人图这钱多有钱途、有人看中这里的平台当跳板、还有人觉得这牛人多氛围好问题有挑战......然而，这些不会写脸上，需要在长期的沟通中建立信任。\n方向感、使命与责任。中层管理者对于公司有着举足轻重的作用，负责信息向上反馈和向下流通。往下看，有许多实际问题需要解决；往上看，许多事情又似乎显得很trivial的。想要从一堆乱麻中找出最有价值的点去做，不得不说，确实很考验人的眼光，我对此毫无经验可言，个人觉得，除了极富前瞻力之外，很重要的一点是敢于担当，不怕率领团队走错方向（失败在所难免），最怕的是优柔寡断停滞不前。另外多说一点，相对而言，滴滴这边的管理算是比较扁平的了，但作为底层员工，仍然很难感受到上层的一些调整，这很被动。\nHire Slow, Fire Fast.以前我曾认为，组建一个优秀的团队，显然是要在薪资允许范围内，招最牛的人，然后一起做最棒的事。现在想法有些变化了，招什么样的人，更多的是取决于未来一段时间内，想要做成怎样一件事，至于人嘛，当然是越牛越好，但是也得考虑团队的整体阵容，否则，庙太小，委屈了别人；人太菜，拖了大家的进度。不过要真按我这标准，估计三分之一的人都得换血......","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"离职申请里有这么一个问题：","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"问：“有什么建议，帮助我们做得更好？”答：“招更合适的人，做更有意义的事。”","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"广告业务算是更有意义的事么？不知道。我只知道，自己不再是团队里合适的那个人。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#选择","page":"我在滴滴这一年","title":"选择","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"换工作其实没有做太多特殊准备，师弟师妹们毕业聚餐的时候跟WH简单聊了聊意向，然后很热心推荐我过去Rokid聊了聊，钱给得自然是很多咯，但毕竟还是希望在NLP方面有个更大的平台多沉淀沉淀，所以婉拒了。中间让以前的本科同学CGB给推了一波腾讯AILab那边，面试很高效，也没有特别为难，碰巧ZSC师兄也在那边，是个挺不错的机会，然后也接着投了微软（最早在LinkedIn上联系的我，几乎没来得及准备）、谷歌（面试周期有点长，时间上不允许）、亚马逊（石沉大海），最后在腾讯和微软之间选了后者，别问我为什么，事实上两边薪资差不多，工作内容也比较接近，我抛硬币决定的。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"开个玩笑;)","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"“如果下一份工作不能带来新的挑战和乐趣，那我宁愿待在原地。”，这话是我说的。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"“啥？给很多钱？”，“小孩子才看钱，大人只论成败。”，这话不是我说的......","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#意外","page":"我在滴滴这一年","title":"意外","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"关于离职，和老大谈了有两三次吧，最后大概是看我去意已决，也就同意了。没想到隔了几天，组里在我前面几个月进来的ZJ和DJQ也提了离职。总之，这件事对我的触动很大（对老大而言估计也消化了好久）。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"团队为什么走到了一起？\n又为什么而继续走下去？","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"大家平时都是靠着惯性在往前走，这两个问题似乎无关紧要，然而一旦外部环境发生变化，这些问题便会跳出来拷问团队里的每一个人。如果无法给出令人信服的答案，就难免会有人中途掉队。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"作为管理者，永远无法去评判个体的选择是否正确，每个人都有自己的无奈。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#关于滴滴的一些个人感受","page":"我在滴滴这一年","title":"关于滴滴的一些个人感受","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"再强调下，以下是我的一些个人观点，仅供有兴趣加入滴滴的同学参考，请用批判的眼光理解和吸收！","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"算法这块的缺口不是特别大，但因为这边流动性比较大，需要有人持续填坑。\nDL和RL在这边的实际应用一只手数得过来，需要持续打磨。\n项目与人绑定得太紧，沟通成本较高。需要有类似联络人的角色，将团队内部的人员与需求方解耦。\n内部整体在从“集市”的开发模式走向“大教堂”的模式，系统平台部的工作有很大的发展空间。(虽然办公环境仍然是个“集市”)\n内部急缺一些提升效率的工具，需要有人造轮子（逐渐有人在做，但仍然不够）。\n即便是“明星项目”，也不是那么容易做哦，考虑下时间成本。\n百度过来的人太多了。\n内部相对保守封闭，许多代码看不到，文档没权限的情况，不知道是不是以前留下的恶习，搞得好像人人都在做“明星项目”似的，不利于学习和交流。\n经常会有些高质量的内部分享。\n许多人走了，包括许多我认为的牛人。\n这一年里跟我有过交集的所有人都非常热心（对同事、对乘客、对司机），很感动。\n不要认为进入了一个高速发展中的团队，自己就会自动跟着快速上升。Stay Hungry，Stay Foolish。\n职级体系很扯淡，还是务实点，多考虑下package。（临走前我把部门所有人的职级都扫了一遍）\n以前我不懂什么叫KPI、OKR，现在，好像也还不懂......但愿你们玩得6\n学会包装。以前我曾对此不齿，后来见得多了，也就释然了。","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/#最后","page":"我在滴滴这一年","title":"最后","text":"","category":"section"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"能耐心看到这很不容易了，这一年里买了不少书，有些需要处理，少年不来看看？","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"CHOOSE YOUR WAYBE YOURSELF. KEEP YOUR DREAM. NEVER GIVE UP.","category":"page"},{"location":"essays/The_Past_Year_at_DidiChuxing/","page":"我在滴滴这一年","title":"我在滴滴这一年","text":"(Image: gongka)","category":"page"},{"location":"assets/revealjs/css/theme/README/#Dependencies","page":"-","title":"Dependencies","text":"","category":"section"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Themes are written using Sass to keep things modular and reduce the need for repeated selectors across files. Make sure that you have the reveal.js development environment installed before proceeding: https://revealjs.com/installation/#full-setup","category":"page"},{"location":"assets/revealjs/css/theme/README/#Creating-a-Theme","page":"-","title":"Creating a Theme","text":"","category":"section"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"To create your own theme, start by duplicating a .scss file in /css/theme/source. It will be automatically compiled from Sass to CSS (see the gulpfile) when you run npm run build -- css-themes.","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Each theme file does four things in the following order:","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Include /css/theme/template/mixins.scss","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Shared utility functions.","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Include /css/theme/template/settings.scss","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Declares a set of custom variables that the template file (step 4) expects. Can be overridden in step 3.","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Override","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"This is where you override the default theme. Either by specifying variables (see settings.scss for reference) or by adding any selectors and styles you please.","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"Include /css/theme/template/theme.scss","category":"page"},{"location":"assets/revealjs/css/theme/README/","page":"-","title":"-","text":"The template theme file which will generate final CSS output based on the currently defined variables.","category":"page"},{"location":"index.zh/#关于","page":"👋 关于","title":"👋 关于","text":"","category":"section"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"<div class=\"avatar\"></div>","category":"page"},{"location":"index.zh/#关于我的头像","page":"👋 关于","title":"关于我的头像","text":"","category":"section"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"原始照片拍摄于2012年的夏天，中南大学南校区图书馆前的小树林里，手里拿的是哪本书已经忘了，不过那支笔我还记得，是一支铅笔。 拍摄者是我老婆。","category":"page"},{"location":"index.zh/#关于我","page":"👋 关于","title":"关于我","text":"","category":"section"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"经历：","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"2023至今，在零一万物从事大模型方向基础架构方面的工作。(持续招人中...🤗)\n2022~2023，在启元世界从事游戏领域的自然语言理解与强化学习。\n2017~2022，在微软从事自然语言处理相关的工作。\n2016~2017，在滴滴出行从事智能补贴和调度的工作。\n2013~2016，中科院自动化所自然语言处理处理方向硕士。\n2009~2013，中南大学自动化专业本科。","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"联系：","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"Twitter,偶尔上去逛逛。\n微信,不怎么发朋友圈，没啥可看的。\n豆瓣，偶尔上去记录下。\nlichess，有兴趣来一把？","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"开源：","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"ReinforcementLearning.jl，最近一段时间的主要精力都花在了这上面。\n趣学Julia，前段时间刚开了个坑，还没来得及写点东西。\nJulia中文社区，经常去上面回答问题。","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"编程：","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"Clojure，（曾经）最喜欢的编程语言。\nJulia，目前觉得最好用的语言。","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"还有其它想知道的？欢迎来这里🙋 提问。","category":"page"},{"location":"index.zh/#关于本站","page":"👋 关于","title":"关于本站","text":"","category":"section"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"这个网站我折腾过好几次，目前体会最深的一点是，请用你最熟悉的工具。","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"我目前主要的业余时间都在写Julia，某种程度上讲，我对Julia的熟悉程度甚至超过了工作中所使用的其它编程语言。这也是为什么这一次将博客换成了基于Julia的一套构建流程。在Julia中，广泛使用的是一套是基于Franklin.jl来构建博客，比如Julia的官方博客，不过综合考虑之后，我决定直接基于Documenter.jl来构建。一方面是我有选择恐惧症，面对各种各样的主题模板实在是不知道选哪个好，而自己从头写一个模板又没有那个时间精力了（虽然我之前确实写过一个Distill的主题）；另一方面，我能力有限，实在是没有完全搞清楚Franklin.jl的代码是如何工作的，这让我在使用的过程中感觉很慌...... 相比之下，我对Documenter.jl比较熟悉，了解如何做一些个性化的定制。","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"整个博客的发布流程基本和一个普通的julia安装包的文档发布流程一样，只不过我单独写了一些自定义的插件，所以，如果有人有兴趣构建一个和我类似的博客的话，只需要把这些插件复制粘贴到make.jl文件里即可。","category":"page"},{"location":"index.zh/","page":"👋 关于","title":"👋 关于","text":"本站发表的内容默认遵循 CC-BY-4.0。","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"keywords: Julia,C++ CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/#A-Guide-to-Wrap-a-C-Library-with-CxxWrap.jl-and-BinaryBuilder.jl-in-Julia","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"","category":"section"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"The following parts are not covered here:","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"How to write the wrapper code in C++. (It is detailed here. And I find the examples are also very useful!)","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"And you will learn the following parts after reading this post.","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"How to quickly debug your code?\nThe missing parts that are not documented in BinaryBuilder.jl and CxxWrap.jl","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/#Prepare","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"Prepare","text":"","category":"section"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"First things first. Suppose you want to write a Julia wrapper for a C++ package (I'll take the one I wrote, VisualDL, for example). You need to fork that repo into your own account and clone that repo to your local computer. Then install necessary dependencies according to the document and make sure you can compile it successfully.","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"The next step is to write the wrapper code. Usually you would like to add a flag in the CMakeLists.txt file to signafy whether to build the Julia wrapper or not. Like this","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"option(WITH_JULIA       \"Compile VisualDL with Julia\"               OFF)","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Then make a seperate folder containing all your source codes and corresponding CMakeLists.txt. And include that folder in the root CMakeLists.txt file. Like this","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"if(WITH_JULIA)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/visualdl/julia)\nendif()","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"For the simplest case, only a CMakeLists.txt file and your_wrapper_code.cc are needed. Like this","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Following the instructions from CxxWrap.jl, you should find it easy to write the wrapper codes. If the project you are working on already has a python wrapper, I strongly suggest you to take look at it first. And it will save you a lot of time.","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Then you need to specify how to build your target in the CMakeLists.txt, for example:","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"# 1. find JlCxx\n\nfind_package(JlCxx REQUIRED)\n\n# 2. add libraries and dependencies\n\nadd_library(im ${PROJECT_SOURCE_DIR}/visualdl/logic/im.cc)\nadd_library(sdk ${PROJECT_SOURCE_DIR}/visualdl/logic/sdk.cc ${PROJECT_SOURCE_DIR}/visualdl/utils/image.h)\nadd_dependencies(im storage_proto)\nadd_dependencies(sdk entry binary_record storage storage_proto eigen3)\nadd_library(vdljl SHARED vdljl.cc)\nadd_dependencies(vdljl im entry tablet sdk storage protobuf eigen3)\n\n# 3. specify targets\n\ntarget_link_libraries(vdljl PRIVATE JlCxx::cxxwrap_julia entry binary_record im tablet storage sdk protobuf ${OPTIONAL_LINK_FLAGS})\n\n# 4. install\n\ninstall(TARGETS vdljl\n    RUNTIME DESTINATION lib\n    ARCHIVE DESTINATION lib\n    LIBRARY DESTINATION lib)","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/#Local-Debug","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"Local Debug","text":"","category":"section"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Now you have finished all the necessary changes to the original package, you may want to get the compiled library.","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Let's install CxxWrap in Julia first. Enter the package mode and add CxxWrap","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"(v1.1) pkg> add CxxWrap","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Now you have CxxWrap and the underlying libcxxwrap-julia installed. We can print the library path and the cmake file path:","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"julia> using CxxWrap\n\njulia> CxxWrap.jlcxx_path\n\"/home/tj/.julia/packages/CxxWrap/KcmSi/deps/usr/lib/libcxxwrap_julia.so\"\n\njulia> julia> readdir(joinpath(dirname(CxxWrap.jlcxx_path), \"cmake\", \"JlCxx\"))\n5-element Array{String,1}:\n \"FindJulia.cmake\"\n \"JlCxxConfig.cmake\"\n \"JlCxxConfigExports-release.cmake\"\n \"JlCxxConfigExports.cmake\"\n \"JlCxxConfigVersion.cmake\"","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"What we are interested in here is the the path of joinpath(dirname(CxxWrap.jlcxx_path), \"cmake\", \"JlCxx\") (Here is the /home/tj/.julia/packages/CxxWrap/KcmSi/deps/usr/lib/cmake/JlCxx). Now we can compile the package with JlCxx_DIR properly set:","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"$ mkdir build\n\n$ cd build\n\n$ cmake -DWITH_JULIA=ON -DJlCxx_DIR=/home/tj/.julia/packages/CxxWrap/KcmSi/deps/usr/lib/cmake/JlCxx ..\n\n$ make\n\n$ make install","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Then you can load the compiled library in the Julia REPL for testing:","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"module VisualDL\n  using CxxWrap\n  @wrapmodule(\"/absolute/path/to/your/lib\")\n\n  function __init__()\n    @initcxx\n  end\nend\n\nusing .VisualDL","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/#BinaryBuilder","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"BinaryBuilder","text":"","category":"section"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"In order to leverage the BinaryBuilder, we create an independent repo (for example, VisualDLBuilder) to build the tarballs. Be careful with the following lines:","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Don't forget to specify the compiler_abi field in the platforms like this here, if your code doesn't compile with old gcc.\nFor the sources in the build_tarballs.jl, you can specify an absolute local path pointing to the modified package above for debugging. After making sure that everything works fine, you make a PR then ask the repo owner to tag a new release. And then change this variable into the url => hash form.\nDo not forget to run make install at the end of script. Seriously!\nIn the dependencies part, remember to add both CxxWrap and Julia.","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"As for the .travis.yml file, for now you need to specify the MbedTLS to version 0.6.6 due to the error.","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"Althought there's a helper function in BinaryBuilder.jl named setup_travis to help you set up the deploy step, I never succeed. So I'd suggest you to install travis cli and run travis login –pro first!!! Then travis setup releases.","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/#The-Julia-Wrapper-Package","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"The Julia Wrapper Package","text":"","category":"section"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"This is the final step. You create a new package. Add the CxxWrap as your dependency. Rename the build file you get by BinaryBuilder to build.jl and put it into the deps folder. And you expect to get the deps.jl after running julia deps/build.jl. Unfortunately, you'll see an error like this:","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"ERROR: LoadError: LibraryProduct(nothing, [\"libvdljl\"], :libvdljl, \"Prefix(/home/tianjun/tmp/visualdl/deps/usr)\") is not satisfied, cannot generate deps.jl!","category":"page"},{"location":"essays/A_Guide_to_Wrap_a_C++_Library_with_CXXWrap.jl_and_BinaryBuilder.jl_in_Julia/","page":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","title":"A Guide to Wrap a C++ Library with CxxWrap.jl and BinaryBuilder.jl in Julia","text":"The reason is that we need the shared package of jlcxx. So remember to put using CxxWrap in the first line of build.jl. Then everything should work as you wish.","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"keywords: Cuda CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/CUDA_in_One_Picture/#一张图说cuda","page":"一张图说cuda","title":"一张图说cuda","text":"","category":"section"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"(Image: cuda.jpg)","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"没去上几次高性能计算的课，有不完善的地方还请见谅。赶在明天考试之前复习了下课件，加上自己的一些理解随手画了画。","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"说说自己对并行计算的一点浅显认识。以前一直以为，并行计算嘛，就是fork出进程然后各干各的，最后汇总下结果。但发现实际中并行计算往往并非是完全独立的，相反，各个进程之间往往需要各种同步和交流机制。这在一定程度上对编程能力提出了巨大挑战，一方面需要对任务进行分块，另一方面需要自己控制好同步和交流的节奏（弄不好就出现计算结果飘忽不定的情况）。也就是说，原来在串行程序中根本不会出现的资源读写问题，到了并行程序里可能就会成为大问题。许多事情都需要自己手动控制好，就算再有耐心的程序猿看到了也会有些抓狂。只能寄希望以后某一天编译器可以变得足够智能，把苦逼的程序猿解放出来。另外不得不说，pycuda的封装做得很好，只是我没比较过性能上的差异。","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"为了写大作业，我不得不重拾很久都没碰过的c语言。嗯，指针真是个好东西，有时候真是无比怀念啊......不过，数组越界的问题，完全靠自觉了......唉，凡事都是有得有失。不过我觉得自己应该不会再用c来并行计算了，如果可以，我还是更愿意用一些高层的语言来写，尽管性能上可能会有些损失，但是，相比调试上所花的时间精力来说，值了。（我能说我花了一个多星期来调试大作业么...最后真的是把并行程序和串行程序对照着比较每一次的中间结果。。。然后发现是个相当无厘头的bug！人生啦，就这么毁在bug上了。。。)","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"不过，抛开这些底层的细节。借用老师在课上的一句话来说，并行编程的确是一门艺术活。真正能体现思考的魅力。至少我在编程的时候，脑海里走的是这么个流程。","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"首先，在脑海里虚拟出成千上万个脑细胞，把每个脑细胞想象成一个thread\n再把任务分配到每个脑细胞，并且将其分组group成一个个block\n将思绪按照时间维发散下去，read,write,sync, communicate......\n然后，从每个group里挑选出个老大，负责最后信息的汇总\n最后，唉，又耗费了好多脑细胞。。。清空Memory，重来。。。","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"关于并行编程的一些思考，推荐看看一个系列文章【1】、【2】、【3】，文中关于为什么要学习并行编程，以及并行编程和串行编程的一些差异讲得很不错，而且给出了一些例子。","category":"page"},{"location":"essays/CUDA_in_One_Picture/","page":"一张图说cuda","title":"一张图说cuda","text":"最后，但求明天考试顺利。。。","category":"page"},{"location":"essays/Parallel_Computing/","page":"并发模型串讲","title":"并发模型串讲","text":"","category":"page"},{"location":"essays/Parallel_Computing/","page":"并发模型串讲","title":"并发模型串讲","text":"keywords: Concurrency,C#,Python,Julia,Clojure,Java CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Parallel_Computing/#并发模型串讲","page":"并发模型串讲","title":"并发模型串讲","text":"","category":"section"},{"location":"essays/Parallel_Computing/","page":"并发模型串讲","title":"并发模型串讲","text":"随便写点我所接触过的各个语言的并发模型。","category":"page"},{"location":"essays/Parallel_Computing/#Events-in-C#","page":"并发模型串讲","title":"Events in C#","text":"","category":"section"},{"location":"essays/Parallel_Computing/#Reference","page":"并发模型串讲","title":"Reference","text":"","category":"section"},{"location":"essays/Parallel_Computing/","page":"并发模型串讲","title":"并发模型串讲","text":"Concurrent Computing","category":"page"},{"location":"essays/The_Chinese_Translation_of_Bayesian_Analysis_with_Python/","page":"-","title":"-","text":"","category":"page"},{"location":"essays/The_Chinese_Translation_of_Bayesian_Analysis_with_Python/","page":"-","title":"-","text":"keywords: Book,Python CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/The_Chinese_Translation_of_Bayesian_Analysis_with_Python/","page":"-","title":"-","text":"Background\nTimeUsed\nHighlights in Translation\nThinking in Translation\nBLEU","category":"page"},{"location":"programming/Dot_Product_in_Julia/#如何在Julia中计算点积?","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"回字有几种写法? 🤔","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-11-19</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-11-19</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-11-16</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-11-16</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='54' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='54' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='35' height='20' fill='#0F80C1'/><rect width='54' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='355' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='250'>Julia</text><text x='355' y='140' transform='scale(.1)' textLength='250'>Julia</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='60' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='60' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='41' height='20' fill='#0F80C1'/><rect width='60' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='310'>CUDA</text><text x='385' y='140' transform='scale(.1)' textLength='310'>CUDA</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='52' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='52' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='33' height='20' fill='#0F80C1'/><rect width='52' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='345' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='230'>GPU</text><text x='345' y='140' transform='scale(.1)' textLength='230'>GPU</text></g></svg></div>","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"两个向量veca = a_1 a_2  a_n 和 vecb = b_1 b_2  b_n 之间点积（dot product)的代数定义如下：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"veca cdot vecb = sum^n_i=1 a_i b_i = a_1 b_1 + a_2 b_2 +  + a_n b_n","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"那么，如何在Julia中快速计算点积呢？","category":"page"},{"location":"programming/Dot_Product_in_Julia/#版本1：-使用-LinearAlgebra-标准库中的-dot-函数","page":"如何在Julia中计算点积?","title":"版本1： 使用 LinearAlgebra 标准库中的 dot 函数","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using LinearAlgebra\n\njulia> N = 1024*1024\n1048576\n\njulia> x, y = rand(N), rand(N);\n\njulia> dot(x,y)\n262311.47579656926\n","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"先测试下标准库里 dot 的性能：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using BenchmarkTools\n\njulia> @benchmark dot($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  244.474 μs …  43.973 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     252.275 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   314.178 μs ± 884.297 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▇█▄▃▂▁▁▁▁▁▁▁ ▁▂                                               ▂\n  ████████████████▇▇▇▇▇█▇▇▇▇▇▇▇▇▆▆▅▆▇▇▅▃▅▅▄▃▄▄▃▃▄▃▅▇██▆▅▅▃▄▁▃▃▃ █\n  244 μs        Histogram: log(frequency) by time        594 μs <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"中间值位于252μs附近。","category":"page"},{"location":"programming/Dot_Product_in_Julia/#版本2：-for循环","page":"如何在Julia中计算点积?","title":"版本2： for循环","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"当然，即使不使用自带的dot函数，我们也可以很方便地用一个 for 循环来实现：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot2_1(x, y)\n    res = 0\n    for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"写法基本和原始的数学表达式一样，那性能如何呢？","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_1($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 2134 samples with 1 evaluation.\n Range (min … max):  2.286 ms …  2.942 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     2.302 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   2.330 ms ± 56.418 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  █ █                                                         \n  █▃█▇▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▂▁▁▁▁▂▂▂▂▂▁▂ ▃\n  2.29 ms        Histogram: frequency by time         2.6 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"呃， 耗时差不多是原来的9倍了。有点不可思议，那怎么优化下呢？ 先用 @code_warntype 看下：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"(Image: )","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"注意到上面标红色的部分，这是提醒我们上面的实现中出现了类型不稳定的情况。主要原因是res在dot2_1函数中，初始化成了Int64类型的0，而我们的输入是两个Vector{Float64}类型的向量。了解这一点之后，可以把上面的实现写得更灵活一些：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot2_2(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里， 通过 promote_type 获取类型信息。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_2($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 3384 samples with 1 evaluation.\n Range (min … max):  1.410 ms …  3.580 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     1.449 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.464 ms ± 66.969 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n         ▆ ▃█ ▄                                               \n  ▂▃▃▃▅█▆██████▇▅█▄▄▄▄▄▄▄▃▄▄▄▃▄▄▄▄▄▃▃▄▃▃▃▂▃▃▃▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂ ▃\n  1.41 ms        Histogram: frequency by time        1.59 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到，比之前稍好了一些，大约是之前的5倍左右。 当然，我们还可以顺手做些进一步的优化，加上@simd并去掉边界检查：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot2_3(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    @inbounds @simd for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_3($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 5545 samples with 1 evaluation.\n Range (min … max):  848.684 μs …  1.296 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     871.641 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   888.964 μs ± 50.935 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▂▇█▇▆▇▆▅▅▅▄▄▃▃▃▂▂▁▂▁▁▁                                       ▂\n  ███████████████████████▇▇▇▇▇▆▆▅▅▆▆▇█▇▇████▇█▇▅▇▇▅▅▅▄▄▅▅▅▅▅▄▃ █\n  849 μs        Histogram: log(frequency) by time      1.11 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这样差距进一步缩小了一些。当然，我们还可以进一步利用 LoopVectorization.jl 这个库来提速：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"using LoopVectorization\nfunction dot2_4(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    @turbo for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_4($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 5905 samples with 1 evaluation.\n Range (min … max):  802.618 μs …  1.211 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     820.607 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   832.880 μs ± 39.868 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n   ▂█▄                                                          \n  ▂███▆▆▇▅▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂\n  803 μs          Histogram: frequency by time         1.02 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"看起来稍微快了一些，不过似乎仍然与LinearAlgebra中的性能有3倍多的性能差距？其实不然，LinearAlgebra中使用了BLAS，而其默认是有多线程加速的，为了公平比较，可以将其线程数设置为1，然后对比：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> LinearAlgebra.BLAS.set_num_threads(1)\n\njulia> @benchmark dot($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 5980 samples with 1 evaluation.\n Range (min … max):  795.374 μs …  1.104 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     811.659 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   823.303 μs ± 37.397 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n   ▅█                                                           \n  ▃███▅▇▇▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃\n  795 μs          Histogram: frequency by time         1.02 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到，二者相差无几。","category":"page"},{"location":"programming/Dot_Product_in_Julia/#版本3：-一行代码","page":"如何在Julia中计算点积?","title":"版本3： 一行代码","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"当然，有的时候其实对性能也不是那么关心，反而代码的简洁性更重要，那么也可以简单地用一行代码来搞定：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark sum(a*b for (a,b) in zip($(rand(N)),$(rand(N))))\nBenchmarkTools.Trial: 3823 samples with 1 evaluation.\n Range (min … max):  1.232 ms …  1.840 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     1.281 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.295 ms ± 54.505 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n   ▃█▇▄▆▂                                                     \n  ▃███████▆▇▄▄▄▅▅▄▅▄▅▆▆▆▅▅▆▇▆▆▆▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁ ▃\n  1.23 ms        Histogram: frequency by time        1.46 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"或者，直接用 mapreduce:","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"mapreduce(*, +, x, y)","category":"page"},{"location":"programming/Dot_Product_in_Julia/#版本4：-多线程","page":"如何在Julia中计算点积?","title":"版本4： 多线程","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"受前面LinearAlgebra中多线程的启发，我们同样也可以用Julia自带的多线程完成点积的计算。不过需要记得在启动Julia的时候，通过 -t auto 来指定线程数。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using Base.Threads\n\njulia> nthreads()\n4","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里我本机就4个线程。所以","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot4_1(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    @threads for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot4_1($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 109 samples with 1 evaluation.\n Range (min … max):  28.586 ms … 113.851 ms  ┊ GC (min … max):  0.00% … 62.77%\n Time  (median):     39.838 ms               ┊ GC (median):     0.00%\n Time  (mean ± σ):   45.888 ms ±  20.565 ms  ┊ GC (mean ± σ):  14.59% ± 19.04%\n\n   ▁      █▃                                                    \n  ▇█▄█▆▁▁▇██▆▇▄▄▄▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▄▁█▇▄ ▄\n  28.6 ms       Histogram: log(frequency) by time       108 ms <\n\n Memory estimate: 32.00 MiB, allocs estimate: 2097174.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这个结果就比较有意思了，由于我们的多线程实现存在race condition, 实际上得到的结果并不对，并且速度相当慢。当然，为了保证结果的正确性，可以对res加锁，但并不能带来性能上的提升。一个简单的办法是，将数据分片，每个线程做自己单独的计算，最后把多个线程的结果合并：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot4_2(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zeros(promote_type(X,Y), nthreads())\n    @threads for i in 1:length(x)\n        @inbounds res[threadid()] += x[i] * y[i]\n    end\n    sum(res)\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot4_2($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  378.194 μs …  16.460 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     397.990 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   433.403 μs ± 243.825 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▅█▆▆▆▄▂▁ ▁▁      ▁▂▂▁ ▂▃▃▂▁                                   ▂\n  ██████████████▇▇███████████▇▅▆▅▅▇▅▁▃▁▃▃▁▄▁▃▁▁▅▇▄▅▃▃▄▅▄▁▄▄▆▅▄▅ █\n  378 μs        Histogram: log(frequency) by time        878 μs <\n\n Memory estimate: 1.98 KiB, allocs estimate: 22.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这样得到的结果，相比单线程的结果要快了近3.2倍。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"Julia标准库里没有提供多线程的求和操作，不过有一些第三方库提供了这类基本操作，比如ThreadsX.jl。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using ThreadsX\n\njulia> @benchmark ThreadsX.sum(a*b for (a,b) in zip($(rand(N)),$(rand(N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  291.519 μs …  2.023 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     326.248 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   339.611 μs ± 42.828 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n        ▃▆█▆▄▂▁                                                 \n  ▁▂▃▅▆█████████▆▆▆▆▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▃\n  292 μs          Histogram: frequency by time          472 μs <\n\n Memory estimate: 17.45 KiB, allocs estimate: 249.","category":"page"},{"location":"programming/Dot_Product_in_Julia/#版本5：-GPU版","page":"如何在Julia中计算点积?","title":"版本5： GPU版","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"如果你手上正好有块GPU，不妨试试看在GPU上做点积。Julia中的CUDA.jl极大地方便了Julia语言里的GPU编程，针对点积这样的常见操作，其提供了基于cuBLAS的封装，下面来试下：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using CUDA\n\njulia> @benchmark CUDA.@sync dot($(cu(rand(N))), $(cu(rand(N)))) \nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  26.521 μs … 68.923 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     27.798 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   28.331 μs ±  1.494 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▂▁   ▃▇█▅▁ ▃▅▇▅▂   ▂▃                                       ▂\n  ███▆▇████████████▇████▆▄▄▅▆▆▅▅▅▅▅▅▅▆▆▆▆▅▆▄▅▆▅▄▅▅▂▅▄▄▅▅▄▄▃▅▄ █\n  26.5 μs      Histogram: log(frequency) by time      35.9 μs <\n\n Memory estimate: 16 bytes, allocs estimate: 1.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到，其速度相当快。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"不过，由于cuBLAS里的dot只针对常见的 Float32, Float64, Float16 以及对应的复数类型的GPU上的向量有实现，当输入的两个向量的元素类型不一致时，目前的CUDA.jl(v3.5.0)会fallback到CPU版本的实现，导致性能极慢：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> z = rand(Bool, N);\n\njulia> cx, cz = cu(x), cu(z);\n\njulia> @time dot(cx, cz)\n┌ Warning: Performing scalar indexing on task Task (runnable) @0x00007f63cc0c0010.\n│ Invocation of getindex resulted in scalar indexing of a GPU array.\n│ This is typically caused by calling an iterating implementation of a method.\n│ Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n│ and therefore are only permitted from the REPL for prototyping purposes.\n│ If you did intend to index this array, annotate the caller with @allowscalar.\n└ @ GPUArrays ~/.julia/packages/GPUArrays/3sW6s/src/host/indexing.jl:56\n 12.914170 seconds (6.29 M allocations: 1.000 GiB, 0.87% gc time)","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"一个简单的workaround是，先把类型不同的两个向量转换成相同的类型，然后再调用dot函数：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark CUDA.@sync dot($(cu(rand(N))), convert(CuArray{Float32}, $(cu(rand(Bool, N)))))\nBenchmarkTools.Trial: 3968 samples with 1 evaluation.\n Range (min … max):  1.073 ms …   4.408 ms  ┊ GC (min … max): 0.00% … 30.06%\n Time  (median):     1.140 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.252 ms ± 464.709 μs  ┊ GC (mean ± σ):  3.35% ±  6.05%\n\n  ▂█▃  ▄▁                                     ▁                \n  ███▇▆██▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄█▅▃▁▃▁▁▁▃▁▃▁▁▁█ █\n  1.07 ms      Histogram: log(frequency) by time      3.85 ms <\n\n Memory estimate: 5.00 MiB, allocs estimate: 12.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"相比原来的GPU版本，多出来了一次拷贝数据的时间，这显然不是我们想要的。 不过，CUDA.jl的强大之处在于，针对这类没有内置的实现，我们可以很容易地通过编写自定义的核函数来实现。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_1(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res)\n        for i in 1:length(x)\n            @inbounds res[] += x[i] * y[i]\n        end\n    end\n    @cuda kernel(x, y, res)\n    res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"自己手写核函数经常容易出现各种bug，所以首要任务是先确认我们计算的结果是正确的：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot5_1(cx, cz), dot(cx, convert(CuArray{Float32}, cz)))\ntrue","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"注意这里用的是isapprox来做比较。看起来我们得到的结果是正确的，那么其性能如何呢？","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark CUDA.@sync dot5_1($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 103 samples with 1 evaluation.\n Range (min … max):  48.510 ms …  54.895 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     48.514 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   48.606 ms ± 657.494 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  █▁                                                            \n  ███▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄ ▄\n  48.5 ms       Histogram: log(frequency) by time      50.6 ms <\n\n Memory estimate: 1.78 KiB, allocs estimate: 29.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"呃，还不如先convert了再调用自带的dot函数...... 那问题出在哪呢？其实上面的核函数只用了一个线程在计算，但是在GPU上有大量的线程可供计算，于是，可以采用上面的CPU上多线程的方法来计算：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_2(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res)\n        index = threadIdx().x\n        stride = blockDim().x\n        for i in index:stride:length(x)\n            @inbounds res[] += x[i] * y[i]\n        end\n    end\n    k = @cuda launch=false kernel(x, y, res)\n    config = launch_configuration(k.fun)\n    k(x, y, res; threads=min(length(x), config.threads))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里在运行核函数的时候，指定了threads的个数，在核函数内部的for循环把数据根据threads切分成了不同的片段，每个thread负责计算各自的一部分。 先验证下正确性：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot5_2(cx, cz), dot(cx, convert(CuArray{Float32}, cz)))\nfalse","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"等等，这里似乎犯了和前面多线程计算时候一样的错误，在往res里累积求和的时候，会存在静态条件。仔细观察可以发现，我们不用每次都往res里写入结果，只需要在每个线程内部先计算完，最后叠加上去即可，同时最后要加锁。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_3(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        stride = blockDim().x\n        s = zero(T)\n        for i in index:stride:length(x)\n            @inbounds s += x[i] * y[i]\n        end\n        CUDA.@atomic res[] += s\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun)\n    k(x, y, res, T; threads=min(length(x), config.threads))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里用了CUDA.@atomic来保证原子操作，同样，先确认计算的正确性：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_3(cx, cz))\ntrue","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"再看下速度如何：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark CUDA.@sync dot5_3($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  175.298 μs … 448.774 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     178.373 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   179.218 μs ±   4.301 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n    ▁▃▅▅▇█████▇▇▇▇▇▆▆▅▅▄▄▃▂▂▁▁▁▁ ▁   ▁▁▁▁▁ ▁▁▁▁▁▁▁              ▃\n  ▅▅██████████████████████████████████████████████▇██▇▇▆▇▆▅▅▇▅▆ █\n  175 μs        Histogram: log(frequency) by time        191 μs <\n\n Memory estimate: 2.16 KiB, allocs estimate: 39.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"还不错，至少比CPU版本快了，但是离CUBLAS版本的性能还有一定差距。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"考虑到一块GPU中，还会有多个block，而上面我们才用了其中的一个block，显然还有很大的优化空间！","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"一个基本思路是，根据输入的数据，分配多个block，在每个block的数据区块中，按thread再切分一次，每个thread计算自己所属的数据的点积之和。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_4(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        thread_stride = blockDim().x\n        block_stride = (length(x)-1) ÷ gridDim().x + 1\n        start = (blockIdx().x - 1) * block_stride + 1\n        stop = blockIdx().x * block_stride\n\n        s = zero(T)\n        for i in start-1+index:thread_stride:stop\n            @inbounds s += x[i] * y[i]\n        end\n        CUDA.@atomic res[] += s\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun)\n    k(x, y, res, T; threads=min(length(x), config.threads), blocks=config.blocks)\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_4(cx, cz))\ntrue\n\njulia> @benchmark CUDA.@sync dot5_4($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  134.011 μs … 383.172 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     134.933 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   135.095 μs ±   2.723 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n       ▁▃▄▇▇▇▆████▇▆▃▃▁                                          \n  ▂▂▃▅▆█████████████████▆▅▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂ ▄\n  134 μs           Histogram: frequency by time          138 μs <\n\n Memory estimate: 2.16 KiB, allocs estimate: 39.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"OK, 看起来稍微快了一些。需要注意的是，前面我们直接将每个thread计算的结果往一个res对象中通过加锁叠加上去了，这样导致每个block中每个thread都会卡在原子操作那一步。 一种优化方式是每个block的内部，先把各个thread的计算结果缓存起来，等一个block内所有thread都计算出来了同步一下，然后内部先reduce，最后再通过原子操作同步到最终的结果上。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_5(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        thread_stride = blockDim().x\n        block_stride = (length(x)-1) ÷ gridDim().x + 1\n        start = (blockIdx().x - 1) * block_stride + 1\n        stop = blockIdx().x * block_stride\n\n        cache = CuDynamicSharedArray(T, (thread_stride,))\n\n        for i in start-1+index:thread_stride:stop\n            @inbounds cache[index] += x[i] * y[i]\n        end\n\n        sync_threads()\n\n        if index == 1\n            s = zero(T)\n            for i in 1:thread_stride\n                s += cache[i]\n            end\n            CUDA.@atomic res[] += s\n        end\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun; shmem=(threads) -> threads*sizeof(T))\n    threads = min(length(x), config.threads)\n    blocks = config.blocks\n    k(x, y, res, T; threads=threads, blocks=config.blocks, shmem=threads*sizeof(T))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_5(cx, cz))\ntrue\n\njulia> @benchmark CUDA.@sync dot5_5($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  54.364 μs … 358.597 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     55.217 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   55.559 μs ±   4.023 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n     ▄▇█▇▅▃▂                                                    \n  ▂▄█████████▇▇▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂ ▃\n  54.4 μs         Histogram: frequency by time         61.3 μs <\n\n Memory estimate: 2.33 KiB, allocs estimate: 43.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到,其性能跟CUBLAS比较接近了。当然，上面的代码还可以进一步优化，上面最后reduce的时候，只有index为1的线程在运行，其实可以多个线程一起工作：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"using CUDA:i32\n\nfunction dot5_6(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        thread_stride = blockDim().x\n        block_stride = (length(x)-1i32) ÷ gridDim().x + 1i32\n        start = (blockIdx().x - 1i32) * block_stride + 1i32\n        stop = blockIdx().x * block_stride\n\n        cache = CuDynamicSharedArray(T, (thread_stride,))\n\n        for i in start-1i32+index:thread_stride:stop\n            @inbounds cache[index] += x[i] * y[i]\n        end\n        sync_threads()\n\n        mid = thread_stride\n        while true\n            mid = (mid - 1i32) ÷ 2i32 + 1i32\n            if index <= mid\n                @inbounds cache[index] += cache[index+mid]\n            end\n            sync_threads()\n            mid == 1i32 && break\n        end\n\n        if index == 1i32\n            CUDA.@atomic res[] += cache[1]\n        end\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun; shmem=(threads) -> threads*sizeof(T))\n    threads = min(length(x), config.threads)\n    blocks = config.blocks\n    k(x, y, res, T; threads=threads, blocks=config.blocks, shmem=threads*sizeof(T))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_6(cx, cz))\ntrue\n\njulia> @benchmark CUDA.@sync dot5_6($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  22.520 μs … 375.954 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     23.475 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   23.762 μs ±   3.748 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n        ▁▅██▆▃▁                                                 \n  ▂▂▃▃▄▆███████▇▅▄▅▅▅▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂ ▃\n  22.5 μs         Histogram: frequency by time           28 μs <\n\n Memory estimate: 2.16 KiB, allocs estimate: 39.","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这样，最终的结果跟CUBLAS的性能基本一致了。","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"从代码层面上讲，上面的代码还可以进一步简化下，上面的while循环其实是一个经典的reduce操作，而CUDA.jl中内置了一个函数reduce_block来简化该操作，下面是简化后的核函数写法：","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"忘了说了，如果你还是one-line solution的爱好者，其实之前的CPU版本的写法在GPU上同样work哦~","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"mapreduce((x,y)->dot(x, y), +, x, y)","category":"page"},{"location":"programming/Dot_Product_in_Julia/#参考","page":"如何在Julia中计算点积?","title":"参考","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"Introduction to CUDA.jl\nGTC-2010\nCUDA.jl#1240","category":"page"},{"location":"programming/Dot_Product_in_Julia/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/Thinking_in_NLP/","page":"关于NLP的一些思考","title":"关于NLP的一些思考","text":"","category":"page"},{"location":"essays/Thinking_in_NLP/","page":"关于NLP的一些思考","title":"关于NLP的一些思考","text":"keywords: Job,NLP CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Thinking_in_NLP/#关于NLP的一些思考","page":"关于NLP的一些思考","title":"关于NLP的一些思考","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"keywords: Algorithm CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#Throwing-Eggs-from-a-Building","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"下午做练习题时碰到的问题，Algorithms, 4th中的1.4.24和1.4.25。思考了之后发现是个挺有意思的问题。下面结合题目和网上的一些资料做个简单的分析。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#1.-问题描述","page":"Throwing Eggs from a Building","title":"1. 问题描述","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"原文的问题是这样的：","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"1.4.24 Throwing eggs from a building. Suppose that you have an N-story building and plenty of eggs. Suppose also that an egg is broken if it is thrown off floor F or higher, and intact otherwise. First, devise a strategy to determine the value of F such that the number of broken eggs is sim lg N when using sim lg N throws, then find a way to reduce the cost to sim 2lg F.","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"简单来说就是这么个意思：","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"在一座N层楼房上往下扔假鸡蛋，这些假鸡蛋只有在第F层楼及以上才会被摔破（没有摔破的鸡蛋可以接着用）。为了找到这个F，设计一个思路使得尝试的次数接近sim lg N并且最后摔破的鸡蛋个数接近sim lg N，然后想办法降低到sim 2lg F。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#1.1-二分法","page":"Throwing Eggs from a Building","title":"1.1 二分法","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"首先想到的应该是用二分法来解决这个问题。从中间数（N/2)开始，如果鸡蛋摔破了，就继续往下找。显然，如果鸡蛋在1楼才摔破的话，摔破的鸡蛋个数和尝试的次数都接近sim lg N。问题在于，如何降低到sim 2lg F？","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#1.2-减少摔碎的鸡蛋个数","page":"Throwing Eggs from a Building","title":"1.2 减少摔碎的鸡蛋个数","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"试着思考下这个问题的特殊之处，如果某一次尝试的过程中鸡蛋没有摔破，那么可以接着用！回顾前面的二分法中的极端情况，每次尝试都摔碎了个蛋，太浪费了。也就是说，如果换成从下往上搜索而不是从中间开始搜索，那么最初的几次尝试很大可能不会摔碎蛋的。于是，最简单的应该就是拿着鸡蛋从1楼开始往上一层一层试，直到鸡蛋摔碎。不过这样虽然摔碎的鸡蛋的个数降到了1个，但是测试的次数却上升到了F个。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#1.3-平衡摔碎的鸡蛋数和尝试的次数","page":"Throwing Eggs from a Building","title":"1.3 平衡摔碎的鸡蛋数和尝试的次数","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"从前面的分析可以感受到，如果降低摔碎的鸡蛋个数，测试的次数就上去了，反之亦然。那么如何平衡呢？前面是拿着鸡蛋一层一层往上测试，这样子太慢了！不妨每隔两层（三层，五层？）测试一次，摔碎了的话再退回来。这样测试的次数将低了一些，但是仍然是线性的。还是太慢了！干脆换成指数增长。假设第k次摔碎了，然后再倒回来采用二分查找。这样摔碎的鸡蛋个数是sim lg(F2)（前面在第1242^k-1层测试的时候没摔碎，只有后面2^k-1到 2^k之间 二分查找时候才有可能摔碎），而尝试的次数  为sim 2lg F。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#1.4-疑惑","page":"Throwing Eggs from a Building","title":"1.4 疑惑","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"疑惑的是，这样子虽然肯定可以降低摔碎鸡蛋的个数，但并不一定能降低尝试的次数啊","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#2-问题扩展","page":"Throwing Eggs from a Building","title":"2 问题扩展","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"1.4.25 Throwing two eggs from a building. Consider the previous question, but now suppose you only have two eggs, and your cost model is the number of throws. Devise a strategy to determine F such that the number of throws is at most 2sqrtN, then find a way to reduce the cost to sim csqrtF. This is analogous to a situation where search hits (egg intact) are much cheaper than misses(egg broken).","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#2.1-简单的尝试","page":"Throwing Eggs from a Building","title":"2.1 简单的尝试","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"现在的问题变成了，如果只有两个鸡蛋，怎样才能降低查找次数？","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"不考虑其他的，假设楼房有100层，现在手上有两个蛋，先跑到50楼扔一个了再说，人品不好，蛋碎了，那么接下来该怎么办？老老实实拿着剩下的那个从一楼开始尝试吧，最多试50次。直觉告诉我们，一开始就选太大了反而得不偿失。事实上，借用前一个问题的分析思路，可以尝试用线性增长的方式来解决这个问题(显然这次不能用指数增长了，还得check最后一个区间的……)。假如每次往上提升采用一个定步长，其实可以算出最优解。设步长为x，那么最大的查找次数为x + frac100x，其最优解近似于2sqrtN","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#2.2-变步长","page":"Throwing Eggs from a Building","title":"2.2 变步长","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"前面这种解法的瓶颈点在哪呢？最后一步！","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"假设鸡蛋在最后一步那地方碎了，此时已经走了frac100x步，然后还需要再尝试10次（从90到100层之间，也就是步长的长度）。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"通过采用变步长的思想，前面这个解决方案还可以稍微改进一些。我们知道，二分法求解问题的核心思想是最大化信息熵，通俗点说，就是每check一次之后，不管目标值在check点的左边还是右边，对我来说需要check的次数是相同的。对应到这个问题上，设第一步的步长为x_1，不管蛋碎了没有，我希望接下来check的次数都是相同的。显然，如果蛋碎了，我就只剩一个蛋了，还需要从下往上checkx_1-1次，如果蛋没碎，此时只要x_1选取的合理，满足前面最大熵要求，我仍然只需要x_1 - 1次就能找到F。如此迭代下去便不难发现，最后可以得到公式x_1 + (x_1-1) + (x_1 - 1 - 1) +  + 1 = N，从而可以求解出初始步长。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/#3-更多的鸡蛋","page":"Throwing Eggs from a Building","title":"3 更多的鸡蛋～","text":"","category":"section"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"如果鸡蛋的个数变成3个，4个，5个......","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"采用减而治之的思想，可以很好去解决这个问题。以3个鸡蛋为例子：","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"首先，得确定第一个步长x_1，\n如果碎了，则问题转换成了2个鸡蛋x_1-1层楼的问题，（根据前面的方法假设该问题的最优解为x_c)；\n如果没碎，则转换成3个鸡蛋N-x_1层楼的问题","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"通过迭代的方法比较容易求解该类问题。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"更多有意思的分析可以看看这里。 下图是从上文中摘出的一幅图，用来说明不同情况下需要的蛋的个数。","category":"page"},{"location":"essays/Throwing_Eggs_from_a_Building/","page":"Throwing Eggs from a Building","title":"Throwing Eggs from a Building","text":"(Image: )","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"keywords: Flux.jl,Julia CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/#详解Flux.jl","page":"详解Flux.jl","title":"详解Flux.jl","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"本文将详细介绍Julia语言中的一个深度学习库——Flux.jl，目的是在理解其内部结构之后，能在其之上做个性化定制。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/#核心概念","page":"详解Flux.jl","title":"核心概念","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/#TrackedArray","page":"详解Flux.jl","title":"TrackedArray","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"TrackedArray类型用来对最基本的数组做封装。我们知道，深度学习框架带来的最大好处之一就是不用手写梯度反传的函数，其实现是基于这样一个事实，对于一类基本的函数，其梯度的计算方式是已知的，于是通过链式法则可以实现对整个网络中的每个参数进行更新。因此，一个TrackedArray类型应该至少包含","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"数据，即数组当前的值\n映射函数，描述当前数据是根据怎样的函数（以及对应的参数）得到的，从而方便进一步反传\n梯度，当前数据的梯度","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"然后我们看看源码中的定义","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"struct TrackedArray{T,N,A<:AbstractArray{T,N}} <: AbstractArray{T,N}\n  tracker::Tracked{A}\n  data::A\n  grad::A\n  TrackedArray{T,N,A}(t::Tracked{A}, data::A) where {T,N,A} = new(t, data)\n  TrackedArray{T,N,A}(t::Tracked{A}, data::A, grad::A) where {T,N,A} = new(t, data, grad)\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"可以看到，代码的定义与我们的直觉相符，这里的tracker字段就是用来记录data字段是怎么得到的。再具体看下Tracked{T}的定义：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"mutable struct Tracked{T}\n  ref::UInt32\n  f::Call\n  isleaf::Bool\n  grad::T\n  Tracked{T}(f::Call) where T = new(0, f, false)\n  Tracked{T}(f::Call, grad::T) where T = new(0, f, false, grad)\n  Tracked{T}(f::Call{Nothing}, grad::T) where T = new(0, f, true, grad)\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"ref先不管，isleaf用来标志当前是否是叶子节点(叶子节点有特殊含义，需要作区分，原因是一旦遇到叶子节点，就不需要继续反传了)，grad用来记录梯度（初看似乎跟TrackedArray中有重复？其实从数据结构上来看，需要有这么个地方做缓存，后面会解释。），最关键的f记录了作用的函数以及其参数，下面是Call的定义：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"struct Call{F,As<:Tuple}\n  func::F\n  args::As\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"其实就是为了弥补Julia中函数的类型没有携带参数类型。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"总结一下:","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"TrackedArray 包含 data, grad 和 tracker 三个字段，分别用于记录当前节点上的数据，梯度以及当前节点是如何根据其它节点计算得到的。\ntracker 是一个 Tracked{T} 类型，其中最核心的一个字段是计算函数f::Call。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/#前向计算","page":"详解Flux.jl","title":"前向计算","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"现在我们了解了TrackedArray的组成，但是具体怎么做前向计算的呢？","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/#通过param构造TrackedArray","page":"详解Flux.jl","title":"通过param构造TrackedArray","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"万丈高楼平地起！","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"在julia中，数组一般以AbstractArray的形式存在，而在Flux中，为了存储前向计算函数和梯度信息，需要将这类AbstractArray数据构造成TrackedArray，然后才能对不同的TrackedArray做前向计算。param函数就是用来构造TrackedArray的。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"# https://github.com/FluxML/Flux.jl/blob/master/src/tracker/Tracker.jl#L107\nparam(xs::AbstractArray) = TrackedArray(float.(xs))\n\n# https://github.com/FluxML/Flux.jl/blob/master/src/tracker/lib/array.jl#L32\nTrackedArray(x::AbstractArray) = TrackedArray(Call(), x, zeros(x))\n\n# https://github.com/FluxML/Flux.jl/blob/master/src/tracker/Tracker.jl#L25\nCall() = Call(nothing, ())\n\n# https://github.com/FluxML/Flux.jl/blob/master/src/tracker/lib/array.jl#L29\nTrackedArray(c::Call, x::A, Δ::A) where A <: AbstractArray = TrackedArray{eltype(A),ndims(A),A}(Tracked{A}(c, Δ), x, Δ)\n\n# https://github.com/FluxML/Flux.jl/blob/master/src/tracker/Tracker.jl#L39\nTracked{T}(f::Call{Nothing}, grad::T) where T = new(0, f, true, grad)","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"可以看到，对于原始的数组类型，用param封装成TrackedArray之后，主要就是在外层套了一个nothing的f，并置为了叶子节点。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"(Image: the `param` function)","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"这里用一个例子来确认下：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"julia> w1 = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> w1_tracked = param(w1)\nTracked 2×2 Array{Float64,2}:\n 1.0  2.0\n 3.0  4.0\n\njulia> w1_tracked.data\n2×2 Array{Float64,2}:\n 1.0  2.0\n 3.0  4.0\n\njulia> w1_tracked.grad\n2×2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\njulia> w1_tracked.tracker.f\nFlux.Tracker.Call{Void,Tuple{}}(nothing, ())\n\njulia> w1_tracked.tracker.isleaf\ntrue","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"理解TrackedArray这个基础概念之后，接下来看看如何对TrackedArray做运算，毕竟在Flux的世界里，深度学习的网络就是靠TrackedArray构造的(其实还有TrackedReal等等)。在Flux的array.jl文件中，做了大量对TrackedArray的封装工作，目的主要有：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"将TrackedArray看作普通的AbstractArray，把系统对Array的一些操作绑定到data字段上\n重载一些基本的数组运算，通过track函数将对TrackedArray的运算结果封装成新的TrackedArray","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"粗略看一下array.jl便可发现，几乎所有的运算都靠track函数来实现转换：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"function track(f, xs...; kw...)\n  # 前向计算，得到结果y和反向求导函数back\n  y, back = _forward(f, xs...; kw...)\n  # 生成新的Tracked结构\n  track(Call(back, tracker.(xs)), y)\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"第一次看这个代码的时候一脸懵，因为全局搜索_forward你会发现，源代码中总共只出现了三处。但这不符合直觉啊，所有的TrackArray运算都会用到_forward函数，因此应该有很多重载函数才对。后来才发现，_forward函数是通过一个@grad宏定义的（这个宏稍稍有点复杂，核心是定义前向和反向求导的计算方式），在重载（或者定义）每个计算函数的时候，通过这个@grad宏同时把前向计算和梯度计算函数都定义了。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"macro grad(ex)\n  @capture(shortdef(ex), (name_(args__) = body_) |\n                         (name_(args__) where {T__} = body_)) || error(\"Need a function definition\")\n  T == nothing && (T = [])\n  isexpr(name, :(::)) || (name = :(::typeof($name)))\n  insert!(args, 1+isexpr(args[1], :parameters) , name)\n  @q(Tracker._forward($(args...)) where $(T...) = $body) |> esc\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"这里很骚气地用了MacroTools中的@capture宏，说白了，就是用来构造上面的_forward函数，看个例子就明白了","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"@grad a * b = data(a)*data(b), Δ -> (Δ*b, a*Δ)  # 返回两个元素，第一个是前向计算的结果，第二个是反向计算梯度的函数","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"于是，前向计算的问题基本解决了，同时反向计算需要的偏导函数也准备好了。为了支持除了built-in计算方式之外的一些常见的函数（比如Softmax, Relu等），Flux单独开发了一个库NNlib.jl。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/#反向传播","page":"详解Flux.jl","title":"反向传播","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"从代码逻辑上来讲，反向传播的实现很容易：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"从后往前计算偏导并更新TrackedArray的grad字段\n根据偏导更新weight","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"不过有些小细节需要处理：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"function back!(x, Δ)\n  istracked(x) || return\n  scan(x)\n  back(tracker(x), Δ)\n  return\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"这里，scan的目的是重置整个网络中的grad：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"function scan(x::Tracked)\n  x.isleaf && return\n  ref = x.ref += 1\n  if ref == 1\n    scan(x.f)\n    isdefined(x, :grad) && (x.grad = zero_grad!(x.grad))\n  end\n  return\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"可以看到，ref的作用是引用计数（这里先+=1，后面back执行的时候会-=1），反向传播的时候，会将多次计数的grad进行累加，直至计算完成后再真正执行back_:","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"function back(x::Tracked, Δ)\n  x.isleaf && (x.grad = accum!(x.grad, Δ); return)\n  ref = x.ref -= 1\n  if ref > 0 || isdefined(x, :grad)\n    if isdefined(x, :grad)\n      x.grad = accum!(x.grad, Δ)\n    else\n      x.grad = Δ\n    end\n    ref == 0 && back_(x.f, x.grad)\n  else\n    ref == 0 && back_(x.f, Δ)\n  end\n  return\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"而back_的逻辑就很简单了：","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"function back_(c::Call, Δ)\n  Δs = c.func(Δ)\n  (Δs isa Tuple && length(Δs) >= length(c.args)) ||\n    error(\"Gradient is not a tuple of length $(length(c.args))\")\n  foreach(back, c.args, data.(Δs))\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"计算偏导并迭代下去。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"接下来是update!","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"function update!(x, Δ)\n  x.data .+= data(Δ)\n  tracker(x).grad .= 0\n  return x\nend","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"可以看到，每次计算完会有一个置零的操作。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"对，如果手动更新的话，就这么简单了。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"不过大多时候，都有个Optimiser，如SGD,Adam等，来辅助更新梯度。Flux在这方面没有任何特殊之处，作者用一个Param结构来管理data和Δ。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"struct Param{T}\n  x::T\n  Δ::T\nen","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"然后，各个Optimizer管理自己的状态，~~主要是通过闭包实现的~~，最新版的不再使用闭包了，直接构造了struct。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/#layer","page":"详解Flux.jl","title":"layer","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"layer对一些常见的模块做了封装，如RNN和CNN等。写起来确实简单，不过，感觉需要有benchmark测试下性能。","category":"page"},{"location":"essays/An_Introduction_to_Flux.jl/#其它","page":"详解Flux.jl","title":"其它","text":"","category":"section"},{"location":"essays/An_Introduction_to_Flux.jl/","page":"详解Flux.jl","title":"详解Flux.jl","text":"剩下的主要就是一些工具函数了，比如treelike，onehot等。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/#如何在Julia中计算点积?","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"回字有几种写法? 🤔","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-11-19</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-11-19</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-11-16</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-11-16</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='54' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='54' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='35' height='20' fill='#0F80C1'/><rect width='54' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='355' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='250'>Julia</text><text x='355' y='140' transform='scale(.1)' textLength='250'>Julia</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='60' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='60' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='41' height='20' fill='#0F80C1'/><rect width='60' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='310'>CUDA</text><text x='385' y='140' transform='scale(.1)' textLength='310'>CUDA</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='52' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='52' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='33' height='20' fill='#0F80C1'/><rect width='52' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='345' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='230'>GPU</text><text x='345' y='140' transform='scale(.1)' textLength='230'>GPU</text></g></svg></div>","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"两个向量veca = a_1 a_2  a_n 和 vecb = b_1 b_2  b_n 之间点积（dot product)的代数定义如下：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"veca cdot vecb = sum^n_i=1 a_i b_i = a_1 b_1 + a_2 b_2 +  + a_n b_n","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"那么，如何在Julia中快速计算点积呢？","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/#版本1：-使用-LinearAlgebra-标准库中的-dot-函数","page":"如何在Julia中计算点积?","title":"版本1： 使用 LinearAlgebra 标准库中的 dot 函数","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using LinearAlgebra\n\njulia> N = 1024*1024\n1048576\n\njulia> x, y = rand(N), rand(N);\n\njulia> dot(x,y)\n262311.47579656926\n","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"先测试下标准库里 dot 的性能：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using BenchmarkTools\n\njulia> @benchmark dot($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  244.474 μs …  43.973 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     252.275 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   314.178 μs ± 884.297 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▇█▄▃▂▁▁▁▁▁▁▁ ▁▂                                               ▂\n  ████████████████▇▇▇▇▇█▇▇▇▇▇▇▇▇▆▆▅▆▇▇▅▃▅▅▄▃▄▄▃▃▄▃▅▇██▆▅▅▃▄▁▃▃▃ █\n  244 μs        Histogram: log(frequency) by time        594 μs <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"中间值位于252μs附近。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/#版本2：-for循环","page":"如何在Julia中计算点积?","title":"版本2： for循环","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"当然，即使不使用自带的dot函数，我们也可以很方便地用一个 for 循环来实现：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot2_1(x, y)\n    res = 0\n    for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"写法基本和原始的数学表达式一样，那性能如何呢？","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_1($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 2134 samples with 1 evaluation.\n Range (min … max):  2.286 ms …  2.942 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     2.302 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   2.330 ms ± 56.418 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  █ █                                                         \n  █▃█▇▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▂▁▁▁▁▂▂▂▂▂▁▂ ▃\n  2.29 ms        Histogram: frequency by time         2.6 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"呃， 耗时差不多是原来的9倍了。有点不可思议，那怎么优化下呢？ 先用 @code_warntype 看下：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"(Image: )","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"注意到上面标红色的部分，这是提醒我们上面的实现中出现了类型不稳定的情况。主要原因是res在dot2_1函数中，初始化成了Int64类型的0，而我们的输入是两个Vector{Float64}类型的向量。了解这一点之后，可以把上面的实现写得更灵活一些：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot2_2(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里， 通过 promote_type 获取类型信息。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_2($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 3384 samples with 1 evaluation.\n Range (min … max):  1.410 ms …  3.580 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     1.449 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.464 ms ± 66.969 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n         ▆ ▃█ ▄                                               \n  ▂▃▃▃▅█▆██████▇▅█▄▄▄▄▄▄▄▃▄▄▄▃▄▄▄▄▄▃▃▄▃▃▃▂▃▃▃▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂ ▃\n  1.41 ms        Histogram: frequency by time        1.59 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到，比之前稍好了一些，大约是之前的5倍左右。 当然，我们还可以顺手做些进一步的优化，加上@simd并去掉边界检查：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot2_3(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    @inbounds @simd for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_3($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 5545 samples with 1 evaluation.\n Range (min … max):  848.684 μs …  1.296 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     871.641 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   888.964 μs ± 50.935 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▂▇█▇▆▇▆▅▅▅▄▄▃▃▃▂▂▁▂▁▁▁                                       ▂\n  ███████████████████████▇▇▇▇▇▆▆▅▅▆▆▇█▇▇████▇█▇▅▇▇▅▅▅▄▄▅▅▅▅▅▄▃ █\n  849 μs        Histogram: log(frequency) by time      1.11 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这样差距进一步缩小了一些。当然，我们还可以进一步利用 LoopVectorization.jl 这个库来提速：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"using LoopVectorization\nfunction dot2_4(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    @turbo for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot2_4($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 5905 samples with 1 evaluation.\n Range (min … max):  802.618 μs …  1.211 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     820.607 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   832.880 μs ± 39.868 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n   ▂█▄                                                          \n  ▂███▆▆▇▅▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂\n  803 μs          Histogram: frequency by time         1.02 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"看起来稍微快了一些，不过似乎仍然与LinearAlgebra中的性能有3倍多的性能差距？其实不然，LinearAlgebra中使用了BLAS，而其默认是有多线程加速的，为了公平比较，可以将其线程数设置为1，然后对比：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> LinearAlgebra.BLAS.set_num_threads(1)\n\njulia> @benchmark dot($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 5980 samples with 1 evaluation.\n Range (min … max):  795.374 μs …  1.104 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     811.659 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   823.303 μs ± 37.397 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n   ▅█                                                           \n  ▃███▅▇▇▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃\n  795 μs          Histogram: frequency by time         1.02 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到，二者相差无几。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/#版本3：-一行代码","page":"如何在Julia中计算点积?","title":"版本3： 一行代码","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"当然，有的时候其实对性能也不是那么关心，反而代码的简洁性更重要，那么也可以简单地用一行代码来搞定：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark sum(a*b for (a,b) in zip($(rand(N)),$(rand(N))))\nBenchmarkTools.Trial: 3823 samples with 1 evaluation.\n Range (min … max):  1.232 ms …  1.840 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     1.281 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.295 ms ± 54.505 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n   ▃█▇▄▆▂                                                     \n  ▃███████▆▇▄▄▄▅▅▄▅▄▅▆▆▆▅▅▆▇▆▆▆▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁ ▃\n  1.23 ms        Histogram: frequency by time        1.46 ms <\n\n Memory estimate: 0 bytes, allocs estimate: 0.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"或者，直接用 mapreduce:","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"mapreduce(*, +, x, y)","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/#版本4：-多线程","page":"如何在Julia中计算点积?","title":"版本4： 多线程","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"受前面LinearAlgebra中多线程的启发，我们同样也可以用Julia自带的多线程完成点积的计算。不过需要记得在启动Julia的时候，通过 -t auto 来指定线程数。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using Base.Threads\n\njulia> nthreads()\n4","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里我本机就4个线程。所以","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot4_1(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zero(promote_type(X,Y))\n    @threads for i in eachindex(x, y)\n        res += x[i] * y[i]\n    end\n    res\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot4_1($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 109 samples with 1 evaluation.\n Range (min … max):  28.586 ms … 113.851 ms  ┊ GC (min … max):  0.00% … 62.77%\n Time  (median):     39.838 ms               ┊ GC (median):     0.00%\n Time  (mean ± σ):   45.888 ms ±  20.565 ms  ┊ GC (mean ± σ):  14.59% ± 19.04%\n\n   ▁      █▃                                                    \n  ▇█▄█▆▁▁▇██▆▇▄▄▄▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▄▁█▇▄ ▄\n  28.6 ms       Histogram: log(frequency) by time       108 ms <\n\n Memory estimate: 32.00 MiB, allocs estimate: 2097174.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这个结果就比较有意思了，由于我们的多线程实现存在race condition, 实际上得到的结果并不对，并且速度相当慢。当然，为了保证结果的正确性，可以对res加锁，但并不能带来性能上的提升。一个简单的办法是，将数据分片，每个线程做自己单独的计算，最后把多个线程的结果合并：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot4_2(x::AbstractArray{X}, y::AbstractArray{Y}) where {X,Y}\n    res = zeros(promote_type(X,Y), nthreads())\n    @threads for i in 1:length(x)\n        @inbounds res[threadid()] += x[i] * y[i]\n    end\n    sum(res)\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark dot4_2($(rand(N)), $(rand(N)))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  378.194 μs …  16.460 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     397.990 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   433.403 μs ± 243.825 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▅█▆▆▆▄▂▁ ▁▁      ▁▂▂▁ ▂▃▃▂▁                                   ▂\n  ██████████████▇▇███████████▇▅▆▅▅▇▅▁▃▁▃▃▁▄▁▃▁▁▅▇▄▅▃▃▄▅▄▁▄▄▆▅▄▅ █\n  378 μs        Histogram: log(frequency) by time        878 μs <\n\n Memory estimate: 1.98 KiB, allocs estimate: 22.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这样得到的结果，相比单线程的结果要快了近3.2倍。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"Julia标准库里没有提供多线程的求和操作，不过有一些第三方库提供了这类基本操作，比如ThreadsX.jl。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using ThreadsX\n\njulia> @benchmark ThreadsX.sum(a*b for (a,b) in zip($(rand(N)),$(rand(N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  291.519 μs …  2.023 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     326.248 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   339.611 μs ± 42.828 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n        ▃▆█▆▄▂▁                                                 \n  ▁▂▃▅▆█████████▆▆▆▆▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▃\n  292 μs          Histogram: frequency by time          472 μs <\n\n Memory estimate: 17.45 KiB, allocs estimate: 249.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/#版本5：-GPU版","page":"如何在Julia中计算点积?","title":"版本5： GPU版","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"如果你手上正好有块GPU，不妨试试看在GPU上做点积。Julia中的CUDA.jl极大地方便了Julia语言里的GPU编程，针对点积这样的常见操作，其提供了基于cuBLAS的封装，下面来试下：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> using CUDA\n\njulia> @benchmark CUDA.@sync dot($(cu(rand(N))), $(cu(rand(N)))) \nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  26.521 μs … 68.923 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     27.798 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   28.331 μs ±  1.494 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▂▁   ▃▇█▅▁ ▃▅▇▅▂   ▂▃                                       ▂\n  ███▆▇████████████▇████▆▄▄▅▆▆▅▅▅▅▅▅▅▆▆▆▆▅▆▄▅▆▅▄▅▅▂▅▄▄▅▅▄▄▃▅▄ █\n  26.5 μs      Histogram: log(frequency) by time      35.9 μs <\n\n Memory estimate: 16 bytes, allocs estimate: 1.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到，其速度相当快。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"不过，由于cuBLAS里的dot只针对常见的 Float32, Float64, Float16 以及对应的复数类型的GPU上的向量有实现，当输入的两个向量的元素类型不一致时，目前的CUDA.jl(v3.5.0)会fallback到CPU版本的实现，导致性能极慢：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> z = rand(Bool, N);\n\njulia> cx, cz = cu(x), cu(z);\n\njulia> @time dot(cx, cz)\n┌ Warning: Performing scalar indexing on task Task (runnable) @0x00007f63cc0c0010.\n│ Invocation of getindex resulted in scalar indexing of a GPU array.\n│ This is typically caused by calling an iterating implementation of a method.\n│ Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n│ and therefore are only permitted from the REPL for prototyping purposes.\n│ If you did intend to index this array, annotate the caller with @allowscalar.\n└ @ GPUArrays ~/.julia/packages/GPUArrays/3sW6s/src/host/indexing.jl:56\n 12.914170 seconds (6.29 M allocations: 1.000 GiB, 0.87% gc time)","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"一个简单的workaround是，先把类型不同的两个向量转换成相同的类型，然后再调用dot函数：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark CUDA.@sync dot($(cu(rand(N))), convert(CuArray{Float32}, $(cu(rand(Bool, N)))))\nBenchmarkTools.Trial: 3968 samples with 1 evaluation.\n Range (min … max):  1.073 ms …   4.408 ms  ┊ GC (min … max): 0.00% … 30.06%\n Time  (median):     1.140 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.252 ms ± 464.709 μs  ┊ GC (mean ± σ):  3.35% ±  6.05%\n\n  ▂█▃  ▄▁                                     ▁                \n  ███▇▆██▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄█▅▃▁▃▁▁▁▃▁▃▁▁▁█ █\n  1.07 ms      Histogram: log(frequency) by time      3.85 ms <\n\n Memory estimate: 5.00 MiB, allocs estimate: 12.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"相比原来的GPU版本，多出来了一次拷贝数据的时间，这显然不是我们想要的。 不过，CUDA.jl的强大之处在于，针对这类没有内置的实现，我们可以很容易地通过编写自定义的核函数来实现。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_1(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res)\n        for i in 1:length(x)\n            @inbounds res[] += x[i] * y[i]\n        end\n    end\n    @cuda kernel(x, y, res)\n    res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"自己手写核函数经常容易出现各种bug，所以首要任务是先确认我们计算的结果是正确的：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot5_1(cx, cz), dot(cx, convert(CuArray{Float32}, cz)))\ntrue","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"注意这里用的是isapprox来做比较。看起来我们得到的结果是正确的，那么其性能如何呢？","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark CUDA.@sync dot5_1($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 103 samples with 1 evaluation.\n Range (min … max):  48.510 ms …  54.895 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     48.514 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   48.606 ms ± 657.494 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  █▁                                                            \n  ███▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄ ▄\n  48.5 ms       Histogram: log(frequency) by time      50.6 ms <\n\n Memory estimate: 1.78 KiB, allocs estimate: 29.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"呃，还不如先convert了再调用自带的dot函数...... 那问题出在哪呢？其实上面的核函数只用了一个线程在计算，但是在GPU上有大量的线程可供计算，于是，可以采用上面的CPU上多线程的方法来计算：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_2(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res)\n        index = threadIdx().x\n        stride = blockDim().x\n        for i in index:stride:length(x)\n            @inbounds res[] += x[i] * y[i]\n        end\n    end\n    k = @cuda launch=false kernel(x, y, res)\n    config = launch_configuration(k.fun)\n    k(x, y, res; threads=min(length(x), config.threads))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里在运行核函数的时候，指定了threads的个数，在核函数内部的for循环把数据根据threads切分成了不同的片段，每个thread负责计算各自的一部分。 先验证下正确性：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot5_2(cx, cz), dot(cx, convert(CuArray{Float32}, cz)))\nfalse","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"等等，这里似乎犯了和前面多线程计算时候一样的错误，在往res里累积求和的时候，会存在静态条件。仔细观察可以发现，我们不用每次都往res里写入结果，只需要在每个线程内部先计算完，最后叠加上去即可，同时最后要加锁。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_3(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        stride = blockDim().x\n        s = zero(T)\n        for i in index:stride:length(x)\n            @inbounds s += x[i] * y[i]\n        end\n        CUDA.@atomic res[] += s\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun)\n    k(x, y, res, T; threads=min(length(x), config.threads))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这里用了CUDA.@atomic来保证原子操作，同样，先确认计算的正确性：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_3(cx, cz))\ntrue","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"再看下速度如何：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> @benchmark CUDA.@sync dot5_3($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  175.298 μs … 448.774 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     178.373 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   179.218 μs ±   4.301 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n    ▁▃▅▅▇█████▇▇▇▇▇▆▆▅▅▄▄▃▂▂▁▁▁▁ ▁   ▁▁▁▁▁ ▁▁▁▁▁▁▁              ▃\n  ▅▅██████████████████████████████████████████████▇██▇▇▆▇▆▅▅▇▅▆ █\n  175 μs        Histogram: log(frequency) by time        191 μs <\n\n Memory estimate: 2.16 KiB, allocs estimate: 39.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"还不错，至少比CPU版本快了，但是离CUBLAS版本的性能还有一定差距。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"考虑到一块GPU中，还会有多个block，而上面我们才用了其中的一个block，显然还有很大的优化空间！","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"一个基本思路是，根据输入的数据，分配多个block，在每个block的数据区块中，按thread再切分一次，每个thread计算自己所属的数据的点积之和。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_4(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        thread_stride = blockDim().x\n        block_stride = (length(x)-1) ÷ gridDim().x + 1\n        start = (blockIdx().x - 1) * block_stride + 1\n        stop = blockIdx().x * block_stride\n\n        s = zero(T)\n        for i in start-1+index:thread_stride:stop\n            @inbounds s += x[i] * y[i]\n        end\n        CUDA.@atomic res[] += s\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun)\n    k(x, y, res, T; threads=min(length(x), config.threads), blocks=config.blocks)\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_4(cx, cz))\ntrue\n\njulia> @benchmark CUDA.@sync dot5_4($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  134.011 μs … 383.172 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     134.933 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   135.095 μs ±   2.723 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n       ▁▃▄▇▇▇▆████▇▆▃▃▁                                          \n  ▂▂▃▅▆█████████████████▆▅▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂ ▄\n  134 μs           Histogram: frequency by time          138 μs <\n\n Memory estimate: 2.16 KiB, allocs estimate: 39.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"OK, 看起来稍微快了一些。需要注意的是，前面我们直接将每个thread计算的结果往一个res对象中通过加锁叠加上去了，这样导致每个block中每个thread都会卡在原子操作那一步。 一种优化方式是每个block的内部，先把各个thread的计算结果缓存起来，等一个block内所有thread都计算出来了同步一下，然后内部先reduce，最后再通过原子操作同步到最终的结果上。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"function dot5_5(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        thread_stride = blockDim().x\n        block_stride = (length(x)-1) ÷ gridDim().x + 1\n        start = (blockIdx().x - 1) * block_stride + 1\n        stop = blockIdx().x * block_stride\n\n        cache = CuDynamicSharedArray(T, (thread_stride,))\n\n        for i in start-1+index:thread_stride:stop\n            @inbounds cache[index] += x[i] * y[i]\n        end\n\n        sync_threads()\n\n        if index == 1\n            s = zero(T)\n            for i in 1:thread_stride\n                s += cache[i]\n            end\n            CUDA.@atomic res[] += s\n        end\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun; shmem=(threads) -> threads*sizeof(T))\n    threads = min(length(x), config.threads)\n    blocks = config.blocks\n    k(x, y, res, T; threads=threads, blocks=config.blocks, shmem=threads*sizeof(T))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_5(cx, cz))\ntrue\n\njulia> @benchmark CUDA.@sync dot5_5($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  54.364 μs … 358.597 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     55.217 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   55.559 μs ±   4.023 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n     ▄▇█▇▅▃▂                                                    \n  ▂▄█████████▇▇▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂ ▃\n  54.4 μs         Histogram: frequency by time         61.3 μs <\n\n Memory estimate: 2.33 KiB, allocs estimate: 43.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"可以看到,其性能跟CUBLAS比较接近了。当然，上面的代码还可以进一步优化，上面最后reduce的时候，只有index为1的线程在运行，其实可以多个线程一起工作：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"using CUDA:i32\n\nfunction dot5_6(x::CuArray{T1}, y::CuArray{T2}) where {T1, T2}\n    T = promote_type(T1, T2)\n    res = CuArray{T}([zero(T)])\n    function kernel(x, y, res, T)\n        index = threadIdx().x\n        thread_stride = blockDim().x\n        block_stride = (length(x)-1i32) ÷ gridDim().x + 1i32\n        start = (blockIdx().x - 1i32) * block_stride + 1i32\n        stop = blockIdx().x * block_stride\n\n        cache = CuDynamicSharedArray(T, (thread_stride,))\n\n        for i in start-1i32+index:thread_stride:stop\n            @inbounds cache[index] += x[i] * y[i]\n        end\n        sync_threads()\n\n        mid = thread_stride\n        while true\n            mid = (mid - 1i32) ÷ 2i32 + 1i32\n            if index <= mid\n                @inbounds cache[index] += cache[index+mid]\n            end\n            sync_threads()\n            mid == 1i32 && break\n        end\n\n        if index == 1i32\n            CUDA.@atomic res[] += cache[1]\n        end\n        return nothing\n    end\n    k = @cuda launch=false kernel(x, y, res,T)\n    config = launch_configuration(k.fun; shmem=(threads) -> threads*sizeof(T))\n    threads = min(length(x), config.threads)\n    blocks = config.blocks\n    k(x, y, res, T; threads=threads, blocks=config.blocks, shmem=threads*sizeof(T))\n    CUDA.@allowscalar res[]\nend","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"julia> isapprox(dot(cx, cz), dot5_6(cx, cz))\ntrue\n\njulia> @benchmark CUDA.@sync dot5_6($(cu(rand(N))), $(cu(rand(Bool, N))))\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  22.520 μs … 375.954 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     23.475 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   23.762 μs ±   3.748 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n        ▁▅██▆▃▁                                                 \n  ▂▂▃▃▄▆███████▇▅▄▅▅▅▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂ ▃\n  22.5 μs         Histogram: frequency by time           28 μs <\n\n Memory estimate: 2.16 KiB, allocs estimate: 39.","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"这样，最终的结果跟CUBLAS的性能基本一致了。","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"从代码层面上讲，上面的代码还可以进一步简化下，上面的while循环其实是一个经典的reduce操作，而CUDA.jl中内置了一个函数reduce_block来简化该操作，下面是简化后的核函数写法：","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"忘了说了，如果你还是one-line solution的爱好者，其实之前的CPU版本的写法在GPU上同样work哦~","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"mapreduce((x,y)->dot(x, y), +, x, y)","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/#参考","page":"如何在Julia中计算点积?","title":"参考","text":"","category":"section"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"Introduction to CUDA.jl\nGTC-2010\nCUDA.jl#1240","category":"page"},{"location":"programming/Dot_Product_in_Julia/index.zh/","page":"如何在Julia中计算点积?","title":"如何在Julia中计算点积?","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"keywords: Julia,Concurrency CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/#用Julia实现读写锁","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"","category":"section"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"本文受Implementing reader-writer locks一文启发，采用Julia实现读写锁（原文用的是Golang）。","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/#为何需要读写锁","page":"用Julia实现读写锁","title":"为何需要读写锁","text":"","category":"section"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"在多线程编程过程中，对于一些关键资源，需要对其加锁，以保证同一时刻只有一个线程在操作数据。不过在某些场景下，加锁带来的代价会比较大。如果只有一个互斥锁，那么当读取操作的次数远大于写入操作的次数时，由于每次读取都会对数据加锁，必然带来额外的开销。显然，如果多次读取操作之间没有写入操作，那么这段时间内其实时不需要对数据加锁的，于是乎，便有了读写锁专门用于提升此类场景下锁的效率。","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"接下来，我们将一步步实现高效的读写锁。","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/#MutexAsRWLock","page":"用Julia实现读写锁","title":"MutexAsRWLock","text":"","category":"section"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"先假设只有一把锁，看看其效率如何：","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"struct MutexAsRWLock\n    m::Threads.Mutex\n    MutexAsRWLock() = new(Threads.Mutex())\nend\n\nread_lock(l::MutexAsRWLock) = lock(l.m)\nread_unlock(l::MutexAsRWLock) = unlock(l.m)\nwrite_lock(l::MutexAsRWLock) = lock(l.m)\nwrite_unlock(l::MutexAsRWLock) = unlock(l.m)","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"然后用原文中提到的测试方法，测试下这种情况下，read_lock和write_lock获取锁的时间：","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"julia> batch_test_rwlock(rwl, 1000, 10)\n(2.0248251801001482e-8, 1.9721886599999977e-8)","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/#ReaderCountRWLock","page":"用Julia实现读写锁","title":"ReaderCountRWLock","text":"","category":"section"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"接下来将其换成一种最简单的实现：读写锁共用一个互斥锁，不过，获取写锁时，如果当前已经有了读锁（count大于1），那么就将其释放掉，然后循环下去：","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"mutable struct ReaderCountRWLock\n    m::Threads.Mutex\n    reader_count::Int\n    ReaderCountRWLock() = new(Threads.Mutex(), 0)\nend\n\nfunction read_lock(l::ReaderCountRWLock)\n    lock(l.m) do\n    l.reader_count += 1\n    end\nend\n\nfunction read_unlock(l::ReaderCountRWLock)\n    lock(l.m) do\n        l.reader_count -= 1\n        if l.reader_count < 0\n            error(\"reader count negative\")\n        end\n    end\nend\n\nfunction write_lock(l::ReaderCountRWLock)\n    while true\n        lock(l.m)\n        if l.reader_count > 0\n            unlock(l.m)\n        else\n            break\n        end\n    end\nend\n\nfunction write_unlock(l::ReaderCountRWLock)\n    unlock(l.m)\nend","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"julia> batch_test_rwlock(rwl, 1000, 10)\n(1.2749199800001581e-10, 4.536146970000002e-8)","category":"page"},{"location":"essays/Implementing_Readers_Writer_Lock_in_Julia/","page":"用Julia实现读写锁","title":"用Julia实现读写锁","text":"可以看到，读锁的时间大大降低了，但是写入锁的时间稍稍增加了一些。","category":"page"},{"location":"blogroll/#Blogroll","page":"🔗 Blogroll","title":"🔗 Blogroll","text":"","category":"section"},{"location":"blogroll/","page":"🔗 Blogroll","title":"🔗 Blogroll","text":"Following are some interesting sites I'd like to share with you. Feel free to add yours here by clicking the Edit on Github link on the top right corner of this page.","category":"page"},{"location":"blogroll/#[laike9m](https://laike9m.com/)-(En/Zh)","page":"🔗 Blogroll","title":"laike9m (En/Zh)","text":"","category":"section"},{"location":"blogroll/#[Roger-Luo](https://rogerluo.dev/)-(En)","page":"🔗 Blogroll","title":"Roger Luo (En)","text":"","category":"section"},{"location":"blogroll/#[Ronnie-Wang](http://wattlebird.github.io/)-(Zh)","page":"🔗 Blogroll","title":"Ronnie Wang (Zh)","text":"","category":"section"},{"location":"blogroll/#[Hongxu-Xu](https://xuhongxu.com)-(Zh)","page":"🔗 Blogroll","title":"Hongxu Xu (Zh)","text":"","category":"section"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"keywords: AI CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/#人工智能简介","page":"人工智能简介","title":"人工智能简介","text":"","category":"section"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"本文是从我自己的角度出发，向小朋友们简要介绍什么是人工智能。","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"5次讲座","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"机器人的前世今生","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"本系列课程通过带领大家探讨什么是机器人这个话题，介绍历史上的“机器人”、机器人发展现状、现代机器人技术、机器人未来趋势","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"1.1 机器人历史","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"1.2机器人现状 1.3机器人现状及未来","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"总结机器人发展趋势","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"走进人工智能","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"本系列课程将带领大家了解人工智能的概念与历程，理解当前人工智能领域所面临的机遇与挑战，并借助一些生动形象的例子，让大家理解人工智能领域最基本的算法，梳理当前的研究热点，为学习后面的课程打下坚实的基础。","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"2.1 搜索的艺术","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"首先介绍人工智能领域所面临的一些经典问题，以及如何通过搜索的方式来解决，最后从搜索的角度揭示当前的热门研究问题。","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"经典的搜索算法（DFS, BFS,HF…）以及对应的经典例子（以棋类游戏为例）\n高级搜索算法（动态搜索，近似搜索，优先条件搜索等……）\nAlphaZero是如何做搜索的？除了游戏之外，还有哪些更复杂的问题呢？由此引出下一讲的学习策略。","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"2.2 学习与推理","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"当我们谈论人工智能时，谈到最多的一点就是人工智能的学习与推理能力，那么具体是怎么学习，又是如何做推理的呢？","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"什么是知识和模型？\n知识从哪来？\n模型如何构建？\n机器怎么做推理？","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"2.3 决策与行动","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"有了这些强大的算法之后，如何利用它们为我们的生活提供便利的服务呢？我们将从以下几个场景展开，介绍人工智能是如何影响着我们生活的方方面面的：","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"语音机器人\n个性化推荐\n自动驾驶","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"大数据","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"3.1 The secret of mining massive datasets   通过多个案例介绍，向大家说明大数据是什么、有什么用，数据挖掘是什么、有什么用，以及数据挖掘与人工智能的关系 3.2 The tasks of data mining   通过前述一个或多个案例，给大家介绍数据挖掘的任务和内容，并以通俗易懂的方式讲述各个任务，包括分类、聚类、回归、时序数据分析、异常点监测等 3.3 The procedure of how to execute data mining   通过挑选前述案例中的一个或两个任务，来具体讲述下数据挖掘的实施过程与实施步骤，包括问题定义、数据准备、数据预处理、数据挖掘算法执行、结果解释与评估等步骤","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"计算机视觉","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"4.1 给计算机安上眼睛 Basic Concepts   从介绍视觉入手，引入计算机视觉，介绍计算机视觉的基本概念，历史，领域和前沿效果。","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"什么是视觉？What is Vision? What is Computer Vision? Why we need Computer Vision? What is the relationship between Computer Vision and Artificial Intelligence?\nBrief history of Computer Vision.\nWhat can Computer Vision helps us do? Research Areas of Computer Vision.\nCutting edges of Computer Vision.","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"4.2 传统方法与深度学习的比较 Traditional CV VS Deep Learning Way   介绍并比较传统的计算机视觉方法和深度学习方法的异同，了解计算机视觉算法的一般流程，明白特征提取和分类的概念","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"What is the world looks like in the eyes of computers. Something need to know about images.\nCommon pipeline of dealing with a Computer Vision Issue\nUsing detection as an example\nFeature Space and Feature extraction\nClassification","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"4.3 练就计算机的火眼金睛 Make difference as an AI expert   介绍如何在计算机视觉中的应用神经网络，了解神经网络的基本概念","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"What is Neural Network, compared with neuron, and its brief history.\nCNN and use CNN to extract feature.\nHow does computer learn? i.e. How to train a neural network.\nUsing Detection as an example","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"自然语言处理","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"5.1 自然语言理解简介/走进自然语言的世界/自然语言知多少   自然语言理解是计算机科学领域与人工智能领域中的一个重要方向，它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。本讲座从概要、应用、任务、挑战四个方面较为系统地带您走进自然语言的世界。通过本次讲座，您将对人工智能和自然语言有初步认识。","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"自然语言理解是什么\n自然语言应用举例\n自然语言任务简介","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"5.2 自然语言理解的方法/如何让计算机理解人类语言","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"简介: \n自然语言理解中的经典方法\n神经网络与自然语言理解\n自然语言理解的趋势","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"5.3 对话机器人/与机器人聊天/对话机器人的前世今生/从自然语言理解到问答机器人","category":"page"},{"location":"essays/A_Short_Introduction_to_AI_for_children/","page":"人工智能简介","title":"人工智能简介","text":"简介\n什么是对话机器人\n对话机器人框架\n对话机器人应用","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"keywords: Kaggle,Competition CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/#Data-Science-London-Scikit-learn","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"","category":"section"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"先感受一下这40维特征的分布情况： (Image: original feature distribution)","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"从这个图可以得到几个信息，一是特征都分布在０附近，特征之间没有很大的差异性，比较均衡；二是每一维特征的盒子分布的长度大概是１：３，有点接近高斯分布。事实上，针对每一维画一个直方图（其实这里画KDE的图更合适）可以粗略看出其分布情况：","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"(Image: feature distribution example)","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"上图中蓝绿色分别表示label分别为0，1对应到第５维特征时候的特征分布。 图１是把label为0和1的所有训练集同时表示在了一张图上，那么将二者分开来看看呢？","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"(Image: Box Distribution)","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"这样稍微可以看出点差别了，比较明显的是，有几维特征（比如第5，13维）在左右两边的分布出现明显的偏差。因此，可以断定，对于该数据集而言，少量的特征占有主要地位，而其他大多数特征只有较低的权重。当然，这样不够精确，下面对其量化下。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"分别尝试用相关性衡量，逻辑回归，Lasso, svc，以及决策树模型，对初始特征的权值进行衡量，min-max归一化后的图如下","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"(Image: Feature Weights in Different Models)","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"可以看到，权值较大的特征大概是15维左右。下图是根据pca得到的特征权重。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"(Image: PCA top 15)","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"对特征了解了这么多，就来指定分类方法啦～","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"首先根据tutorial试下水，用svm对40维特征做训练，采用rbf核，５折交叉验证的结果是0.922，可以看到，svm对于这类有着强特征的数据表现不错。为了进一步提升，结合前面的分析可知，首先可以做的是对原始数据降噪。很容易想到的就是主成分分析。这里做pca降维的时候，需要结合训练集和测试集（主要是因为训练集才1000而测试集有9000，因此需要引入测试集对训练集进行强化）。同样采用5折交叉验证，当pca降维到12，13维附近的时候，最好能达到0.95左右(线上测试结果大概0.945附近)。实际上，降维的程度直接影响该结果。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"那么，到此为止，似乎就遇到瓶颈了。提取主成分，分类，一气呵成。从前面两步可以看出，提升的关键在于对数据的清理，那么，能不能在此基础上继续往前探索呢？我们知道主成分分析有其局限性，那么还有哪些其他改进的办法呢？沿着这个思路，尝试采用sparse filtering 对该降维的过程做出改进。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"直觉告诉我们，先用pca降维的维数作为基础，对原有的数据做sparse-filtering，同样５折交叉验证大概是0.928左右，可见跟使用原始的svm差别不大，修改sparse-filtering使用的维度，遍历之后如下图所示：","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"(Image: Sparse Filtering)","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"我们知道，sparse-filtering与pca降维的显著差异之一是，pca降维只找主要关系，而SF则是找特征之间的内在组合关系。（后面可以利用该特性进一步提升），从图中可以看出，采用SF的最好效果要略优于pca降维后的效果，可以达到0.955附近，但是实际线上测试不过0.94。这说明存在一定的过拟合现象，个人感觉，最主要的原因时后面的svm层过度调参所致。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"可以尝试换成逻辑回归层作为分类试试。遗憾的是LR并不能达到svm那样的效果（主要是缺少核函数的映射过程，尝试的结果可想而知）。另外，感觉采用auto-encoder后可能效果要比sf要稍好一些，等熟悉了pylearn2后可以尝试下。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"SF的效果带给人的启发之一是，原来40维特征，通过SF处理后，可以得到和pca降维后近似的结果，但是维度的变化范围比较广(20~50)。也就是说，我们的目的并不是降维，降维只是手段之一，我们的目的是提取有用的信息。理解这一点后就好说了。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"回顾上面所做的，实际上就是一个简单的3层网络结构。似乎，稀疏表示之后再分类的最好的效果止步于0.95。由于训练集数据较少，大量的数据是未标记的。那么，一个很单纯的想法就是，将测试集的预测结果中准确度极高的部分并入训练集，扩充训练集样本，强化训练。论坛里已经有人这么尝试过，似乎，没有太大提升。我估计，主要原因是，从测试集中提取到的概率值极高的那部分数据实际上是远离svm边界的数据，这部分数据加入到训练集中，对于区分那些边界附近的点意义不大。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"整理下思路，现在的瓶颈似乎是在svm上，那些边界点难以分隔。因此，可以尝试加入一些弱分类器，另外适当调整参数C。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"先用决策树试一下。本地测试0.8。换随机森林，先将训练集二八分，80%为train_set,20%为val_set，然后用40课树训练train_set，分别预测train_set,val_set，得到40维的概率值，分别记为rf_train_set,rf_val_set。再用svm训练这个rf_train_set，用得到的最佳参数去预测rf_val_set。结果是，该模型对rf_train_set的结果能达到100%，但是对rf_val_set仅仅只有84%左右。看来rf的预测值只能用来打辅助。分析其原因，一方面数据量太少，过拟合无疑。另外随机森林的数量和深度也需要适当限制，否则如果单颗树就陷入过拟合，其效果必然不好。","category":"page"},{"location":"essays/Data_Science_London_Scikit-Learn/","page":"Data Science London + Scikit-learn","title":"Data Science London + Scikit-learn","text":"最后再尝试下融合。只简单试了一下特征融合，没做太多参数上的调优，但是小有提升，线上接近0.96。仔细想了想，尝试只能到此为止了。然后去论坛里找了找大家的解决方案，思路很新颖。通过分析数据的分布得出结论数据是造的。于是乎，对症下药，针对该数据的分布情况，采用GMM估计出原始分布的参数，再用简单分类器以GMM的结果为特征再次分类。我用svm复现了下该方法，确实很厉害，接近0.99。最后拿第一的那位也是融合了下rf的结果后做到的。","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"keywords: Survey,RelationExtraction CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/RelationExtraction/#Relation-Extraction","page":"Relation Extraction","title":"Relation Extraction","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"By Jun Tian","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Slides/Papers/Data are removed. (2021-08-12)","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"2018-03-21","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"The task of relation extraction(RE) is to extract links between pairs of nominals.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Given a sentence S with annotated pairs of nominals e_1 and e_2, we aim to identify the relations between e_1 and e_2.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Typical relation types include birthdate(PER, DATE), and founder-of(PER, ORG), with examples for relations being birthdate(John Smith, 1985-01-01) or founder-of(Bill Gates, Microsoft).","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"(Image: TypicalRelationExtractionPipeline.png)","category":"page"},{"location":"essays/RelationExtraction/#Survey","page":"Relation Extraction","title":"Survey","text":"","category":"section"},{"location":"essays/RelationExtraction/#Papers","page":"Relation Extraction","title":"Papers","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐⭐[Pawar, Sachin, Girish K. Palshikar, and Pushpak Bhattacharyya. \"Relation Extraction: A Survey.\" arXiv preprint arXiv:1712.05191 (2017).][]\n⭐⭐⭐[Maynard, Diana, Kalina Bontcheva, and Isabelle Augenstein. \"Natural language processing for the semantic web.\" Synthesis Lectures on the Semantic Web: Theory and Technology 6.2 (2016): 1-194.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Chapter 4. Relation Extraction.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐[Li, Juanzi, et al. \"Knowledge Graph and Semantic Computing.\"][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"P50. A Survey on Relation Extraction","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Kumar, Shantanu. \"A Survey of Deep Learning Methods for Relation Extraction.\" arXiv preprint arXiv:1705.03645 (2017).][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Mostly are CNN","category":"page"},{"location":"essays/RelationExtraction/#Slides","page":"Relation Extraction","title":"Slides","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐⭐Learning Semantic Relations from Text 2015 EMNLP\nRelation Extraction 2013\nA-survey-on-Relation-Extraction-Slides.pdf","category":"page"},{"location":"essays/RelationExtraction/#Approaches","page":"Relation Extraction","title":"Approaches","text":"","category":"section"},{"location":"essays/RelationExtraction/#Bootstrapping-Methods","page":"Relation Extraction","title":"Bootstrapping Methods","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐[Brin, Sergey. \"Extracting patterns and relations from the world wide web.\" International Workshop on The World Wide Web and Databases. Springer, Berlin, Heidelberg, 1998.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"(Image: DIPRE.png)","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Etzioni, Oren, et al. \"Web-scale information extraction in knowitall:(preliminary results).\" Proceedings of the 13th international conference on World Wide Web. ACM, 2004.][]\n⭐[Carlson, Andrew, et al. \"Toward an architecture for never-ending language learning.\" AAAI. Vol. 5. 2010.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"(Image: NELL.png)","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Pedro, Saulo DS, and Estevam R. Hruschka. \"Conversing learning: Active learning and active social interaction for human supervision in never-ending learning systems.\" Ibero-American Conference on Artificial Intelligence. Springer, Berlin, Heidelberg, 2012.][]","category":"page"},{"location":"essays/RelationExtraction/#Rule-Based-Approaches","page":"Relation Extraction","title":"Rule Based Approaches","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"There are two different types of rule-based approaches:","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Those which are stand-alone (poor recall, unable to generalize to unseen patterns).\nThose which learn rules for inference to complement other relation extraction approaches.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Soderland, Stephen G. Learning text analysis rules for domain-specific natural language processing. Diss. University of Massachusetts at Amherst, 1997.][]\n[Reiss, Frederick, et al. \"An algebraic approach to rule-based information extraction.\" Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on. IEEE, 2008.][]\n⭐[Dong, Xin, et al. \"Knowledge vault: A web-scale approach to probabilistic knowledge fusion.\" Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"This starts with a pair of entities that are known to be in a relation according to a (seed) knowledge base, then performs random walk over the knowledge graph to find other paths that connect these entities.","category":"page"},{"location":"essays/RelationExtraction/#Supervised-Approaches","page":"Relation Extraction","title":"Supervised Approaches","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Pros: Best performance, provided that a sufficient amount of labeled training data is available. Cons: Labeled training data is expensive to produce and thus limited in quantity.","category":"page"},{"location":"essays/RelationExtraction/#Traditional-Methods","page":"Relation Extraction","title":"Traditional Methods","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Typical features:","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"n-grams of words to left and right of entities;\nn-grams of POS of words to left and right of entities;\nflag indicating which entity came first in sentence;\nsequence of POS tags and bag of words (BOW) between the two entities;\ndependency path between subject and object;\nPOS tags of words on the dependency path between the two entities; and\nlemmas on the dependency path.\nrelation embeddings","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Kambhatla, Nanda. \"Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations.\" Proceedings of the ACL 2004 on Interactive poster and demonstration sessions. Association for Computational Linguistics, 2004.][]","category":"page"},{"location":"essays/RelationExtraction/#Neural-Network-Methods","page":"Relation Extraction","title":"Neural Network Methods","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐⭐[Socher, Richard, et al. \"Semantic compositionality through recursive matrix-vector spaces.\" Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning. Association for Computational Linguistics, 2012.][]\n[Hashimoto, Kazuma, et al. \"Simple customization of recursive neural networks for semantic relation classification.\" Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. 2013.][]\n[Zhang, Dongxu, and Dong Wang. \"Relation Classification: CNN or RNN?.\" Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016. 665-675.][]","category":"page"},{"location":"essays/RelationExtraction/#Convolution-Neural-Network","page":"Relation Extraction","title":"Convolution Neural Network","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐⭐[Zeng, Daojian, et al. \"Relation classification via convolutional deep neural network.\" Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers. 2014.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Lexical and sentence level features.   (Image: cnn_zeng)","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Nguyen, Thien Huu, and Ralph Grishman. \"Relation extraction: Perspective from convolutional neural networks.\" Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing. 2015.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"(Image: perspective_cnn)","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Santos, Cicero Nogueira dos, Bing Xiang, and Bowen Zhou. \"Classifying relations by ranking with convolutional neural networks.\" arXiv preprint arXiv:1504.06580 (2015).][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Ranking is introduced.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Xu, Kun, et al. \"Semantic relation classification via convolutional neural networks with simple negative sampling.\" arXiv preprint arXiv:1506.07650 (2015).][]\n⭐[Lin, Yankai, et al. \"Neural relation extraction with selective attention over instances.\" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2016.][]","category":"page"},{"location":"essays/RelationExtraction/#Recurrent-Neural-Network","page":"Relation Extraction","title":"Recurrent Neural Network","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Zhang, Dongxu, and Dong Wang. \"Relation classification via recurrent neural network.\" arXiv preprint arXiv:1508.01006 (2015).][]\n[Zhang, Shu, et al. \"Bidirectional long short-term memory networks for relation classification.\" Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation. 2015.][]\n[Xu, Yan, et al. \"Classifying relations via long short term memory networks along shortest dependency paths.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015.][]\n[Zhou, Peng, et al. \"Attention-based bidirectional long short-term memory networks for relation classification.\" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Vol. 2. 2016.][]","category":"page"},{"location":"essays/RelationExtraction/#Joint-Extraction/End-to-End","page":"Relation Extraction","title":"Joint Extraction/End-to-End","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Roth, Dan, and Wen-tau Yih. A linear programming formulation for global inference in natural language tasks. ILLINOIS UNIV AT URBANA-CHAMPAIGN DEPT OF COMPUTER SCIENCE, 2004.][]\n[Li, Qi, and Heng Ji. \"Incremental joint extraction of entity mentions and relations.\" Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2014.][]\n[Miwa, Makoto, and Yutaka Sasaki. \"Modeling joint entity and relation extraction with table representation.\" Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.][]\n[Miwa, Makoto, and Mohit Bansal. \"End-to-end relation extraction using lstms on sequences and tree structures.\" arXiv preprint arXiv:1601.00770 (2016).][]\n⭐[Zheng, Suncong, et al. \"Joint entity and relation extraction based on a hybrid neural network.\" Neurocomputing 257 (2017): 59-66.][]\n[Ma, Xuezhe, and Eduard Hovy. \"End-to-end sequence labeling via bi-directional lstm-cnns-crf.\" arXiv preprint arXiv:1603.01354 (2016).][]\n[Liu, Yang, et al. \"Implicit Discourse Relation Classification via Multi-Task Neural Networks.\" AAAI. 2016.][]\n⭐⭐[Sun, Mingming, et al. \"Logician: A Unified End-to-End Neural Approach for Open-Domain Information Extraction.\" Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 2018.][]","category":"page"},{"location":"essays/RelationExtraction/#Deep-Reinforcement-Learning","page":"Relation Extraction","title":"Deep Reinforcement Learning","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐⭐[Zeng, Xiangrong, et al. \"Large Scaled Relation Extraction with Reinforcement Learning.\" Relation 2 (2018): 3.][]\n⭐⭐[Feng, Jun, et al. \"Reinforcement Learning for Relation Classification from Noisy Data.\" (2018).][]\n⭐⭐⭐[Narasimhan, Karthik, Adam Yala, and Regina Barzilay. \"Improving information extraction by acquiring external evidence with reinforcement learning.\" arXiv preprint arXiv:1603.07954 (2016).][]\n[Feng, Yuntian, et al. \"Joint Extraction of Entities and Relations Using Reinforcement Learning and Deep Learning.\" Computational intelligence and neuroscience 2017 (2017).][]","category":"page"},{"location":"essays/RelationExtraction/#Unsupervised-Approaches","page":"Relation Extraction","title":"Unsupervised Approaches","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Pros: Leverage large amounts of data and extract large numbers of relations.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Yates, Alexander, et al. \"Textrunner: open information extraction on the web.\" Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations. Association for Computational Linguistics, 2007.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Learn a CRF over POS tags and NP chunks. A Self-Supervised Classifier is also used.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Yan, Yulan, et al. \"Unsupervised relation extraction by mining wikipedia texts using information from the web.\" Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009.][]\n[Kinoshita, Keisuke, et al. \"The REVERB challenge: A common evaluation framework for dereverberation and recognition of reverberant speech.\" Applications of Signal Processing to Audio and Acoustics (WASPAA), 2013 IEEE Workshop on. IEEE, 2013.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Address some issues in TextRunner.(Read the paper for details.)","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Angeli, Gabor, Melvin Jose Johnson Premkumar, and Christopher D. Manning. \"Leveraging linguistic structure for open domain information extraction.\" Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Vol. 1. 2015.][]","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"Attention is first introduced.","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Wang, Linlin, et al. \"Relation classification via multi-level attention cnns.\" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2016.][]","category":"page"},{"location":"essays/RelationExtraction/#Distant-Supervision-Approaches","page":"Relation Extraction","title":"Distant Supervision Approaches","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Craven, Mark, and Johan Kumlien. \"Constructing biological knowledge bases by extracting information from text sources.\" ISMB. Vol. 1999. 1999.][]\n⭐⭐⭐[Mintz, Mike, et al. \"Distant supervision for relation extraction without labeled data.\" Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009.][]\nIf two entities participate in a relation, any sentence that contains those two entities might express that relation.\nIn fact, it is supervised by a database, rather than by labeled text.  (Image: DistantSupervisionOverview.png)\n⭐[Riedel, Sebastian, Limin Yao, and Andrew McCallum. \"Modeling relations and their mentions without labeled text.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Berlin, Heidelberg, 2010.][]\nIf two entities participate in a relation, at least one sentence that mentions these two entities might express that relation.\n⭐[Hoffmann, Raphael, et al. \"Knowledge-based weak supervision for information extraction of overlapping relations.\" Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association for Computational Linguistics, 2011.][]\n⭐[Surdeanu, Mihai, et al. \"Multi-instance multi-label learning for relation extraction.\" Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning. Association for Computational Linguistics, 2012.][]\n[Le Sun, Xianpei Han. \"Global Distant Supervision for Relation Extraction.\" (2016).][]\n[Zhang, Hongjun, et al. \"Relation extraction with deep reinforcement learning.\" IEICE TRANSACTIONS on Information and Systems 100.8 (2017): 1893-1902.][]\n[Ji, Guoliang, et al. \"Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions.\" AAAI. 2017.][]","category":"page"},{"location":"essays/RelationExtraction/#Summary","page":"Relation Extraction","title":"Summary","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"(Image: comparision.png)","category":"page"},{"location":"essays/RelationExtraction/#Data","page":"Relation Extraction","title":"Data","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"SemEval2010_task8\nSemEval2018_task7\nACE 2004 (NOT FREE)\nACE 2005 (NOT FREE)","category":"page"},{"location":"essays/RelationExtraction/#Tools","page":"Relation Extraction","title":"Tools","text":"","category":"section"},{"location":"essays/RelationExtraction/#Packages","page":"Relation Extraction","title":"Packages","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐⭐OpenIE5.0\n⭐Stanford relation extractor\nStanford Open Information Extraction\nOllie\nReVerb\nDeepDive","category":"page"},{"location":"essays/RelationExtraction/#Code","page":"Relation Extraction","title":"Code","text":"","category":"section"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"⭐⭐Neural Relation Extraction\nReinforcement Learning for Relation Classification from Noisy Data(AAAI2018)\nDeepRL-InformationExtraction","category":"page"},{"location":"essays/RelationExtraction/","page":"Relation Extraction","title":"Relation Extraction","text":"[Maynard, Diana, Kalina Bontcheva, and Isabelle Augenstein. \"Natural language processing for the semantic web.\" Synthesis Lectures on the Semantic Web: Theory and Technology 6.2 (2016): 1-194.]: Paper/NaturalLanguageProcessingfortheSemanticWeb.pdf [Brin, Sergey. \"Extracting patterns and relations from the world wide web.\" International Workshop on The World Wide Web and Databases. Springer, Berlin, Heidelberg, 1998.]: Paper/1999-65.pdf [Etzioni, Oren, et al. \"Web-scale information extraction in knowitall:(preliminary results).\" Proceedings of the 13th international conference on World Wide Web. ACM, 2004.]: Paper/1p100.pdf [Carlson, Andrew, et al. \"Toward an architecture for never-ending language learning.\" AAAI. Vol. 5. 2010.]: Paper/1879-8287-1-PB.pdf [Pedro, Saulo DS, and Estevam R. Hruschka. \"Conversing learning: Active learning and active social interaction for human supervision in never-ending learning systems.\" Ibero-American Conference on Artificial Intelligence. Springer, Berlin, Heidelberg, 2012.]: Paper/iberamia2012.pdf [Reiss, Frederick, et al. \"An algebraic approach to rule-based information extraction.\" Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on. IEEE, 2008.]: Paper/48e62ae4478bfad44adfec18b156f471a68c.pdf [Dong, Xin, et al. \"Knowledge vault: A web-scale approach to probabilistic knowledge fusion.\" Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.]: Paper/Dong2014KVW.pdf [Yates, Alexander, et al. \"Textrunner: open information extraction on the web.\" Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations. Association for Computational Linguistics, 2007.]: Paper/p25-yates.pdf [Kinoshita, Keisuke, et al. \"The REVERB challenge: A common evaluation framework for dereverberation and recognition of reverberant speech.\" Applications of Signal Processing to Audio and Acoustics (WASPAA), 2013 IEEE Workshop on. IEEE, 2013.]: Paper/8eff98cfd960ba7ab004b213ef1d1a76f17b.pdf [Angeli, Gabor, Melvin Jose Johnson Premkumar, and Christopher D. Manning. \"Leveraging linguistic structure for open domain information extraction.\" Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Vol. 1. 2015.]: Paper/P15-1034.pdf [Craven, Mark, and Johan Kumlien. \"Constructing biological knowledge bases by extracting information from text sources.\" ISMB. Vol. 1999. 1999.]: Paper/ISMB99-010.pdf [Mintz, Mike, et al. \"Distant supervision for relation extraction without labeled data.\" Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009.]: Paper/P09-1113.pdf [Li, Juanzi, et al. \"Knowledge Graph and Semantic Computing.\"]: Paper/knowledgegraphandsemanticcomputing.pdf [Yan, Yulan, et al. \"Unsupervised relation extraction by mining wikipedia texts using information from the web.\" Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009.]: Paper/P09-1115.pdf [Kambhatla, Nanda. \"Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations.\" Proceedings of the ACL 2004 on Interactive poster and demonstration sessions. Association for Computational Linguistics, 2004.]: Paper/P04-3022.pdf [Riedel, Sebastian, Limin Yao, and Andrew McCallum. \"Modeling relations and their mentions without labeled text.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Berlin, Heidelberg, 2010.]: Paper/b9a731678bf0494fe29cbebb42a822224cc6.pdf [Hoffmann, Raphael, et al. \"Knowledge-based weak supervision for information extraction of overlapping relations.\" Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association for Computational Linguistics, 2011.]: Paper/P11-1055.pdf [Surdeanu, Mihai, et al. \"Multi-instance multi-label learning for relation extraction.\" Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning. Association for Computational Linguistics, 2012.]: Paper/D12-1042.pdf [Le Sun, Xianpei Han. \"Global Distant Supervision for Relation Extraction.\" (2016).]: Paper/12006-56239-1-PB.pdf [Socher, Richard, et al. \"Semantic compositionality through recursive matrix-vector spaces.\" Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning. Association for Computational Linguistics, 2012.]: Paper/D12-1110.pdf [Zeng, Daojian, et al. \"Relation classification via convolutional deep neural network.\" Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers. 2014.]: Paper/C14-1220.pdf [Nguyen, Thien Huu, and Ralph Grishman. \"Relation extraction: Perspective from convolutional neural networks.\" Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing. 2015.]: Paper/W15-1506.pdf [Santos, Cicero Nogueira dos, Bing Xiang, and Bowen Zhou. \"Classifying relations by ranking with convolutional neural networks.\" arXiv preprint arXiv:1504.06580 (2015).]: Paper/1504.06580.pdf [Xu, Kun, et al. \"Semantic relation classification via convolutional neural networks with simple negative sampling.\" arXiv preprint arXiv:1506.07650 (2015).]: Paper/1506.07650.pdf [Lin, Yankai, et al. \"Neural relation extraction with selective attention over instances.\" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2016.]: Paper/P16-1200.pdf [Wang, Linlin, et al. \"Relation classification via multi-level attention cnns.\" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2016.]: Paper/P16-1123.pdf [Zhang, Dongxu, and Dong Wang. \"Relation classification via recurrent neural network.\" arXiv preprint arXiv:1508.01006 (2015).]: Paper/1508.01006.pdf [Zhang, Shu, et al. \"Bidirectional long short-term memory networks for relation classification.\" Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation. 2015.]: Paper/Y15-1009.pdf [Xu, Yan, et al. \"Classifying relations via long short term memory networks along shortest dependency paths.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015.]: Paper/D15-1206.pdf [Zhou, Peng, et al. \"Attention-based bidirectional long short-term memory networks for relation classification.\" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Vol. 2. 2016.]: Paper/P16-2034.pdf [Li, Qi, and Heng Ji. \"Incremental joint extraction of entity mentions and relations.\" Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2014.]: Paper/P14-1038.pdf [Miwa, Makoto, and Yutaka Sasaki. \"Modeling joint entity and relation extraction with table representation.\" Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.]: Paper/D14-1200.pdf [Miwa, Makoto, and Mohit Bansal. \"End-to-end relation extraction using lstms on sequences and tree structures.\" arXiv preprint arXiv:1601.00770 (2016).]: Paper/1601.00770.pdf [Zheng, Suncong, et al. \"Joint entity and relation extraction based on a hybrid neural network.\" Neurocomputing 257 (2017): 59-66.]: Paper/Joint-Entity-and-Relation-Extraction-Based-on.pdf [Ma, Xuezhe, and Eduard Hovy. \"End-to-end sequence labeling via bi-directional lstm-cnns-crf.\" arXiv preprint arXiv:1603.01354 (2016).]: Paper/1603.01354.pdf [Kumar, Shantanu. \"A Survey of Deep Learning Methods for Relation Extraction.\" arXiv preprint arXiv:1705.03645 (2017).]: Paper/1705.03645.pdf [Liu, Yang, et al. \"Implicit Discourse Relation Classification via Multi-Task Neural Networks.\" AAAI. 2016.]: Paper/11831-56211-1-PB.pdf [Zhang, Dongxu, and Dong Wang. \"Relation Classification: CNN or RNN?.\" Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016. 665-675.]: Paper/213.pdf [Feng, Jun, et al. \"Reinforcement Learning for Relation Classification from Noisy Data.\" (2018).]: Paper/AAAI2018Denoising.pdf [Pawar, Sachin, Girish K. Palshikar, and Pushpak Bhattacharyya. \"Relation Extraction: A Survey.\" arXiv preprint arXiv:1712.05191 (2017).]: Paper/1712.05191.pdf [Zeng, Xiangrong, et al. \"Large Scaled Relation Extraction with Reinforcement Learning.\" Relation 2 (2018): 3.]: Paper/zengaaai2018.pdf [Narasimhan, Karthik, Adam Yala, and Regina Barzilay. \"Improving information extraction by acquiring external evidence with reinforcement learning.\" arXiv preprint arXiv:1603.07954 (2016).]: Paper/1603.07954.pdf [Zhang, Hongjun, et al. \"Relation extraction with deep reinforcement learning.\" IEICE TRANSACTIONS on Information and Systems 100.8 (2017): 1893-1902.]: Paper/E100.D2016EDP7450.pdf [Feng, Yuntian, et al. \"Joint Extraction of Entities and Relations Using Reinforcement Learning and Deep Learning.\" Computational intelligence and neuroscience 2017 (2017).]: Paper/7643065.pdf [Sun, Mingming, et al. \"Logician: A Unified End-to-End Neural Approach for Open-Domain Information Extraction.\" Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 2018.]: Paper/2018LogicianAUnifiedEnd-to-EndNeuralApproachforopendomainIE(1).pdf [Ji, Guoliang, et al. \"Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions.\" AAAI. 2017. ]: Paper/14491-66562-1-PB.pdf [Hashimoto, Kazuma, et al. \"Simple customization of recursive neural networks for semantic relation classification.\" Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. 2013.]: Paper/D13-1137.pdf [Roth, Dan, and Wen-tau Yih. A linear programming formulation for global inference in natural language tasks. ILLINOIS UNIV AT URBANA-CHAMPAIGN DEPT OF COMPUTER SCIENCE, 2004.]: Paper/ADA460702.pdf [Soderland, Stephen G. Learning text analysis rules for domain-specific natural language processing. Diss. University of Massachusetts at Amherst, 1997.]: Paper/10.1.1.48.8283.pdf","category":"page"},{"location":"essays/archive/#20210812","page":"20210812","title":"20210812","text":"","category":"section"},{"location":"essays/archive/","page":"20210812","title":"20210812","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-13</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2021-08-13</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-08-12</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-08-12</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='70' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='70' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='51' height='20' fill='#0F80C1'/><rect width='70' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='435' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='410'>Archive</text><text x='435' y='140' transform='scale(.1)' textLength='410'>Archive</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='52' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='52' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='33' height='20' fill='#0F80C1'/><rect width='52' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='345' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='230'>记录</text><text x='345' y='140' transform='scale(.1)' textLength='230'>记录</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='52' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='52' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='33' height='20' fill='#0F80C1'/><rect width='52' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='345' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='230'>Test</text><text x='345' y='140' transform='scale(.1)' textLength='230'>Test</text></g></svg></div>","category":"page"},{"location":"essays/archive/","page":"20210812","title":"20210812","text":"大概有两三年没写博客了，最近忽然很想写点东西，尴尬的是，以前写的pipeline大部分已经忘得一干二净了，于是今天重新整理了下以 前网站里的内容，把大部分内容都搬运到了JuliaDocumenter上来，比我想象中要简单很多，去掉一些大文件之后，整个repo的大小控制 在了20M左右（大部分是图片）。仔细检查了下，原来的文章里的部分样式没有很好地兼容，主要是公式和代码，不过总体来说问题不 大。考虑到这部分文章应该也没人会感兴趣了，我将这部分内容从侧边栏里隐藏起来了，当然，如果还是有人有兴趣“考古”的话，还是可 以通过右下角下一篇文章的链接按顺序查看的。","category":"page"},{"location":"essays/archive/","page":"20210812","title":"20210812","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"一个例子","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"某个夜黑风高的夜晚，一个警察在街边巡逻，突然听到了一阵报警声。循声望去，发现街对面的一家珠宝店玻璃被砸破了，一个带着面具的人正准备从里面翻出来，同时手里还拿着一袋珠宝。","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"能否断定那个带着面具的人就一定是窃贼？","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"在这里，证据（Evidence）虽然并不能让我们断定 戴面具的那个人就是窃贼（Statement），但却让该Statement更可信。","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"什么是概率？","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"贝叶斯学派的一种解释: 描述一件事的可信程度。","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"贝叶斯公式","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"以北京今天下雪为例子，解释 先验，似然，后验","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"贝叶斯分析的重点：","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"如何估计参数：","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"解析的方法：","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"共轭先验","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"马尔科夫方法","category":"page"},{"location":"essays/Bayesian_Analysis_Intro/note/","page":"-","title":"-","text":"非马尔科夫方法","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"keywords: Book,MachineLearning CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#Machine-Learning-A-Bayesian-and-Optimization-Perspective-读书笔记","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"个人感觉这本书的覆盖面有点广，更适合有一定基础之后在回过头来读。暂时先看完了2，3，4章，打个卡，后面有机会再继续读这本书。","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#CH02","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"CH02","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"这一章先回顾了些基础知识，主要是概率和信息论里的基础，顺带复习了下《概率统计》那本书。2.4节的随机过程没太看懂，这块要补一补相关的基础，以后需要的时候再回头来看看。","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"下面是我写的部分习题的解答。","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.1","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.1","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nE(X) = sum_i=1^n E(X_i) = np\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nbeginsplit\nVar(X) = sum_i=1^n Var(X_i) \n       = nVar(X_i) \n       = n left( E(X_i^2) - (E(X_i))^2right) \n       = n(p - p^2)\nendsplit\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.2","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.2","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nE(X) = int_a^b x frac1b-a  dx = fraca+b2\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nbeginsplit\nVar(X) = E(X^2) - (E(X))^2 \n       = int_a^b x^2 frac1b-a  dx - left( fraca+b2right) ^ 2\n     = fraca^2 + ab + b^23  - fraca^2 + 2ab + b^24 \n     = fraca^2 -2ab + b^212\nendsplit\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.3","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.3","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"See the Appendix A.1 in http://cs229.stanford.edu/section/gaussians.pdf","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.4","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.4","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"The definition of beta function is given by:","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"\nbeginequation\nB(alpha beta) = int_0^1 x^alpha-1 (1-x)^beta - 1 dx\nlabelbeta_eq\nendequation\n\n\nAnd we have\n\nbeginequation\nB(alpha beta) = fracGamma(alpha) Gamma(beta)Gamma(alpha + beta)\nlabelbeta_eq_gamma\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"The Beta distribution is:","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nf(x mid alpha beta) = leftbeginmatrix\nfracGamma(alpha + beta)Gamma(alpha) Gamma(beta) x^alpha -1(1-x)^beta - 1  for  0lt x lt1  \n0  otherwise\nendmatrixright\nendequation\n\n\nSo we get\n\nbeginequation\nbeginsplit\nE(X^k) = int_0^1 x^k f(x mid alpha beta)  dx \n       = fracGamma(alpha + beta)Gamma(alpha) Gamma(beta) int_0^1 x^alpha + k -1(1-x)^beta - 1  dx \n       = fracGamma(alpha + beta)Gamma(alpha)Gamma(beta)  cdot  fracGamma(alpha + k) Gamma(beta)Gamma(alpha + k + beta)\nendsplit\nlabelbeta_moment\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"And the Gamma function has a property that:","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nbeginmatrix\nGamma(alpha) = (alpha - 1)Gamma(alpha-1)  if alpha gt 1\nendmatrix\nlabelgamma_property\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"Combine eqrefbeta_moment and eqrefgamma_property, we have that:","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nE(X) = fracalphaalpha + beta\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nE(X^2) = fracalpha (alpha + 1)(alpha + beta)(alpha + beta + 1)\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"So we get: beginequation Var(X) = E(X^2) -(E(X))^2 =fracalpha beta(alpha + beta)^2(alpha + beta + 1) endequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.5","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.5","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"Bellow I will show that eqrefbeta_eq_gamma and eqrefbeta_eq are equal: $ \\begin{split} \\Gamma(a)\\Gamma(b)  &= \\int0^\\infty e^{-x} x^{a-1} \\, dx \\int0^{\\infty} e^{-y} y^{b-1} \\, dy  \\\n&= \\int0^\\infty \\int0^\\infty  e^{-(x+y)} x^{a-1} y^{b-1} \\, dx \\,dy  \\\n\\end{split}$","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"change t = x + y, naturally t ge x we have:","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginsplit\nint_0^infty int_0^infty  e^-(x+y) x^a-1 y^b-1  dx dy  \n= int_0^infty e^-t left(int_0^infty x^a-1(t-x)^b-1  dxright) dt \n stackrelx=mu t=int_0^infty e^-t left( t^a+b-1  int_0^1 mu^a-1 (1-mu)^b-1  dmuright) dt \n = int_0^1 mu^a-1 (1-mu)^b-1  dmu int_0^inftye^-t t^a+b-1  dt \n= int_0^1 mu^a-1 (1-mu)^b-1  dmu cdot Gamma(a+b)\nendsplit","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.6","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.6","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nbeginsplit\nE(X^k) = int_0^infty x^k fracb^aGamma(a) x^a-1 e^-bx  dx \nstackrelz=bx=int_0^infty fracb^aGamma(a) left(fraczbright)^a-1+ke^z frac1b dz \n= b^-k fracGamma(a+k)Gamma(a) \nendsplit\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"Then we have: beginalign E(X) = fracab \nE(X^2) = frac(a+1)ab^2  \nVar(X) =E(X^2)-(E(X))^2 = fracab^2 endalign","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.7","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.7","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"See http://www.mas.ncl.ac.uk/~nmf16/teaching/mas3301/week6.pdf for details.","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.8","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.8","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"Suppose Var(X_i) = sigma^2, so we have Var(barX)=sigma^2n, when n to infty, Var(barX) to 0.","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.11","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.11","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"Let f(x) = ln x -x + 1, the first order is f(x) = 1x - 1, so we have f(x) ge f(1) = 0.","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.12","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.12","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nbeginsplit\nI(xy) = sum_x in mathcalX sum_y in mathcalYP(xy) log fracP(xy)P(x)P(y) \n= - sum_x in mathcalX sum_y in mathcalYP(xy) log fracP(x)P(y)P(xy) \n ge - sum_x in mathcalX sum_y in mathcalY P(xy)left(fracP(x)P(y)P(xy) -1right) \nendsplit\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P2.13","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P2.13","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"\nbeginequation\nbeginsplit\n-sum_i in I p_i log left( frac q_i p_i right)  ge - sum_i in I p_i left( frac q_i - p_i p_iright) \n = -sum_i in I (q_i - p_i) \n = 1 - sum_i in I q_i \n ge 0\nendsplit\nendequation\n\n\n P215 \n\nSee httpsstatsstackexchangecomquestions66108(httpsstatsstackexchangecomquestions66108why-is-entropy-maximised-when-the-probability-distribution-is-uniform) for details\n\n CH03\n\n这一章先从参数估计入手介绍了参数视角下的线性回归和分类问题作者提到了本书重点关注有监督的问题无监督的问题没有涉及\n\n下面是我写的部分习题的解答\n\n P31\n\nbeginequation\nbeginsplit\nsigma_c^2 = Var(hattheta) \n= Var(frac1m sum_i=1^m hattheta_i) \n= frac1m^2 sum_i=1^m Var(hattheta_i) \n= frac1m sigma^2\nendsplit\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P3.2-and-P3.3","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P3.2 & P3.3","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"See http://willett.ece.wisc.edu/wp-uploads/2016/01/15-MVUE.pdf for details.","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P3.4","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P3.4","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"According to the quadratic formula, we can easily get the inequation.","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P3.5","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P3.5","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"By taking the derivative of MSE(hattheta_b) with respect to alpha, we let:","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\n2(1+alpha)MSE(hattheta_MVU) + 2hattheta_o^2 alpha = 0\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"and then we get:","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"beginequation\nalpha_* = - fracMSE(hattheta_MVU)MSE(hattheta_MVU) + hattheta_o^2 = - frac11+frachattheta_o^2MSE(hattheta_MVU)\nendequation","category":"page"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/#P3.6","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"P3.6","text":"","category":"section"},{"location":"essays/Notes_on_Machine_Learning_A_Bayesian_and_Optimization_Perspective/","page":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","title":"Machine Learning A Bayesian and Optimization Perspective 读书笔记","text":"Since the expectation in Eq 3.26 is taken with respect to p(mathcalXtheta), if the integration and differentiation can be interchanged, we can first take the integration of p(mathcalXtheta), resulting Eq 3.26","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"keywords: Survey,ReinforcementLearning,Python CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/#深度强化学习相关库概览","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"","category":"section"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"知己知彼，方能百战不殆！","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"在写一个新的DRL库之前，不妨先学习下已有工具包的组织架构，以及不同的工具包都有哪些优缺点。","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"以下是本文重点考虑的几个库(也欢迎推荐其它优秀的库)：","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"DeepRL 这个库基于PyTorch，作者之前写了Reinforcement Learning: An Introduction的Python实现。似乎是前不久刚public的，可以看出作者的Python编码能力在这一年里似乎进步了不少😋，总之，DeepRL的结构还是蛮清晰的。\nCoach 据说是架构最清晰的一个库，支持TensorFlow。\nTensorForce 也是基于TensorFlow的一个库。\nRLlib 这个框架需要花点时间仔细研读下源码，里面封装了一个Actor模型用来处理分布式并发执行的逻辑依赖问题，做法跟Coach的那类Parameter sharing很不一样，从论文上来看，效率也要高很多，感觉是未来的一个趋势。得花时间想想channel模型是否适用（毕竟Julia目前并没有内置的actor模型）。","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/#DeepRL","page":"深度强化学习相关库概览","title":"DeepRL","text":"","category":"section"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"整个库是围绕着Agent对象展开的，通过config初始化Agent对象，然后在外围执行run_iterations或run_episodes控制进度。OO的思想有点重，以至于初始化的时候需要指定的部分非常多。","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/#Pros","page":"深度强化学习相关库概览","title":"Pros","text":"","category":"section"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"Agent的划分很清晰，基本都控制在100行代码以内\n在Gym的基础之上又套了一层Task，这个值得借鉴\n在对PyTorch封装的部分，抽象出了network_body和network_head，姑且理解为编码层和输出层，这个也值得学习借鉴\n有logger模块，后面自己实现的时候，可以结合类似TensorBoard的工具打log","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/#Cons","page":"深度强化学习相关库概览","title":"Cons","text":"","category":"section"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"没有文档\nAgent中与环境交互部分耦合得比较紧，把一些step和rollout单独划分出来会更简洁些\n一些小的模块作者已经在注意抽象了，比如replay等，但是接口还需改进\n并行化，跑多个副本","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/#Coach","page":"深度强化学习相关库概览","title":"Coach","text":"","category":"section"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"目前粗略看了下，真的是相当清晰。要是有一些Guide知道如何新写一个Agent，怎么做Compare等等，应该会有更多的人Envolve进来。后面写的时候应该会反复参考这个库。","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"怎么并行化运行多个task，以及维护一个Parameter Server，暂时没有想好如何在Julia中实现，直觉告诉我这点应该是Julia的优势。","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/#TensorForce","page":"深度强化学习相关库概览","title":"TensorForce","text":"","category":"section"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"目前文档还不是很全，但目前看到的几点值得学习的地方是：","category":"page"},{"location":"essays/An_Overview_of_Existing_Reinforcement_Learning_Libraries/","page":"深度强化学习相关库概览","title":"深度强化学习相关库概览","text":"contrib中，对不同环境做了统一抽象，这个跟我正在做的不谋而合\nagent虽然也按类做了划分，但是感觉不如Coach做得好\n跟TF绑定得有点太紧了","category":"page"},{"location":"assets/revealjs/examples/markdown/#Markdown-Demo","page":"Markdown Demo","title":"Markdown Demo","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/#External-1.1","page":"Markdown Demo","title":"External 1.1","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"Content 1.1","category":"page"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"Note: This will only appear in the speaker notes window.","category":"page"},{"location":"assets/revealjs/examples/markdown/#External-1.2","page":"Markdown Demo","title":"External 1.2","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"Content 1.2","category":"page"},{"location":"assets/revealjs/examples/markdown/#External-2","page":"Markdown Demo","title":"External 2","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"Content 2.1","category":"page"},{"location":"assets/revealjs/examples/markdown/#External-3.1","page":"Markdown Demo","title":"External 3.1","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"Content 3.1","category":"page"},{"location":"assets/revealjs/examples/markdown/#External-3.2","page":"Markdown Demo","title":"External 3.2","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"Content 3.2","category":"page"},{"location":"assets/revealjs/examples/markdown/#External-3.3-(Image)","page":"Markdown Demo","title":"External 3.3 (Image)","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"(Image: External Image)","category":"page"},{"location":"assets/revealjs/examples/markdown/#External-3.4-(Math)","page":"Markdown Demo","title":"External 3.4 (Math)","text":"","category":"section"},{"location":"assets/revealjs/examples/markdown/","page":"Markdown Demo","title":"Markdown Demo","text":"\\[ J(\\theta_0,\\theta_1) = \\sum_{i=0} \\]","category":"page"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/#Notes-on-Distributional-Reinforcement-Learning","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"","category":"section"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"<div class=blogmeta><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='150' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='150' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='75' height='20' fill='#555'/><rect x='75' width='75' height='20' fill='#97C40F'/><rect width='150' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='385' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>Last Update</text><text x='385' y='140' transform='scale(.1)' textLength='650'>Last Update</text><text x='1115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2022-01-13</text><text x='1115' y='140' transform='scale(.1)' textLength='650'>2022-01-13</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='122' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='122' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='47' height='20' fill='#555'/><rect x='47' width='75' height='20' fill='#4c1'/><rect width='122' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='245' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='370'>Create</text><text x='245' y='140' transform='scale(.1)' textLength='370'>Create</text><text x='835' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='650'>2021-12-29</text><text x='835' y='140' transform='scale(.1)' textLength='650'>2021-12-29</text></g></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='94' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='94' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='21' height='20' fill='#555'/><rect x='21' width='73' height='20' fill='#4c1'/><rect width='94' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='115' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='110'>⇩</text><text x='115' y='140' transform='scale(.1)' textLength='110'>⇩</text><text x='565' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='630'>notebook.jl</text><text x='565' y='140' transform='scale(.1)' textLength='630'>notebook.jl</text></g><a target='_blank' xlink:href='notebook.jl'><rect width='94' height='20' fill='rgba(0,0,0,0)'/></a></svg><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='160' height='20'><linearGradient id='s' x2='0' y2='100%'><stop offset='0' stop-color='#bbb' stop-opacity='.1'/><stop offset='1' stop-opacity='.1'/></linearGradient><clipPath id='r'><rect width='160' height='20' rx='3' fill='#fff'/></clipPath><g clip-path='url(#r)'><rect width='19' height='20' fill='#555'/><rect x='19' width='141' height='20' fill='#0F80C1'/><rect width='160' height='20' fill='url(#s)'/></g><g fill='#fff' text-anchor='middle' font-family='Verdana,Geneva,DejaVu Sans,sans-serif' text-rendering='geometricPrecision' font-size='110'><text x='105' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='90'>#</text><text x='105' y='140' transform='scale(.1)' textLength='90'>#</text><text x='885' y='150' fill='#010101' fill-opacity='.3' transform='scale(.1)' textLength='1310'>Reinforcement Learning</text><text x='885' y='140' transform='scale(.1)' textLength='1310'>Reinforcement Learning</text></g></svg></div>","category":"page"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"<iframe src=\"notebook.jl.html\" style=\"width: 100%;height: 100vh\"></iframe>","category":"page"},{"location":"reading/Notes_on_Distributional_Reinforcement_Learning/","page":"Notes on Distributional Reinforcement Learning","title":"Notes on Distributional Reinforcement Learning","text":"<script src=\"https://utteranc.es/client.js\"\n        repo=\"findmyway/TianJun.jl\"\n        issue-term=\"url\"\n        label=\"💬Comment\"\n        theme=\"github-light\"\n        crossorigin=\"anonymous\"\n        async>\n</script>\n","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"keywords: Probability CJKmainfont: KaiTi –-","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/#The-Gambler's-Ruin-Problem","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"","category":"section"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"最近在看概率统计和Explorations in Monte Carlo Methods这两本书的时候，都有看到这个例子，单独拎出来记录下。","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/#问题描述","page":"The Gambler's Ruin Problem","title":"问题描述","text":"","category":"section"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"假设A、B两人一起玩一个游戏，A获胜的概率为p，B获胜的概率为1-p，A手上有i块钱，B手上有k-i块钱（即两人的总和为k），每次输的一方要给对方1块钱。重复该游戏直到其中一方破产，求最终A剩余的钱为k的概率。","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"我们可以将该过程抽象出来：假设A是坐标轴上位于i处的一点，每次随机向左或向右移动单位长，向右移动的概率为p，向左移动的概率为1-p，重复该过程，直到A运动到原点或者位置k时结束，那么最终该点位于位置k的概率为多少？","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"(Image: )","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/#问题分析","page":"The Gambler's Ruin Problem","title":"问题分析","text":"","category":"section"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"这里将A最终位于点k记为事件W，直观上看，假如p=12，那么k-i相对于i-0越大，那么P(W)也就越小。由于A每次只能移动一步，于是，该问题可以看做是动态规划的问题。","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"记每次移动后A的位置为a，于是有：","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"$","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"\\begin{equation} \\mathrm{P}(W|a=i)=p \\mathrm{P}(W|a=i+1) + (1-p) \\mathrm{P}(W|a=i-1) \\end{equation} $","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"为了方便，记mathrmP(Wa=i)为a_i，于是上式可以写成如下通项公式：","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"$","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"\\begin{equation} (1-p)(a{i} - a{i-1})=p(a{i+1} - a{i}) \\end{equation} $","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"然后，根据边界条件a_0 = 0和a_k = 1可以得到以下式：","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"$","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"\\begin{equation} \\begin{split} a2 - a1 &= \\frac{1-p}{p} a1 \\\na3 - a2 &= \\frac{1-p}{p} (a2 - a1) \\; &= \\left(\\frac{1-p}{p}\\right)^2 a1 \\\n\\vdots \\\na{k-1} - a{k-2} &= \\frac{1-p}{p} (a{k-2} - a{k-3}) \\; &= \\left(\\frac{1-p}{p}\\right)^{k-2} a1 \\\n1 - a{k-1} &= \\frac{1-p}{p} (a{k-1} - a{k-2}) \\; &= \\left(\\frac{1-p}{p}\\right)^{k-1} a_1 \\\n\\end{split} \\end{equation} $","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/","page":"The Gambler's Ruin Problem","title":"The Gambler's Ruin Problem","text":"求和之后可以得到： $ \\begin{equation} 1 - a1 = a1 \\sum_{i=1}^{k-1} \\left( \\frac{1-p}{p} \\right) ^ i \\end{equation} $","category":"page"},{"location":"essays/The_Gambler_Ruin_Problem/#讨论","page":"The Gambler's Ruin Problem","title":"讨论","text":"","category":"section"}]
}
