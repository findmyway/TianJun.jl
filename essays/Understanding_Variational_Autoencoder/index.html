<!DOCTYPE html>
<html lang="en-US"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Understanding Variational Autoencoder · Jun Tian</title><meta name="title" content="Understanding Variational Autoencoder · Jun Tian"/><meta property="og:title" content="Understanding Variational Autoencoder · Jun Tian"/><meta property="twitter:title" content="Understanding Variational Autoencoder · Jun Tian"/><meta name="description" content="Documentation for Jun Tian."/><meta property="og:description" content="Documentation for Jun Tian."/><meta property="twitter:description" content="Documentation for Jun Tian."/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-132847825-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-132847825-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.jpg" alt="Jun Tian logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Jun Tian</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">👋 About</a></li><li><span class="tocitem">💻 Programming</span><ul><li><a class="tocitem" href="../../programming/A_Deep_Dive_into_Distributed.jl/">A Deep Dive into Distributed.jl</a></li></ul></li><li><span class="tocitem">📖 Reading</span><ul><li><a class="tocitem" href="../../reading/Notes_on_Distributional_Reinforcement_Learning/">Notes on Distributional Reinforcement Learning</a></li></ul></li><li><a class="tocitem" href="../../AMA/">🙋 Ask Me Anything</a></li><li><a class="tocitem" href="../../blogroll/">🔗 Blogroll</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Understanding Variational Autoencoder</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Understanding Variational Autoencoder</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/findmyway/TianJun.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/findmyway/TianJun.jl/blob/master/docs/src/essays/Understanding_Variational_Autoencoder/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><hr/><p>keywords: Algorithm CJKmainfont: KaiTi –-</p><h1 id="Understanding-Variational-Autoencoder"><a class="docs-heading-anchor" href="#Understanding-Variational-Autoencoder">Understanding Variational Autoencoder</a><a id="Understanding-Variational-Autoencoder-1"></a><a class="docs-heading-anchor-permalink" href="#Understanding-Variational-Autoencoder" title="Permalink"></a></h1><p>本文主要记录自己在学习<a href="https://arxiv.org/abs/1603.00788">Automatic Differentiation Variational Inference</a>过程中的一些参考资料和理解。</p><h2 id="熵（Entropy）"><a class="docs-heading-anchor" href="#熵（Entropy）">熵（Entropy）</a><a id="熵（Entropy）-1"></a><a class="docs-heading-anchor-permalink" href="#熵（Entropy）" title="Permalink"></a></h2><p>以下借用《Statistical Rethinking》一书中的部分内容来理解Entropy及其相关的内容。</p><p>假设今天天气预报告诉我们，明天有可能下雨（记为事件A），该事件有一定的不确定性，等到第二天结束的时候，不论第二天是否下了雨，之前的不确定性都消失了。换句话说，在第二天看到事件A的结果时（下雨或没下雨），我们获取了一定的信息。</p><blockquote><p><strong>信息</strong>：在观测到某一事件发生的结果之后，不确定性的降低程度。</p></blockquote><p>直观上，衡量信息的指标需要满足一下三点：</p><ol><li>连续性。如果该指标不满足连续性，那么一点微小的概率变化会导致很大的不确定性的变化。</li><li>递增性。随着可能发生的事件越多，不确定性越大。比如有两个城市需要预测天气，A城市的有一半的可能下雨，一半的可能是晴天，而B城市下雨、下冰雹和晴天的概率分别为1/3，那么我们希望B城市的不确定性更大一些，毕竟可能性空间更大。</li><li>叠加性。将明天是否下雨记为事件A，明天是否刮风记为事件B，假设二者相互独立，那么将事件A的不确定性与事件B的不确定性之和，与（下雨/刮风、不下雨/刮风、下雨/不刮风、不下雨/不刮风）这四个事件发生的不确定性之和相等。</li></ol><p>信息熵的表达形式刚好满足以上三点：</p><p class="math-container">\[
\begin{equation}
\begin{split}
H(p) &amp; = - \mathbb{E} \log \left(p_i\right) \\
     &amp; = - \sum_{i=1}^{n} p_i \log\left(p_i \right) 
\end{split}
\end{equation}\]</p><p>简单来说，熵就是概率对数的加权平均。</p><h2 id="K-L散度（Kullback-Leibler-Divergence-）"><a class="docs-heading-anchor" href="#K-L散度（Kullback-Leibler-Divergence-）">K-L散度（Kullback-Leibler Divergence ）</a><a id="K-L散度（Kullback-Leibler-Divergence-）-1"></a><a class="docs-heading-anchor-permalink" href="#K-L散度（Kullback-Leibler-Divergence-）" title="Permalink"></a></h2><blockquote><p><strong>散度</strong>:用某个分布去描述另外一个分布时引入的不确定性。</p></blockquote><p>散度的定义如下：</p><p>$</p><p>\begin{equation} \begin{split} D<em>{KL}(p,q) &amp; = \sum</em>{i \in I} p<em>i  \left( \log (p</em>i) - \log (q<em>i) \right) \
       &amp; = \sum</em>{i \in I} p<em>i \log \left( \frac {p</em>i} {q_i} \right)  \end{split} \label{KL} \end{equation} $</p><p>KL散度是大于等于0的，可以通过[Gibb&#39;s不等式][Gibb&#39;s inequality]证明：</p><p>首先，我们知道：</p><p>$</p><p>\begin{equation} \ln x \le x - 1 \end{equation} $</p><p>于是，根据<span>$\eqref{KL}$</span>中KL散度的定义，可以得到如下不等式：</p><p>$</p><p>\begin{equation} \begin{split} -\sum<em>{i \in I} p</em>i \log \left( \frac {q<em>i} {p</em>i} \right) &amp; \ge - \sum<em>{i \in I} p</em>i \left( \frac {q<em>i - p</em>i} {p<em>i}\right) \
 &amp;= -\sum</em>{i \in I} (q<em>i - p</em>i) \
 &amp;= 1 - \sum<em>{i \in I} q</em>i \
 &amp;\ge 0 \end{split} \end{equation} $</p><p>可以看出，只有当两个分布一一对应相等的时候才取0。</p><p>如果将KL散度拆开，可以看作是交叉熵与信息熵之差：</p><p>$</p><p>\begin{equation} D_{KL} = H(p,q) - H(p) \end{equation} $</p><p>关于KL散度，一个很重要的特性是，<span>$KL(p,q)$</span>一般不等于<span>$KL(q,p)$</span>，也就是说，KL散度是有方向性的。这里借用[Statistical Rethinking][SR]一书第6章中的例子来解释下。</p><p>假设在地球上随机选一地点，该点位于水面和陆地的概率分别为0.7和0.3，记为<span>$q=(0.7,0.3)$</span>，我们知道火星非常干燥，假设相应的概率为<span>$p=(0.01,0.99)$</span>，可以算出<span>$KL(p,q)=1.14$</span>，<span>$KL(q,p)=2.62$</span>。可以看出，用火星上的分布去估计地球上的分布时，得到的散度更大。直观可以这么理解：一个地球人第一次到火星上时，有很大概率落在陆地上，根据他在地球上的先验，落在陆地上的概率为0.3，因而不会特别惊讶；相反，一个火星人第一次落到地球上时，大概率会落到水面上，这对于火星人来说，是非常惊讶的事（火星上只有0.01的概率），因而其KL散度更大。因此，通常如果选择一个熵值较大的分布去估计某个真实分布时，得到的KL散度会更小一些。</p><h2 id="The-Evidence-Lower-Bound"><a class="docs-heading-anchor" href="#The-Evidence-Lower-Bound">The Evidence Lower Bound</a><a id="The-Evidence-Lower-Bound-1"></a><a class="docs-heading-anchor-permalink" href="#The-Evidence-Lower-Bound" title="Permalink"></a></h2><p>给定<span>$\boldsymbol{x} = x_{1:n}$</span>为观测变量，<span>$\boldsymbol{z}=z_{1:m}$</span>为隐变量，对应的联合概率为<span>$p(\boldsymbol{z}, \boldsymbol{x})$</span>，后验可以写成：</p><p>$</p><p>\begin{equation} p(\boldsymbol{z} | \boldsymbol{x}) = \frac{p(\boldsymbol{z}, \boldsymbol{x})}{p(\boldsymbol{x})} \label{posterior} \end{equation} $</p><p>其中<span>$p(\boldsymbol{x})$</span>称为证据：</p><p>$</p><p>\begin{equation} p(\boldsymbol{x}) = \int p(\boldsymbol{z}, \boldsymbol{x})d\boldsymbol{z} \end{equation} $</p><p>变分推断背后的思想是，用一些简单的参数化分布（记为<span>$Q_{\phi}(\boldsymbol{z} | \boldsymbol{x})$</span>）去拟合后验分布<span>$P(\boldsymbol{z}|\boldsymbol{x})$</span>，通过调整参数<span>$\phi$</span>使得<span>$Q_{\phi}$</span>尽可能接近<span>$P(\boldsymbol{z}|\boldsymbol{x})$</span>，从而转换成优化问题。衡量二者相似度的方法之一就是用前面提到的KL散度，按理说，我们应该最小化<span>$KL(P,Q)$</span>，不过实际使用中通常是最小化<span>$KL(Q,P)$</span>，前面也介绍了，二者实际上是不同的，可以参考阅读[A Beginner&#39;s Guide to Variational Methods: Mean-Field Approximation][]一文中的<em>Forward KL vs. Reverse KL</em>和<a href="http://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/">KL Divergence: Forward vs Reverse?</a>部分来了解为什么优化<span>$KL(Q,P)$</span>。</p><p>$</p><p>\begin{equation} KL(q(\boldsymbol{z}) \| p(\boldsymbol{z}|\boldsymbol{x})) = \mathbb{E} [ \log q(\boldsymbol{z})] - \mathbb{E} [\log p(\boldsymbol{z}|\boldsymbol{x})] \end{equation} $</p><p>这里的<span>$\mathbb{E}$</span>是相对<span>$q(\boldsymbol{z})$</span>的期望，将<span>$\eqref{posterior}$</span>代入可得：</p><p>$</p><p>\begin{equation} KL(q(\boldsymbol{z}) \| p(\boldsymbol{z}|\boldsymbol{x})) = \mathbb{E} [ \log q(\boldsymbol{z})] - \mathbb{E} [\log p(\boldsymbol{z},\boldsymbol{x})] + \log p(\boldsymbol{x}) \label{KLqp} \end{equation} $</p><p>由于<span>$p(\boldsymbol{x})$</span>是固定的，于是最小化上式中的KL等价于最大化下面的证据下界：</p><p>$</p><p>\begin{equation} ELBO(q) = \mathbb{E}[\log p(\boldsymbol{z},\boldsymbol{x})] - \mathbb{E} [\log q(\boldsymbol{z})] \label{ELBO} \end{equation} $</p><p>上式中的联合概率又可以表示成先验乘以似然，于是有：</p><p>$</p><p>\begin{equation} \begin{split} ELBO(q) &amp; = \mathbb{E} [\log p(\boldsymbol{z})] + \mathbb{E} [\log p(\boldsymbol{x}| \boldsymbol{z})] - \mathbb{E} [\log q(\mathbb{z})] \
&amp; =\mathbb{E}[\log p(\boldsymbol{x}|\boldsymbol{z})] - KL(q(\boldsymbol{z})\| p(\boldsymbol{z})) \end{split} \end{equation} $</p><p>直观上看，第一项是似然的期望，最大化ELBO意味着我们希望隐变量能够很好地解释观测数据；第二项是隐变量的先验与估计之间的KL散度，越小越好。由<span>$\eqref{KLqp}$</span>和<span>$\eqref{ELBO}$</span>可以得到：</p><p>$</p><p>\begin{equation} \log p(\boldsymbol{x}) = KL(q(\boldsymbol{z}) \| p(\boldsymbol{z}|\boldsymbol{x})) + ELBO(q) \end{equation} $</p><p>上面式左边是证据，由于KL散度大于等于0，因而右边的第二项ELBO也就称作证据下界。</p><h2 id="Variational-Autoencoder"><a class="docs-heading-anchor" href="#Variational-Autoencoder">Variational Autoencoder</a><a id="Variational-Autoencoder-1"></a><a class="docs-heading-anchor-permalink" href="#Variational-Autoencoder" title="Permalink"></a></h2><p>关于VAE的文章很多，这里就不详细介绍了。[VAE][]的原文不太好读懂，建议先读[Tutorial on Variational Autoencoders][]，然后可以看看一些代码实现，比如<a href="http://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/">Variational Autoencoder: Intuition and Implementation</a>，和这里<a href="http://kvfrans.com/variational-autoencoders-explained/">Variational Autoencoders Explained</a>。</p><h2 id="Read-More"><a class="docs-heading-anchor" href="#Read-More">Read More</a><a id="Read-More-1"></a><a class="docs-heading-anchor-permalink" href="#Read-More" title="Permalink"></a></h2><ul><li>[A Beginner&#39;s Guide to Variational Methods: Mean-Field Approximation][]</li><li><a href="http://www.openias.org/variational-coin-toss">Variational Coin Toss</a></li><li><a href="https://arxiv.org/abs/1601.00670">Variational Inference: A Review for Statisticians</a></li></ul><p>[Gibb&#39;s inequality]:https://en.wikipedia.org/wiki/Gibbs%27_inequality [SR]:https://book.douban.com/subject/26607925/ [A Beginner&#39;s Guide to Variational Methods: Mean-Field Approximation]:http://blog.evjang.com/2016/08/variational-bayes.html [Tutorial on Variational Autoencoders]:https://arxiv.org/abs/1606.05908 [VAE]:https://arxiv.org/abs/1312.6114</p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>. All contents published at this site follows <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4.0</a> by default. For the Chinese version, please visit <a href="https://tianjun.me">tianjun.me</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Saturday 23 December 2023 15:51">Saturday 23 December 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
