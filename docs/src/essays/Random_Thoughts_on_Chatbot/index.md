---
keywords: Thought,Chatbot
CJKmainfont: KaiTi
---

# 漫谈聊天机器人

本文的主要目的是记录下这段时间关于Chatbot的一些思考。

## Act Like Robot

Chatbot的最初形态是提供一种人机接口，能够根据指令像机器人一样完成一些预定的动作（即Act Like Robot）。该任务的难点在于语义理解（LU）部分，假设语言能准确无误地转换成指令，那么所有Robot的控制都可以扩展到语言这一接口上。

LU的过程既可以由人来做，也可以由机器来做，由于语言实在太丰富，目前实际的系统中，往往是二者的折中，即人们在使用产品的过程中，根据过去的经验，会将语言收缩到较小的范围内。比如，一般不太会去问`明天最高温有没有38°以上？`，而是会直接问`明天的最高温`。在该过程中，人承担了部分理解和推断的任务。

实际的系统中，目前的统计模型能够较好地解决收缩后的LU的解析（大约90%左右吧）。问题似乎不大，不过另一个实际的问题是，许多任务并不太方便通过一句话就完整地表述清楚（比如`订机票`），于是，系统设计层面就多出了任务切换/信息共享/多任务竞争/LU在不同语境下的解析等等一系列问题。以我对现有各大厂商的Chatbot的理解，大家并没有对这些问题的解决方案达成共识，一般都采取一些trick做了简化，这里先不详细展开。

## Act Like Human

显然，人并不满足于只让Chatbot完成一些既定的任务，而是在某些方面*Act Like Human*，最典型的就是情感诉求。从系统层面上讲，只需要在对话中加入情绪识别，再辅以对话库作为支撑即可。然而，更多时候，我们希望在整个对话的过程中Chatbot能够真正**Act Like Human**:

- 质疑
  - 对状态切换的质疑
  - 对不可靠信息的质疑
- 询问
  - 对缺失的参数提出询问
  - 对最终结果进行confirm
- 分享
  - 与用户共享当前的状态信息
  - 共享预测信息

目前来看，由于*询问*类的提问能够很好地预测，因而比较好做，而另外两类不太好直接生产预定的response。

## Think Like Human
